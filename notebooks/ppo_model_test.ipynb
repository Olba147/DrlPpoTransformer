{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PPO Model Testing\n",
        "\n",
        "Evaluate a trained PPO+JEPA model using a single training config file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "da50f2c0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project root: C:\\python\\koulu\\Gradu\n"
          ]
        }
      ],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import io\n",
        "import zipfile\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "from typing import Dict, List\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "# Resolve project root robustly when notebook is launched from different cwd\n",
        "def find_project_root(start: Path) -> Path:\n",
        "    p = start.resolve()\n",
        "    for candidate in [p, *p.parents]:\n",
        "        if (candidate / \"src\").exists() and (candidate / \"configs\").exists():\n",
        "            return candidate\n",
        "    raise RuntimeError(\"Could not locate project root containing src/ and configs/\")\n",
        "\n",
        "PROJECT_ROOT = find_project_root(Path.cwd())\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(PROJECT_ROOT))\n",
        "if str(PROJECT_ROOT / \"src\") not in sys.path:\n",
        "    sys.path.insert(0, str(PROJECT_ROOT / \"src\"))\n",
        "\n",
        "from config.config_utils import load_json_config\n",
        "from Datasets.multi_asset_dataset import Dataset_Finance_MultiAsset\n",
        "from Training.sb3_jepa_ppo import JEPAAuxFeatureExtractor, PPOWithJEPA\n",
        "from models.jepa.jepa import JEPA\n",
        "from models.time_series.patchTransformer import PatchTSTEncoder\n",
        "\n",
        "print(f\"Project root: {PROJECT_ROOT}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a1c90c9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# -----------------------------\n",
        "# User parameters\n",
        "# -----------------------------\n",
        "# Config used for training this PPO model\n",
        "PPO_CONFIG_PATH = \"configs/ppo_jepa_final_1.json\"\n",
        "\n",
        "# Optional overrides (set to None to auto-resolve from config)\n",
        "PPO_CHECKPOINT_PATH = \"checkpoints/jepa6_ppo_final1/ppo_6400000_steps.zip\"\n",
        "# Optional: used only for asset_universe lookup, not for JEPA model weights\n",
        "JEPA_CHECKPOINT_PATH = \"checkpoints/jepa6_ppo_final1/jepa_step_300000.pt\"\n",
        "\n",
        "# If None, evaluate all assets available in validation split\n",
        "MAX_ASSETS = None\n",
        "\n",
        "# Deterministic policy during evaluation\n",
        "DETERMINISTIC = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "30ca8d85",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model name: jepa6_ppo_final1\n",
            "PPO checkpoint: C:\\python\\koulu\\Gradu\\checkpoints\\jepa6_ppo_final1\\ppo_1600000_steps.zip\n",
            "JEPA checkpoint: C:\\python\\koulu\\Gradu\\checkpoints\\jepa6_ppo_final1\\jepa_step_300000.pt\n",
            "Action mode: discrete_3\n",
            "Asset universe: None\n"
          ]
        }
      ],
      "source": [
        "def get_latest_ppo_checkpoint(checkpoint_dir: str) -> str | None:\n",
        "    if not os.path.isdir(checkpoint_dir):\n",
        "        return None\n",
        "    ckpts = []\n",
        "    for fname in os.listdir(checkpoint_dir):\n",
        "        if fname.startswith(\"ppo_\") and fname.endswith(\"_steps.zip\"):\n",
        "            ckpts.append(os.path.join(checkpoint_dir, fname))\n",
        "    if not ckpts:\n",
        "        return None\n",
        "    ckpts.sort(key=lambda p: os.path.getmtime(p))\n",
        "    return ckpts[-1]\n",
        "\n",
        "\n",
        "def load_tickers(path: str) -> list | None:\n",
        "    if not path or not os.path.exists(path):\n",
        "        return None\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        tickers = [line.strip() for line in f if line.strip()]\n",
        "    return tickers or None\n",
        "\n",
        "\n",
        "def load_asset_universe_from_checkpoint(path: str | None) -> list | None:\n",
        "    if not path or not os.path.exists(path):\n",
        "        return None\n",
        "    try:\n",
        "        checkpoint = torch.load(path, map_location=\"cpu\")\n",
        "    except Exception:\n",
        "        return None\n",
        "    asset_universe = checkpoint.get(\"asset_universe\")\n",
        "    return list(asset_universe) if asset_universe else None\n",
        "\n",
        "\n",
        "cfg = load_json_config(str(PROJECT_ROOT / PPO_CONFIG_PATH), \"\", str(PROJECT_ROOT / \"notebooks\" / \"ppo_model_test.ipynb\"))\n",
        "\n",
        "model_name = cfg[\"model_name\"]\n",
        "paths_cfg = cfg[\"paths\"]\n",
        "dataset_cfg = cfg[\"dataset\"]\n",
        "env_cfg = cfg[\"env\"]\n",
        "ppo_cfg = cfg[\"ppo\"]\n",
        "jepa_cfg = cfg[\"jepa_model\"]\n",
        "\n",
        "checkpoint_root = paths_cfg.get(\"checkpoint_root\", \"checkpoints\")\n",
        "log_root = paths_cfg.get(\"log_root\", \"logs\")\n",
        "ppo_checkpoint_dir = str(PROJECT_ROOT / checkpoint_root / model_name)\n",
        "\n",
        "if PPO_CHECKPOINT_PATH is None:\n",
        "    PPO_CHECKPOINT_PATH = get_latest_ppo_checkpoint(ppo_checkpoint_dir)\n",
        "if PPO_CHECKPOINT_PATH is None:\n",
        "    raise FileNotFoundError(f\"No PPO checkpoint found under {ppo_checkpoint_dir}\")\n",
        "if not os.path.isabs(PPO_CHECKPOINT_PATH):\n",
        "    PPO_CHECKPOINT_PATH = str(PROJECT_ROOT / PPO_CHECKPOINT_PATH)\n",
        "\n",
        "if JEPA_CHECKPOINT_PATH is None and paths_cfg.get(\"jepa_checkpoint_dir\"):\n",
        "    jepa_checkpoint_dir = paths_cfg[\"jepa_checkpoint_dir\"]\n",
        "    JEPA_CHECKPOINT_PATH = str(PROJECT_ROOT / jepa_checkpoint_dir / \"best.pt\")\n",
        "if JEPA_CHECKPOINT_PATH is not None and not os.path.isabs(JEPA_CHECKPOINT_PATH):\n",
        "    JEPA_CHECKPOINT_PATH = str(PROJECT_ROOT / JEPA_CHECKPOINT_PATH)\n",
        "\n",
        "ACTION_MODE = env_cfg.get(\"action_mode\", \"continuous\")\n",
        "ALLOW_SHORT = env_cfg.get(\"allow_short\", True)\n",
        "INCLUDE_WEALTH = env_cfg.get(\"include_wealth\", True)\n",
        "TRANSACTION_COST = 0.0005\n",
        "\n",
        "print(\"Model name:\", model_name)\n",
        "print(\"PPO checkpoint:\", PPO_CHECKPOINT_PATH)\n",
        "print(\"JEPA checkpoint:\", JEPA_CHECKPOINT_PATH)\n",
        "print(\"Action mode:\", ACTION_MODE)\n",
        "print(\"Asset universe:\", paths_cfg[\"asset_universe_path\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "f6f03b44",
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class EvalConfig:\n",
        "    annual_trading_days: int = 252\n",
        "    regular_hours_only: bool = True\n",
        "    timeframe: str = \"15min\"\n",
        "    flat_threshold: float = 1e-3\n",
        "\n",
        "\n",
        "def _timeframe_to_minutes(timeframe: str) -> int:\n",
        "    tf = timeframe.strip().lower()\n",
        "    if tf.endswith(\"min\"):\n",
        "        return int(tf[:-3])\n",
        "    if tf.endswith(\"h\"):\n",
        "        return int(tf[:-1]) * 60\n",
        "    raise ValueError(f\"Unsupported timeframe: {timeframe}\")\n",
        "\n",
        "\n",
        "def annualization_factor(cfg: EvalConfig) -> float:\n",
        "    minutes_per_day = 390 if cfg.regular_hours_only else 24 * 60\n",
        "    minutes = _timeframe_to_minutes(cfg.timeframe)\n",
        "    bars_per_day = max(1, minutes_per_day // minutes)\n",
        "    return bars_per_day * cfg.annual_trading_days\n",
        "\n",
        "\n",
        "def action_to_weight(action) -> float:\n",
        "    if ACTION_MODE == \"discrete_3\":\n",
        "        discrete_actions = np.array([-1.0, 0.0, 1.0], dtype=np.float32)\n",
        "        idx = int(np.asarray(action).reshape(-1)[0])\n",
        "        idx = int(np.clip(idx, 0, len(discrete_actions) - 1))\n",
        "        w_t = float(discrete_actions[idx])\n",
        "    else:\n",
        "        w_t = float(np.clip(np.asarray(action).reshape(-1)[0], -1.0, 1.0))\n",
        "    if not ALLOW_SHORT:\n",
        "        w_t = max(0.0, w_t)\n",
        "    return w_t\n",
        "\n",
        "\n",
        "def compute_drawdown(equity: np.ndarray) -> float:\n",
        "    if equity.size == 0:\n",
        "        return float(\"nan\")\n",
        "    peak = np.maximum.accumulate(equity)\n",
        "    drawdown = (equity - peak) / peak\n",
        "    return float(np.min(drawdown))\n",
        "\n",
        "\n",
        "def safe_sharpe(mean: float, std: float, ann_factor: float) -> float:\n",
        "    if std <= 0 or np.isnan(std):\n",
        "        return float(\"nan\")\n",
        "    return float(mean / std * np.sqrt(ann_factor))\n",
        "\n",
        "\n",
        "def build_jepa_model(device: str, num_assets: int) -> JEPA:\n",
        "    encoder_num_assets = num_assets if jepa_cfg.get(\"use_asset_embeddings\", True) else None\n",
        "\n",
        "    jepa_context_encoder = PatchTSTEncoder(\n",
        "        patch_len=jepa_cfg[\"patch_len\"],\n",
        "        d_model=jepa_cfg[\"d_model\"],\n",
        "        n_features=jepa_cfg[\"n_features\"],\n",
        "        n_time_features=jepa_cfg[\"n_time_features\"],\n",
        "        nhead=jepa_cfg[\"nhead\"],\n",
        "        num_layers=jepa_cfg[\"num_layers\"],\n",
        "        dim_ff=jepa_cfg[\"dim_ff\"],\n",
        "        dropout=jepa_cfg[\"dropout\"],\n",
        "        add_cls=jepa_cfg.get(\"add_cls\", True),\n",
        "        pooling=jepa_cfg[\"pooling\"],\n",
        "        pred_len=jepa_cfg[\"pred_len\"],\n",
        "        num_assets=encoder_num_assets,\n",
        "    )\n",
        "    jepa_target_encoder = copy.deepcopy(jepa_context_encoder)\n",
        "\n",
        "    jepa_model = JEPA(\n",
        "        jepa_context_encoder,\n",
        "        jepa_target_encoder,\n",
        "        d_model=jepa_cfg[\"d_model\"],\n",
        "        ema_tau_min=jepa_cfg[\"ema_tau_min\"],\n",
        "        ema_tau_max=jepa_cfg[\"ema_tau_max\"],\n",
        "    )\n",
        "\n",
        "    for param in jepa_model.parameters():\n",
        "        param.requires_grad = False\n",
        "    jepa_model.eval()\n",
        "    return jepa_model.to(device)\n",
        "\n",
        "\n",
        "def extract_jepa_state_dict_from_ppo_zip(model_path: str) -> Dict[str, torch.Tensor]:\n",
        "    with zipfile.ZipFile(model_path, \"r\") as zf:\n",
        "        with zf.open(\"policy.pth\", \"r\") as f:\n",
        "            policy_state = torch.load(io.BytesIO(f.read()), map_location=\"cpu\")\n",
        "\n",
        "    prefix = \"features_extractor.jepa_model.\"\n",
        "    jepa_state = {}\n",
        "    for k, v in policy_state.items():\n",
        "        if k.startswith(prefix):\n",
        "            jepa_state[k[len(prefix):]] = v\n",
        "    if not jepa_state:\n",
        "        raise RuntimeError(\"No JEPA weights found in PPO zip policy state.\")\n",
        "    return jepa_state\n",
        "\n",
        "\n",
        "def load_ppo_model(model_path: str, device: str, policy_kwargs: Dict) -> PPOWithJEPA:\n",
        "    try:\n",
        "        print(\"Loading PPO (and embedded JEPA) directly from PPO zip...\")\n",
        "        return PPOWithJEPA.load(model_path, device=device)\n",
        "    except Exception as exc:\n",
        "        print(f\"Primary PPO load failed ({exc}); retrying with custom policy_kwargs and JEPA weights from PPO zip.\")\n",
        "\n",
        "        fx_kwargs = policy_kwargs.get(\"features_extractor_kwargs\", {})\n",
        "        jepa_model = fx_kwargs.get(\"jepa_model\")\n",
        "        if jepa_model is None:\n",
        "            raise RuntimeError(\"Fallback requires policy_kwargs.features_extractor_kwargs.jepa_model\")\n",
        "\n",
        "        jepa_state = extract_jepa_state_dict_from_ppo_zip(model_path)\n",
        "        missing, unexpected = jepa_model.load_state_dict(jepa_state, strict=False)\n",
        "        if missing:\n",
        "            print(f\"Missing keys when loading JEPA from PPO zip: {missing}\")\n",
        "        if unexpected:\n",
        "            print(f\"Unexpected keys when loading JEPA from PPO zip: {unexpected}\")\n",
        "\n",
        "        return PPOWithJEPA.load(model_path, device=device, custom_objects={\"policy_kwargs\": policy_kwargs})\n",
        "\n",
        "\n",
        "def eval_asset(model: PPOWithJEPA, dataset: Dataset_Finance_MultiAsset, asset_id: str, cfg: EvalConfig) -> Dict[str, float]:\n",
        "    asset_idx = dataset.asset_id_to_idx.get(asset_id, -1)\n",
        "    X = dataset.data_x[asset_id]\n",
        "    dates = dataset.dates[asset_id]\n",
        "    ohlcv = dataset.ohlcv[asset_id]\n",
        "\n",
        "    seq_len = dataset.seq_len\n",
        "    pred_len = dataset.pred_len\n",
        "    n_steps = len(X) - seq_len - pred_len\n",
        "    if n_steps <= 0:\n",
        "        return {}\n",
        "\n",
        "    w_prev = 0.0\n",
        "    wealth = 1.0\n",
        "    rewards, asset_returns, positions, turnovers, equity = [], [], [], [], []\n",
        "\n",
        "    for cursor in range(n_steps):\n",
        "        x_context = X[cursor : cursor + seq_len].astype(np.float32)\n",
        "        t_context = dates[cursor : cursor + seq_len].astype(np.float32)\n",
        "        x_target = X[cursor + seq_len : cursor + seq_len + pred_len].astype(np.float32)\n",
        "        t_target = dates[cursor + seq_len : cursor + seq_len + pred_len].astype(np.float32)\n",
        "\n",
        "        obs = {\n",
        "            \"x_context\": x_context,\n",
        "            \"t_context\": t_context,\n",
        "            \"x_target\": x_target,\n",
        "            \"t_target\": t_target,\n",
        "            \"asset_id\": np.int64(asset_idx),\n",
        "            \"w_prev\": np.array([w_prev], dtype=np.float32),\n",
        "        }\n",
        "        if INCLUDE_WEALTH:\n",
        "            obs[\"wealth_feats\"] = np.array([np.log(wealth)], dtype=np.float32)\n",
        "\n",
        "        action, _ = model.predict(obs, deterministic=DETERMINISTIC)\n",
        "        w_t = action_to_weight(action)\n",
        "\n",
        "        close_t = float(ohlcv[cursor + seq_len - 1][3])\n",
        "        close_tp1 = float(ohlcv[cursor + seq_len][3])\n",
        "        r_tp1 = float(np.log(close_tp1 / close_t))\n",
        "\n",
        "        turnover = abs(w_t - w_prev)\n",
        "        reward = w_t * r_tp1 - TRANSACTION_COST * turnover\n",
        "        wealth *= float(np.exp(reward))\n",
        "\n",
        "        rewards.append(reward)\n",
        "        asset_returns.append(r_tp1)\n",
        "        positions.append(w_t)\n",
        "        turnovers.append(turnover)\n",
        "        equity.append(wealth)\n",
        "        w_prev = w_t\n",
        "\n",
        "    rewards = np.asarray(rewards, dtype=np.float64)\n",
        "    asset_returns = np.asarray(asset_returns, dtype=np.float64)\n",
        "    positions = np.asarray(positions, dtype=np.float64)\n",
        "    turnovers = np.asarray(turnovers, dtype=np.float64)\n",
        "    equity = np.asarray(equity, dtype=np.float64)\n",
        "\n",
        "    ann_factor = annualization_factor(cfg)\n",
        "    mean_reward = float(np.mean(rewards)) if rewards.size else float(\"nan\")\n",
        "    std_reward = float(np.std(rewards, ddof=1)) if rewards.size > 1 else float(\"nan\")\n",
        "\n",
        "    total_log_return = float(np.sum(rewards)) if rewards.size else float(\"nan\")\n",
        "    total_return = float(np.exp(total_log_return) - 1.0) if rewards.size else float(\"nan\")\n",
        "    annualized_return = float(np.exp(mean_reward * ann_factor) - 1.0) if rewards.size else float(\"nan\")\n",
        "    annualized_vol = float(std_reward * np.sqrt(ann_factor)) if rewards.size > 1 else float(\"nan\")\n",
        "    sharpe = safe_sharpe(mean_reward, std_reward, ann_factor)\n",
        "\n",
        "    downside = rewards[rewards < 0]\n",
        "    downside_std = float(np.std(downside, ddof=1)) if downside.size > 1 else float(\"nan\")\n",
        "    sortino = safe_sharpe(mean_reward, downside_std, ann_factor)\n",
        "\n",
        "    max_drawdown = compute_drawdown(equity)\n",
        "    calmar = float(annualized_return / abs(max_drawdown)) if max_drawdown < 0 else float(\"nan\")\n",
        "\n",
        "    win_rate = float(np.mean(rewards > 0)) if rewards.size else float(\"nan\")\n",
        "    avg_turnover = float(np.mean(turnovers)) if turnovers.size else float(\"nan\")\n",
        "    total_turnover = float(np.sum(turnovers)) if turnovers.size else float(\"nan\")\n",
        "    avg_position = float(np.mean(positions)) if positions.size else float(\"nan\")\n",
        "    pos_std = float(np.std(positions, ddof=1)) if positions.size > 1 else float(\"nan\")\n",
        "    abs_pos = float(np.mean(np.abs(positions))) if positions.size else float(\"nan\")\n",
        "\n",
        "    flat_mask = np.abs(positions) <= cfg.flat_threshold\n",
        "    long_mask = positions > cfg.flat_threshold\n",
        "    short_mask = positions < -cfg.flat_threshold\n",
        "    flat_frac = float(np.mean(flat_mask)) if positions.size else float(\"nan\")\n",
        "    long_frac = float(np.mean(long_mask)) if positions.size else float(\"nan\")\n",
        "    short_frac = float(np.mean(short_mask)) if positions.size else float(\"nan\")\n",
        "\n",
        "    trade_count = int(np.sum(np.abs(np.diff(positions)) > cfg.flat_threshold)) if positions.size > 1 else 0\n",
        "\n",
        "    bh_mean = float(np.mean(asset_returns)) if asset_returns.size else float(\"nan\")\n",
        "    bh_std = float(np.std(asset_returns, ddof=1)) if asset_returns.size > 1 else float(\"nan\")\n",
        "    bh_total_return = float(np.exp(np.sum(asset_returns)) - 1.0) if asset_returns.size else float(\"nan\")\n",
        "    bh_annualized_return = float(np.exp(bh_mean * ann_factor) - 1.0) if asset_returns.size else float(\"nan\")\n",
        "    bh_annualized_vol = float(bh_std * np.sqrt(ann_factor)) if asset_returns.size > 1 else float(\"nan\")\n",
        "    bh_sharpe = safe_sharpe(bh_mean, bh_std, ann_factor)\n",
        "\n",
        "    return {\n",
        "        \"asset_id\": asset_id,\n",
        "        \"steps\": int(n_steps),\n",
        "        \"total_return\": total_return,\n",
        "        \"annualized_return\": annualized_return,\n",
        "        \"annualized_volatility\": annualized_vol,\n",
        "        \"sharpe\": sharpe,\n",
        "        \"sortino\": sortino,\n",
        "        \"max_drawdown\": max_drawdown,\n",
        "        \"calmar\": calmar,\n",
        "        \"avg_reward\": mean_reward,\n",
        "        \"reward_volatility\": std_reward,\n",
        "        \"win_rate\": win_rate,\n",
        "        \"avg_turnover\": avg_turnover,\n",
        "        \"total_turnover\": total_turnover,\n",
        "        \"avg_position\": avg_position,\n",
        "        \"position_std\": pos_std,\n",
        "        \"avg_abs_position\": abs_pos,\n",
        "        \"long_frac\": long_frac,\n",
        "        \"short_frac\": short_frac,\n",
        "        \"flat_frac\": flat_frac,\n",
        "        \"trade_count\": trade_count,\n",
        "        \"bh_total_return\": bh_total_return,\n",
        "        \"bh_annualized_return\": bh_annualized_return,\n",
        "        \"bh_annualized_volatility\": bh_annualized_vol,\n",
        "        \"bh_sharpe\": bh_sharpe,\n",
        "    }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "bf9ef6fd",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 11 tickers from C:\\python\\koulu\\Gradu\\configs\\assets\\tickers1.txt\n",
            "tickers: ['AMZN', 'KO', 'DIS', 'V', 'SPY', 'NKE', 'CSCO', 'JPM', 'CAT', 'AMGN', 'DIA']\n",
            "Loading evaluation dataset...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ollik\\AppData\\Local\\Temp\\ipykernel_51592\\3472166087.py:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(path, map_location=\"cpu\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Dataset_Finance_MultiAsset] Global date splits: train_end=2024-08-01 15:15:00+00:00 val_end=2025-04-29 16:30:00+00:00 n_dates=33178 n_train=23224 n_val=4978 n_test=4976\n",
            "Assets to evaluate: 11\n"
          ]
        }
      ],
      "source": [
        "def _resolve_project_path(path_value: str | None) -> str | None:\n",
        "    if path_value is None:\n",
        "        return None\n",
        "    p = Path(path_value)\n",
        "    if p.is_absolute():\n",
        "        return str(p)\n",
        "    return str((PROJECT_ROOT / p).resolve())\n",
        "\n",
        "\n",
        "\n",
        "ticker_list_path = paths_cfg.get(\"ticker_list_path\")\n",
        "if not ticker_list_path:\n",
        "    raise ValueError(\"Config is missing paths.ticker_list_path\")\n",
        "\n",
        "# Build dataset from the same config used in training\n",
        "tickers_path = PROJECT_ROOT / ticker_list_path\n",
        "tickers = load_tickers(str(tickers_path))\n",
        "if not tickers:\n",
        "    raise RuntimeError(f\"No tickers loaded from {tickers_path}\")\n",
        "\n",
        "dataset_kwargs = {\n",
        "    \"root_path\": _resolve_project_path(dataset_cfg[\"root_path\"]),\n",
        "    \"data_path\": dataset_cfg[\"data_path\"],\n",
        "    \"start_date\": dataset_cfg.get(\"start_date\"),\n",
        "    \"split\": \"val\",\n",
        "    \"size\": [dataset_cfg[\"context_len\"], dataset_cfg[\"target_len\"]],\n",
        "    \"use_time_features\": dataset_cfg.get(\"use_time_features\", True),\n",
        "    \"rolling_window\": dataset_cfg[\"rolling_window\"],\n",
        "    \"train_split\": dataset_cfg[\"train_split\"],\n",
        "    \"test_split\": dataset_cfg[\"test_split\"],\n",
        "    \"regular_hours_only\": dataset_cfg.get(\"regular_hours_only\", True),\n",
        "    \"timeframe\": dataset_cfg.get(\"timeframe\", \"15min\"),\n",
        "    \"tickers\": tickers,\n",
        "}\n",
        "\n",
        "asset_universe = load_asset_universe_from_checkpoint(JEPA_CHECKPOINT_PATH)\n",
        "if asset_universe:\n",
        "    dataset_kwargs[\"asset_universe\"] = asset_universe\n",
        "\n",
        "dataset_kwargs[\"tickers\"] = tickers\n",
        "print(f\"Loaded {len(tickers)} tickers from {tickers_path}\")\n",
        "print(f\"tickers: {tickers}\")\n",
        "\n",
        "print(\"Loading evaluation dataset...\")\n",
        "test_dataset = Dataset_Finance_MultiAsset(**dataset_kwargs)\n",
        "if not test_dataset.asset_ids:\n",
        "    raise RuntimeError(\"No assets found in the validation dataset.\")\n",
        "\n",
        "if MAX_ASSETS is not None:\n",
        "    test_dataset.asset_ids = test_dataset.asset_ids[: int(MAX_ASSETS)]\n",
        "\n",
        "print(f\"Assets to evaluate: {len(test_dataset.asset_ids)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "fba4965e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading JEPA model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ollik\\miniconda3\\envs\\.graduenv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading PPO model from C:\\python\\koulu\\Gradu\\checkpoints\\jepa6_ppo_final1\\ppo_1600000_steps.zip...\n",
            "Loading PPO (and embedded JEPA) directly from PPO zip...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "MultiInputActorCriticPolicy(\n",
              "  (features_extractor): JEPAAuxFeatureExtractor(\n",
              "    (jepa_model): JEPA(\n",
              "      (context_enc): PatchTSTEncoder(\n",
              "        (proj_price): Linear(in_features=72, out_features=192, bias=True)\n",
              "        (proj_time): Linear(in_features=32, out_features=192, bias=True)\n",
              "        (posenc): PositionalEncoding()\n",
              "        (encoder): TransformerEncoder(\n",
              "          (layers): ModuleList(\n",
              "            (0-3): 4 x TransformerEncoderLayer(\n",
              "              (self_attn): MultiheadAttention(\n",
              "                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
              "              )\n",
              "              (linear1): Linear(in_features=192, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "              (linear2): Linear(in_features=768, out_features=192, bias=True)\n",
              "              (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "              (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout1): Dropout(p=0.0, inplace=False)\n",
              "              (dropout2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (final_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "        (head): Identity()\n",
              "      )\n",
              "      (target_enc): PatchTSTEncoder(\n",
              "        (proj_price): Linear(in_features=72, out_features=192, bias=True)\n",
              "        (proj_time): Linear(in_features=32, out_features=192, bias=True)\n",
              "        (posenc): PositionalEncoding()\n",
              "        (encoder): TransformerEncoder(\n",
              "          (layers): ModuleList(\n",
              "            (0-3): 4 x TransformerEncoderLayer(\n",
              "              (self_attn): MultiheadAttention(\n",
              "                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
              "              )\n",
              "              (linear1): Linear(in_features=192, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "              (linear2): Linear(in_features=768, out_features=192, bias=True)\n",
              "              (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "              (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout1): Dropout(p=0.0, inplace=False)\n",
              "              (dropout2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (final_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "        (head): Identity()\n",
              "      )\n",
              "      (predictor): Sequential(\n",
              "        (0): Linear(in_features=192, out_features=384, bias=True)\n",
              "        (1): GELU(approximate='none')\n",
              "        (2): Linear(in_features=384, out_features=384, bias=True)\n",
              "        (3): GELU(approximate='none')\n",
              "        (4): Linear(in_features=384, out_features=192, bias=True)\n",
              "        (5): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pi_features_extractor): JEPAAuxFeatureExtractor(\n",
              "    (jepa_model): JEPA(\n",
              "      (context_enc): PatchTSTEncoder(\n",
              "        (proj_price): Linear(in_features=72, out_features=192, bias=True)\n",
              "        (proj_time): Linear(in_features=32, out_features=192, bias=True)\n",
              "        (posenc): PositionalEncoding()\n",
              "        (encoder): TransformerEncoder(\n",
              "          (layers): ModuleList(\n",
              "            (0-3): 4 x TransformerEncoderLayer(\n",
              "              (self_attn): MultiheadAttention(\n",
              "                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
              "              )\n",
              "              (linear1): Linear(in_features=192, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "              (linear2): Linear(in_features=768, out_features=192, bias=True)\n",
              "              (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "              (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout1): Dropout(p=0.0, inplace=False)\n",
              "              (dropout2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (final_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "        (head): Identity()\n",
              "      )\n",
              "      (target_enc): PatchTSTEncoder(\n",
              "        (proj_price): Linear(in_features=72, out_features=192, bias=True)\n",
              "        (proj_time): Linear(in_features=32, out_features=192, bias=True)\n",
              "        (posenc): PositionalEncoding()\n",
              "        (encoder): TransformerEncoder(\n",
              "          (layers): ModuleList(\n",
              "            (0-3): 4 x TransformerEncoderLayer(\n",
              "              (self_attn): MultiheadAttention(\n",
              "                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
              "              )\n",
              "              (linear1): Linear(in_features=192, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "              (linear2): Linear(in_features=768, out_features=192, bias=True)\n",
              "              (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "              (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout1): Dropout(p=0.0, inplace=False)\n",
              "              (dropout2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (final_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "        (head): Identity()\n",
              "      )\n",
              "      (predictor): Sequential(\n",
              "        (0): Linear(in_features=192, out_features=384, bias=True)\n",
              "        (1): GELU(approximate='none')\n",
              "        (2): Linear(in_features=384, out_features=384, bias=True)\n",
              "        (3): GELU(approximate='none')\n",
              "        (4): Linear(in_features=384, out_features=192, bias=True)\n",
              "        (5): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (vf_features_extractor): JEPAAuxFeatureExtractor(\n",
              "    (jepa_model): JEPA(\n",
              "      (context_enc): PatchTSTEncoder(\n",
              "        (proj_price): Linear(in_features=72, out_features=192, bias=True)\n",
              "        (proj_time): Linear(in_features=32, out_features=192, bias=True)\n",
              "        (posenc): PositionalEncoding()\n",
              "        (encoder): TransformerEncoder(\n",
              "          (layers): ModuleList(\n",
              "            (0-3): 4 x TransformerEncoderLayer(\n",
              "              (self_attn): MultiheadAttention(\n",
              "                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
              "              )\n",
              "              (linear1): Linear(in_features=192, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "              (linear2): Linear(in_features=768, out_features=192, bias=True)\n",
              "              (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "              (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout1): Dropout(p=0.0, inplace=False)\n",
              "              (dropout2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (final_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "        (head): Identity()\n",
              "      )\n",
              "      (target_enc): PatchTSTEncoder(\n",
              "        (proj_price): Linear(in_features=72, out_features=192, bias=True)\n",
              "        (proj_time): Linear(in_features=32, out_features=192, bias=True)\n",
              "        (posenc): PositionalEncoding()\n",
              "        (encoder): TransformerEncoder(\n",
              "          (layers): ModuleList(\n",
              "            (0-3): 4 x TransformerEncoderLayer(\n",
              "              (self_attn): MultiheadAttention(\n",
              "                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
              "              )\n",
              "              (linear1): Linear(in_features=192, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "              (linear2): Linear(in_features=768, out_features=192, bias=True)\n",
              "              (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "              (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout1): Dropout(p=0.0, inplace=False)\n",
              "              (dropout2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (final_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "        (head): Identity()\n",
              "      )\n",
              "      (predictor): Sequential(\n",
              "        (0): Linear(in_features=192, out_features=384, bias=True)\n",
              "        (1): GELU(approximate='none')\n",
              "        (2): Linear(in_features=384, out_features=384, bias=True)\n",
              "        (3): GELU(approximate='none')\n",
              "        (4): Linear(in_features=384, out_features=192, bias=True)\n",
              "        (5): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (mlp_extractor): MlpExtractor(\n",
              "    (policy_net): Sequential(\n",
              "      (0): Linear(in_features=227, out_features=256, bias=True)\n",
              "      (1): Tanh()\n",
              "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (3): Tanh()\n",
              "    )\n",
              "    (value_net): Sequential(\n",
              "      (0): Linear(in_features=227, out_features=256, bias=True)\n",
              "      (1): Tanh()\n",
              "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (3): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (action_net): Linear(in_features=256, out_features=3, bias=True)\n",
              "  (value_net): Linear(in_features=256, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "num_asset_ids = int(getattr(test_dataset, \"num_asset_ids\", len(test_dataset.asset_ids)))\n",
        "\n",
        "print(\"Loading JEPA model...\")\n",
        "jepa_model = build_jepa_model(device, num_assets=num_asset_ids)\n",
        "\n",
        "policy_kwargs = dict(\n",
        "    features_extractor_class=JEPAAuxFeatureExtractor,\n",
        "    features_extractor_kwargs=dict(\n",
        "        jepa_model=jepa_model,\n",
        "        embedding_dim=jepa_cfg[\"d_model\"],\n",
        "        patch_len=jepa_cfg[\"patch_len\"],\n",
        "        patch_stride=jepa_cfg[\"patch_stride\"],\n",
        "        use_obs_targets=True,\n",
        "        target_len=test_dataset.pred_len,\n",
        "    ),\n",
        "    net_arch=dict(pi=[256, 256], vf=[256, 256]),\n",
        ")\n",
        "\n",
        "print(f\"Loading PPO model from {PPO_CHECKPOINT_PATH}...\")\n",
        "model = load_ppo_model(PPO_CHECKPOINT_PATH, device=device, policy_kwargs=policy_kwargs)\n",
        "model.policy.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "3c85627d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/11] Evaluating AMZN...\n",
            "[2/11] Evaluating KO...\n",
            "[3/11] Evaluating DIS...\n",
            "[4/11] Evaluating V...\n",
            "[5/11] Evaluating SPY...\n",
            "[6/11] Evaluating NKE...\n",
            "[7/11] Evaluating CSCO...\n",
            "[8/11] Evaluating JPM...\n",
            "[9/11] Evaluating CAT...\n",
            "[10/11] Evaluating AMGN...\n",
            "[11/11] Evaluating DIA...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>asset_id</th>\n",
              "      <th>steps</th>\n",
              "      <th>total_return</th>\n",
              "      <th>annualized_return</th>\n",
              "      <th>annualized_volatility</th>\n",
              "      <th>sharpe</th>\n",
              "      <th>sortino</th>\n",
              "      <th>max_drawdown</th>\n",
              "      <th>calmar</th>\n",
              "      <th>avg_reward</th>\n",
              "      <th>...</th>\n",
              "      <th>position_std</th>\n",
              "      <th>avg_abs_position</th>\n",
              "      <th>long_frac</th>\n",
              "      <th>short_frac</th>\n",
              "      <th>flat_frac</th>\n",
              "      <th>trade_count</th>\n",
              "      <th>bh_total_return</th>\n",
              "      <th>bh_annualized_return</th>\n",
              "      <th>bh_annualized_volatility</th>\n",
              "      <th>bh_sharpe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>AMGN</td>\n",
              "      <td>4416</td>\n",
              "      <td>-0.147091</td>\n",
              "      <td>-0.210266</td>\n",
              "      <td>0.305779</td>\n",
              "      <td>-0.771992</td>\n",
              "      <td>-0.793974</td>\n",
              "      <td>-0.244893</td>\n",
              "      <td>-0.858605</td>\n",
              "      <td>-3.602853e-05</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.146664</td>\n",
              "      <td>-0.209680</td>\n",
              "      <td>0.305772</td>\n",
              "      <td>-0.769582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AMZN</td>\n",
              "      <td>4417</td>\n",
              "      <td>0.105566</td>\n",
              "      <td>0.160518</td>\n",
              "      <td>0.362771</td>\n",
              "      <td>0.410360</td>\n",
              "      <td>0.485925</td>\n",
              "      <td>-0.317797</td>\n",
              "      <td>0.505097</td>\n",
              "      <td>2.272081e-05</td>\n",
              "      <td>...</td>\n",
              "      <td>0.060084</td>\n",
              "      <td>0.996378</td>\n",
              "      <td>0.996378</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003622</td>\n",
              "      <td>1</td>\n",
              "      <td>0.104821</td>\n",
              "      <td>0.159358</td>\n",
              "      <td>0.362985</td>\n",
              "      <td>0.407364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>CAT</td>\n",
              "      <td>4416</td>\n",
              "      <td>-0.143562</td>\n",
              "      <td>-0.205414</td>\n",
              "      <td>0.353585</td>\n",
              "      <td>-0.650291</td>\n",
              "      <td>-0.724398</td>\n",
              "      <td>-0.356979</td>\n",
              "      <td>-0.575422</td>\n",
              "      <td>-3.509363e-05</td>\n",
              "      <td>...</td>\n",
              "      <td>0.086132</td>\n",
              "      <td>0.992527</td>\n",
              "      <td>0.992527</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.007473</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.130198</td>\n",
              "      <td>-0.186948</td>\n",
              "      <td>0.354228</td>\n",
              "      <td>-0.584258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>CSCO</td>\n",
              "      <td>4416</td>\n",
              "      <td>0.137421</td>\n",
              "      <td>0.210515</td>\n",
              "      <td>0.235753</td>\n",
              "      <td>0.810365</td>\n",
              "      <td>1.025087</td>\n",
              "      <td>-0.203259</td>\n",
              "      <td>1.035697</td>\n",
              "      <td>2.915844e-05</td>\n",
              "      <td>...</td>\n",
              "      <td>0.033634</td>\n",
              "      <td>0.998868</td>\n",
              "      <td>0.998868</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001132</td>\n",
              "      <td>1</td>\n",
              "      <td>0.130017</td>\n",
              "      <td>0.198842</td>\n",
              "      <td>0.235809</td>\n",
              "      <td>0.769079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>DIA</td>\n",
              "      <td>4408</td>\n",
              "      <td>-0.026654</td>\n",
              "      <td>-0.039360</td>\n",
              "      <td>0.195011</td>\n",
              "      <td>-0.205914</td>\n",
              "      <td>-0.240573</td>\n",
              "      <td>-0.185307</td>\n",
              "      <td>-0.212403</td>\n",
              "      <td>-6.128715e-06</td>\n",
              "      <td>...</td>\n",
              "      <td>0.058242</td>\n",
              "      <td>0.996597</td>\n",
              "      <td>0.996597</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003403</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.031810</td>\n",
              "      <td>-0.046914</td>\n",
              "      <td>0.195193</td>\n",
              "      <td>-0.246168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>DIS</td>\n",
              "      <td>4370</td>\n",
              "      <td>0.006814</td>\n",
              "      <td>0.010234</td>\n",
              "      <td>0.306697</td>\n",
              "      <td>0.033198</td>\n",
              "      <td>0.041051</td>\n",
              "      <td>-0.319800</td>\n",
              "      <td>0.032000</td>\n",
              "      <td>1.553978e-06</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.007318</td>\n",
              "      <td>0.010991</td>\n",
              "      <td>0.306695</td>\n",
              "      <td>0.035642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>JPM</td>\n",
              "      <td>4416</td>\n",
              "      <td>0.149181</td>\n",
              "      <td>0.229131</td>\n",
              "      <td>0.314291</td>\n",
              "      <td>0.656421</td>\n",
              "      <td>0.759357</td>\n",
              "      <td>-0.274844</td>\n",
              "      <td>0.833676</td>\n",
              "      <td>3.148771e-05</td>\n",
              "      <td>...</td>\n",
              "      <td>0.291829</td>\n",
              "      <td>0.906024</td>\n",
              "      <td>0.906024</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.093976</td>\n",
              "      <td>1</td>\n",
              "      <td>0.093133</td>\n",
              "      <td>0.141246</td>\n",
              "      <td>0.323585</td>\n",
              "      <td>0.408302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>KO</td>\n",
              "      <td>4416</td>\n",
              "      <td>0.003830</td>\n",
              "      <td>0.005688</td>\n",
              "      <td>0.187825</td>\n",
              "      <td>0.030199</td>\n",
              "      <td>0.037589</td>\n",
              "      <td>-0.172204</td>\n",
              "      <td>0.033032</td>\n",
              "      <td>8.657020e-07</td>\n",
              "      <td>...</td>\n",
              "      <td>0.039787</td>\n",
              "      <td>0.998415</td>\n",
              "      <td>0.998415</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001585</td>\n",
              "      <td>1</td>\n",
              "      <td>0.003404</td>\n",
              "      <td>0.005055</td>\n",
              "      <td>0.187840</td>\n",
              "      <td>0.026841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>NKE</td>\n",
              "      <td>4416</td>\n",
              "      <td>-0.320269</td>\n",
              "      <td>-0.436051</td>\n",
              "      <td>0.419048</td>\n",
              "      <td>-1.366887</td>\n",
              "      <td>-1.401690</td>\n",
              "      <td>-0.417277</td>\n",
              "      <td>-1.044993</td>\n",
              "      <td>-8.742245e-05</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.319929</td>\n",
              "      <td>-0.435633</td>\n",
              "      <td>0.419046</td>\n",
              "      <td>-1.365125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SPY</td>\n",
              "      <td>4417</td>\n",
              "      <td>-0.016413</td>\n",
              "      <td>-0.024249</td>\n",
              "      <td>0.213125</td>\n",
              "      <td>-0.115181</td>\n",
              "      <td>-0.129597</td>\n",
              "      <td>-0.210802</td>\n",
              "      <td>-0.115033</td>\n",
              "      <td>-3.746645e-06</td>\n",
              "      <td>...</td>\n",
              "      <td>0.042524</td>\n",
              "      <td>0.998189</td>\n",
              "      <td>0.998189</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001811</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.016873</td>\n",
              "      <td>-0.024926</td>\n",
              "      <td>0.213149</td>\n",
              "      <td>-0.118423</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>V</td>\n",
              "      <td>4416</td>\n",
              "      <td>0.239207</td>\n",
              "      <td>0.374666</td>\n",
              "      <td>0.239594</td>\n",
              "      <td>1.328125</td>\n",
              "      <td>1.672421</td>\n",
              "      <td>-0.178941</td>\n",
              "      <td>2.093803</td>\n",
              "      <td>4.856699e-05</td>\n",
              "      <td>...</td>\n",
              "      <td>0.015048</td>\n",
              "      <td>0.999774</td>\n",
              "      <td>0.999774</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000226</td>\n",
              "      <td>1</td>\n",
              "      <td>0.236605</td>\n",
              "      <td>0.370385</td>\n",
              "      <td>0.239610</td>\n",
              "      <td>1.315020</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11 rows  25 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   asset_id  steps  total_return  annualized_return  annualized_volatility  \\\n",
              "9      AMGN   4416     -0.147091          -0.210266               0.305779   \n",
              "0      AMZN   4417      0.105566           0.160518               0.362771   \n",
              "8       CAT   4416     -0.143562          -0.205414               0.353585   \n",
              "6      CSCO   4416      0.137421           0.210515               0.235753   \n",
              "10      DIA   4408     -0.026654          -0.039360               0.195011   \n",
              "2       DIS   4370      0.006814           0.010234               0.306697   \n",
              "7       JPM   4416      0.149181           0.229131               0.314291   \n",
              "1        KO   4416      0.003830           0.005688               0.187825   \n",
              "5       NKE   4416     -0.320269          -0.436051               0.419048   \n",
              "4       SPY   4417     -0.016413          -0.024249               0.213125   \n",
              "3         V   4416      0.239207           0.374666               0.239594   \n",
              "\n",
              "      sharpe   sortino  max_drawdown    calmar    avg_reward  ...  \\\n",
              "9  -0.771992 -0.793974     -0.244893 -0.858605 -3.602853e-05  ...   \n",
              "0   0.410360  0.485925     -0.317797  0.505097  2.272081e-05  ...   \n",
              "8  -0.650291 -0.724398     -0.356979 -0.575422 -3.509363e-05  ...   \n",
              "6   0.810365  1.025087     -0.203259  1.035697  2.915844e-05  ...   \n",
              "10 -0.205914 -0.240573     -0.185307 -0.212403 -6.128715e-06  ...   \n",
              "2   0.033198  0.041051     -0.319800  0.032000  1.553978e-06  ...   \n",
              "7   0.656421  0.759357     -0.274844  0.833676  3.148771e-05  ...   \n",
              "1   0.030199  0.037589     -0.172204  0.033032  8.657020e-07  ...   \n",
              "5  -1.366887 -1.401690     -0.417277 -1.044993 -8.742245e-05  ...   \n",
              "4  -0.115181 -0.129597     -0.210802 -0.115033 -3.746645e-06  ...   \n",
              "3   1.328125  1.672421     -0.178941  2.093803  4.856699e-05  ...   \n",
              "\n",
              "    position_std  avg_abs_position  long_frac  short_frac  flat_frac  \\\n",
              "9       0.000000          1.000000   1.000000         0.0   0.000000   \n",
              "0       0.060084          0.996378   0.996378         0.0   0.003622   \n",
              "8       0.086132          0.992527   0.992527         0.0   0.007473   \n",
              "6       0.033634          0.998868   0.998868         0.0   0.001132   \n",
              "10      0.058242          0.996597   0.996597         0.0   0.003403   \n",
              "2       0.000000          1.000000   1.000000         0.0   0.000000   \n",
              "7       0.291829          0.906024   0.906024         0.0   0.093976   \n",
              "1       0.039787          0.998415   0.998415         0.0   0.001585   \n",
              "5       0.000000          1.000000   1.000000         0.0   0.000000   \n",
              "4       0.042524          0.998189   0.998189         0.0   0.001811   \n",
              "3       0.015048          0.999774   0.999774         0.0   0.000226   \n",
              "\n",
              "    trade_count  bh_total_return  bh_annualized_return  \\\n",
              "9             0        -0.146664             -0.209680   \n",
              "0             1         0.104821              0.159358   \n",
              "8             1        -0.130198             -0.186948   \n",
              "6             1         0.130017              0.198842   \n",
              "10            1        -0.031810             -0.046914   \n",
              "2             0         0.007318              0.010991   \n",
              "7             1         0.093133              0.141246   \n",
              "1             1         0.003404              0.005055   \n",
              "5             0        -0.319929             -0.435633   \n",
              "4             1        -0.016873             -0.024926   \n",
              "3             1         0.236605              0.370385   \n",
              "\n",
              "    bh_annualized_volatility  bh_sharpe  \n",
              "9                   0.305772  -0.769582  \n",
              "0                   0.362985   0.407364  \n",
              "8                   0.354228  -0.584258  \n",
              "6                   0.235809   0.769079  \n",
              "10                  0.195193  -0.246168  \n",
              "2                   0.306695   0.035642  \n",
              "7                   0.323585   0.408302  \n",
              "1                   0.187840   0.026841  \n",
              "5                   0.419046  -1.365125  \n",
              "4                   0.213149  -0.118423  \n",
              "3                   0.239610   1.315020  \n",
              "\n",
              "[11 rows x 25 columns]"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eval_cfg = EvalConfig(\n",
        "    annual_trading_days=252,\n",
        "    regular_hours_only=dataset_kwargs.get(\"regular_hours_only\", True),\n",
        "    timeframe=dataset_kwargs.get(\"timeframe\", \"15min\"),\n",
        ")\n",
        "\n",
        "results: List[Dict[str, float]] = []\n",
        "for idx, asset_id in enumerate(test_dataset.asset_ids, start=1):\n",
        "    print(f\"[{idx}/{len(test_dataset.asset_ids)}] Evaluating {asset_id}...\")\n",
        "    metrics = eval_asset(model, test_dataset, asset_id, eval_cfg)\n",
        "    if metrics:\n",
        "        results.append(metrics)\n",
        "\n",
        "if not results:\n",
        "    raise RuntimeError(\"No evaluation results produced.\")\n",
        "\n",
        "df = pd.DataFrame(results).sort_values(\"asset_id\")\n",
        "df.head(11)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "6a86b146",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>asset_id</th>\n",
              "      <th>total_return</th>\n",
              "      <th>bh_total_return</th>\n",
              "      <th>sharpe</th>\n",
              "      <th>bh_sharpe</th>\n",
              "      <th>ret_diff</th>\n",
              "      <th>sharpe_diff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>AMGN</td>\n",
              "      <td>-0.147091</td>\n",
              "      <td>-0.146664</td>\n",
              "      <td>-0.771992</td>\n",
              "      <td>-0.769582</td>\n",
              "      <td>-0.000427</td>\n",
              "      <td>-0.002410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AMZN</td>\n",
              "      <td>0.105566</td>\n",
              "      <td>0.104821</td>\n",
              "      <td>0.410360</td>\n",
              "      <td>0.407364</td>\n",
              "      <td>0.000745</td>\n",
              "      <td>0.002997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>CAT</td>\n",
              "      <td>-0.143562</td>\n",
              "      <td>-0.130198</td>\n",
              "      <td>-0.650291</td>\n",
              "      <td>-0.584258</td>\n",
              "      <td>-0.013364</td>\n",
              "      <td>-0.066033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>CSCO</td>\n",
              "      <td>0.137421</td>\n",
              "      <td>0.130017</td>\n",
              "      <td>0.810365</td>\n",
              "      <td>0.769079</td>\n",
              "      <td>0.007404</td>\n",
              "      <td>0.041286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>DIA</td>\n",
              "      <td>-0.026654</td>\n",
              "      <td>-0.031810</td>\n",
              "      <td>-0.205914</td>\n",
              "      <td>-0.246168</td>\n",
              "      <td>0.005156</td>\n",
              "      <td>0.040254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>DIS</td>\n",
              "      <td>0.006814</td>\n",
              "      <td>0.007318</td>\n",
              "      <td>0.033198</td>\n",
              "      <td>0.035642</td>\n",
              "      <td>-0.000504</td>\n",
              "      <td>-0.002445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>JPM</td>\n",
              "      <td>0.149181</td>\n",
              "      <td>0.093133</td>\n",
              "      <td>0.656421</td>\n",
              "      <td>0.408302</td>\n",
              "      <td>0.056048</td>\n",
              "      <td>0.248119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>KO</td>\n",
              "      <td>0.003830</td>\n",
              "      <td>0.003404</td>\n",
              "      <td>0.030199</td>\n",
              "      <td>0.026841</td>\n",
              "      <td>0.000426</td>\n",
              "      <td>0.003357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>NKE</td>\n",
              "      <td>-0.320269</td>\n",
              "      <td>-0.319929</td>\n",
              "      <td>-1.366887</td>\n",
              "      <td>-1.365125</td>\n",
              "      <td>-0.000340</td>\n",
              "      <td>-0.001763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SPY</td>\n",
              "      <td>-0.016413</td>\n",
              "      <td>-0.016873</td>\n",
              "      <td>-0.115181</td>\n",
              "      <td>-0.118423</td>\n",
              "      <td>0.000460</td>\n",
              "      <td>0.003241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>V</td>\n",
              "      <td>0.239207</td>\n",
              "      <td>0.236605</td>\n",
              "      <td>1.328125</td>\n",
              "      <td>1.315020</td>\n",
              "      <td>0.002602</td>\n",
              "      <td>0.013104</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   asset_id  total_return  bh_total_return    sharpe  bh_sharpe  ret_diff  \\\n",
              "9      AMGN     -0.147091        -0.146664 -0.771992  -0.769582 -0.000427   \n",
              "0      AMZN      0.105566         0.104821  0.410360   0.407364  0.000745   \n",
              "8       CAT     -0.143562        -0.130198 -0.650291  -0.584258 -0.013364   \n",
              "6      CSCO      0.137421         0.130017  0.810365   0.769079  0.007404   \n",
              "10      DIA     -0.026654        -0.031810 -0.205914  -0.246168  0.005156   \n",
              "2       DIS      0.006814         0.007318  0.033198   0.035642 -0.000504   \n",
              "7       JPM      0.149181         0.093133  0.656421   0.408302  0.056048   \n",
              "1        KO      0.003830         0.003404  0.030199   0.026841  0.000426   \n",
              "5       NKE     -0.320269        -0.319929 -1.366887  -1.365125 -0.000340   \n",
              "4       SPY     -0.016413        -0.016873 -0.115181  -0.118423  0.000460   \n",
              "3         V      0.239207         0.236605  1.328125   1.315020  0.002602   \n",
              "\n",
              "    sharpe_diff  \n",
              "9     -0.002410  \n",
              "0      0.002997  \n",
              "8     -0.066033  \n",
              "6      0.041286  \n",
              "10     0.040254  \n",
              "2     -0.002445  \n",
              "7      0.248119  \n",
              "1      0.003357  \n",
              "5     -0.001763  \n",
              "4      0.003241  \n",
              "3      0.013104  "
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ret_analysis = df[[\"asset_id\", \"total_return\", \"bh_total_return\", \"sharpe\", \"bh_sharpe\"]].copy()\n",
        "ret_analysis[\"ret_diff\"] = ret_analysis[\"total_return\"] - ret_analysis[\"bh_total_return\"]\n",
        "ret_analysis[\"sharpe_diff\"] = ret_analysis[\"sharpe\"] - ret_analysis[\"bh_sharpe\"]\n",
        "ret_analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "79f59c1e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved per-asset metrics to C:\\python\\koulu\\Gradu\\logs\\jepa6_ppo_final1_test_metrics.csv\n",
            "Saved summary to C:\\python\\koulu\\Gradu\\logs\\jepa6_ppo_final1_test_summary.csv\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>steps</th>\n",
              "      <th>total_return</th>\n",
              "      <th>annualized_return</th>\n",
              "      <th>annualized_volatility</th>\n",
              "      <th>sharpe</th>\n",
              "      <th>sortino</th>\n",
              "      <th>max_drawdown</th>\n",
              "      <th>calmar</th>\n",
              "      <th>avg_reward</th>\n",
              "      <th>reward_volatility</th>\n",
              "      <th>...</th>\n",
              "      <th>position_std</th>\n",
              "      <th>avg_abs_position</th>\n",
              "      <th>long_frac</th>\n",
              "      <th>short_frac</th>\n",
              "      <th>flat_frac</th>\n",
              "      <th>trade_count</th>\n",
              "      <th>bh_total_return</th>\n",
              "      <th>bh_annualized_return</th>\n",
              "      <th>bh_annualized_volatility</th>\n",
              "      <th>bh_sharpe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>4411.272727</td>\n",
              "      <td>-0.001088</td>\n",
              "      <td>0.006856</td>\n",
              "      <td>0.284862</td>\n",
              "      <td>0.014400</td>\n",
              "      <td>0.066473</td>\n",
              "      <td>-0.262009</td>\n",
              "      <td>0.156986</td>\n",
              "      <td>-3.096939e-06</td>\n",
              "      <td>0.003519</td>\n",
              "      <td>...</td>\n",
              "      <td>0.057025</td>\n",
              "      <td>0.989706</td>\n",
              "      <td>0.989706</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.010294</td>\n",
              "      <td>0.727273</td>\n",
              "      <td>-0.006380</td>\n",
              "      <td>-0.001657</td>\n",
              "      <td>0.285810</td>\n",
              "      <td>-0.011028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>median</th>\n",
              "      <td>4416.000000</td>\n",
              "      <td>0.003830</td>\n",
              "      <td>0.005688</td>\n",
              "      <td>0.305779</td>\n",
              "      <td>0.030199</td>\n",
              "      <td>0.037589</td>\n",
              "      <td>-0.244893</td>\n",
              "      <td>0.032000</td>\n",
              "      <td>8.657020e-07</td>\n",
              "      <td>0.003778</td>\n",
              "      <td>...</td>\n",
              "      <td>0.039787</td>\n",
              "      <td>0.998415</td>\n",
              "      <td>0.998415</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001585</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.003404</td>\n",
              "      <td>0.005055</td>\n",
              "      <td>0.305772</td>\n",
              "      <td>0.026841</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows  24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              steps  total_return  annualized_return  annualized_volatility  \\\n",
              "mean    4411.272727     -0.001088           0.006856               0.284862   \n",
              "median  4416.000000      0.003830           0.005688               0.305779   \n",
              "\n",
              "          sharpe   sortino  max_drawdown    calmar    avg_reward  \\\n",
              "mean    0.014400  0.066473     -0.262009  0.156986 -3.096939e-06   \n",
              "median  0.030199  0.037589     -0.244893  0.032000  8.657020e-07   \n",
              "\n",
              "        reward_volatility  ...  position_std  avg_abs_position  long_frac  \\\n",
              "mean             0.003519  ...      0.057025          0.989706   0.989706   \n",
              "median           0.003778  ...      0.039787          0.998415   0.998415   \n",
              "\n",
              "        short_frac  flat_frac  trade_count  bh_total_return  \\\n",
              "mean           0.0   0.010294     0.727273        -0.006380   \n",
              "median         0.0   0.001585     1.000000         0.003404   \n",
              "\n",
              "        bh_annualized_return  bh_annualized_volatility  bh_sharpe  \n",
              "mean               -0.001657                  0.285810  -0.011028  \n",
              "median              0.005055                  0.305772   0.026841  \n",
              "\n",
              "[2 rows x 24 columns]"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save outputs\n",
        "os.makedirs(PROJECT_ROOT / log_root, exist_ok=True)\n",
        "metrics_path = PROJECT_ROOT / log_root / f\"{model_name}_test_metrics.csv\"\n",
        "summary_path = PROJECT_ROOT / log_root / f\"{model_name}_test_summary.csv\"\n",
        "\n",
        "df.to_csv(metrics_path, index=False)\n",
        "summary = df.drop(columns=[\"asset_id\"]).agg([\"mean\", \"median\"])\n",
        "summary.to_csv(summary_path)\n",
        "\n",
        "print(f\"Saved per-asset metrics to {metrics_path}\")\n",
        "print(f\"Saved summary to {summary_path}\")\n",
        "summary\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".graduenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
