{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PPO Model Testing\n",
        "\n",
        "Evaluate a trained PPO+JEPA model using a single training config file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "da50f2c0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project root: C:\\python\\koulu\\Gradu\n"
          ]
        }
      ],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import io\n",
        "import zipfile\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "from typing import Dict, List\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "# Resolve project root robustly when notebook is launched from different cwd\n",
        "def find_project_root(start: Path) -> Path:\n",
        "    p = start.resolve()\n",
        "    for candidate in [p, *p.parents]:\n",
        "        if (candidate / \"src\").exists() and (candidate / \"configs\").exists():\n",
        "            return candidate\n",
        "    raise RuntimeError(\"Could not locate project root containing src/ and configs/\")\n",
        "\n",
        "PROJECT_ROOT = find_project_root(Path.cwd())\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(PROJECT_ROOT))\n",
        "if str(PROJECT_ROOT / \"src\") not in sys.path:\n",
        "    sys.path.insert(0, str(PROJECT_ROOT / \"src\"))\n",
        "\n",
        "from config.config_utils import load_json_config\n",
        "from Datasets.multi_asset_dataset import Dataset_Finance_MultiAsset\n",
        "from Training.sb3_jepa_ppo import JEPAAuxFeatureExtractor, PPOWithJEPA\n",
        "from models.jepa.jepa import JEPA\n",
        "from models.time_series.patchTransformer import PatchTSTEncoder\n",
        "\n",
        "print(f\"Project root: {PROJECT_ROOT}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "5a1c90c9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# -----------------------------\n",
        "# User parameters\n",
        "# -----------------------------\n",
        "# Config used for training this PPO model\n",
        "PPO_CONFIG_PATH = \"configs/ppo_jepa_final_1.json\"\n",
        "\n",
        "# Optional overrides (set to None to auto-resolve from config)\n",
        "PPO_CHECKPOINT_PATH = \"checkpoints/jepa6_ppo_final1/ppo_6400000_steps.zip\"\n",
        "# Optional: used only for asset_universe lookup, not for JEPA model weights\n",
        "JEPA_CHECKPOINT_PATH = \"checkpoints/jepa6_ppo_final1/jepa_step_300000.pt\"\n",
        "\n",
        "# If None, evaluate all assets available in validation split\n",
        "MAX_ASSETS = None\n",
        "\n",
        "# Deterministic policy during evaluation\n",
        "DETERMINISTIC = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "30ca8d85",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model name: jepa6_ppo_final1\n",
            "PPO checkpoint: C:\\python\\koulu\\Gradu\\checkpoints\\jepa6_ppo_final1\\ppo_6400000_steps.zip\n",
            "JEPA checkpoint: C:\\python\\koulu\\Gradu\\checkpoints\\jepa6_ppo_final1\\jepa_step_300000.pt\n",
            "Action mode: discrete_3\n",
            "Asset universe: None\n"
          ]
        }
      ],
      "source": [
        "def get_latest_ppo_checkpoint(checkpoint_dir: str) -> str | None:\n",
        "    if not os.path.isdir(checkpoint_dir):\n",
        "        return None\n",
        "    ckpts = []\n",
        "    for fname in os.listdir(checkpoint_dir):\n",
        "        if fname.startswith(\"ppo_\") and fname.endswith(\"_steps.zip\"):\n",
        "            ckpts.append(os.path.join(checkpoint_dir, fname))\n",
        "    if not ckpts:\n",
        "        return None\n",
        "    ckpts.sort(key=lambda p: os.path.getmtime(p))\n",
        "    return ckpts[-1]\n",
        "\n",
        "\n",
        "def load_tickers(path: str) -> list | None:\n",
        "    if not path or not os.path.exists(path):\n",
        "        return None\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        tickers = [line.strip() for line in f if line.strip()]\n",
        "    return tickers or None\n",
        "\n",
        "\n",
        "def load_asset_universe_from_checkpoint(path: str | None) -> list | None:\n",
        "    if not path or not os.path.exists(path):\n",
        "        return None\n",
        "    try:\n",
        "        checkpoint = torch.load(path, map_location=\"cpu\")\n",
        "    except Exception:\n",
        "        return None\n",
        "    asset_universe = checkpoint.get(\"asset_universe\")\n",
        "    return list(asset_universe) if asset_universe else None\n",
        "\n",
        "\n",
        "cfg = load_json_config(str(PROJECT_ROOT / PPO_CONFIG_PATH), \"\", str(PROJECT_ROOT / \"notebooks\" / \"ppo_model_test.ipynb\"))\n",
        "\n",
        "model_name = cfg[\"model_name\"]\n",
        "paths_cfg = cfg[\"paths\"]\n",
        "dataset_cfg = cfg[\"dataset\"]\n",
        "env_cfg = cfg[\"env\"]\n",
        "ppo_cfg = cfg[\"ppo\"]\n",
        "jepa_cfg = cfg[\"jepa_model\"]\n",
        "\n",
        "checkpoint_root = paths_cfg.get(\"checkpoint_root\", \"checkpoints\")\n",
        "log_root = paths_cfg.get(\"log_root\", \"logs\")\n",
        "ppo_checkpoint_dir = str(PROJECT_ROOT / checkpoint_root / model_name)\n",
        "\n",
        "if PPO_CHECKPOINT_PATH is None:\n",
        "    PPO_CHECKPOINT_PATH = get_latest_ppo_checkpoint(ppo_checkpoint_dir)\n",
        "if PPO_CHECKPOINT_PATH is None:\n",
        "    raise FileNotFoundError(f\"No PPO checkpoint found under {ppo_checkpoint_dir}\")\n",
        "if not os.path.isabs(PPO_CHECKPOINT_PATH):\n",
        "    PPO_CHECKPOINT_PATH = str(PROJECT_ROOT / PPO_CHECKPOINT_PATH)\n",
        "\n",
        "if JEPA_CHECKPOINT_PATH is None and paths_cfg.get(\"jepa_checkpoint_dir\"):\n",
        "    jepa_checkpoint_dir = paths_cfg[\"jepa_checkpoint_dir\"]\n",
        "    JEPA_CHECKPOINT_PATH = str(PROJECT_ROOT / jepa_checkpoint_dir / \"best.pt\")\n",
        "if JEPA_CHECKPOINT_PATH is not None and not os.path.isabs(JEPA_CHECKPOINT_PATH):\n",
        "    JEPA_CHECKPOINT_PATH = str(PROJECT_ROOT / JEPA_CHECKPOINT_PATH)\n",
        "\n",
        "ACTION_MODE = env_cfg.get(\"action_mode\", \"continuous\")\n",
        "ALLOW_SHORT = env_cfg.get(\"allow_short\", True)\n",
        "INCLUDE_WEALTH = env_cfg.get(\"include_wealth\", True)\n",
        "TRANSACTION_COST = float(\n",
        "    env_cfg.get(\"transaction_cost_end\", env_cfg.get(\"transaction_cost\", env_cfg.get(\"transaction_cost_start\", 0.0)))\n",
        ")\n",
        "\n",
        "print(\"Model name:\", model_name)\n",
        "print(\"PPO checkpoint:\", PPO_CHECKPOINT_PATH)\n",
        "print(\"JEPA checkpoint:\", JEPA_CHECKPOINT_PATH)\n",
        "print(\"Action mode:\", ACTION_MODE)\n",
        "print(\"Asset universe:\", paths_cfg[\"asset_universe_path\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "f6f03b44",
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class EvalConfig:\n",
        "    annual_trading_days: int = 252\n",
        "    regular_hours_only: bool = True\n",
        "    timeframe: str = \"15min\"\n",
        "    flat_threshold: float = 1e-3\n",
        "\n",
        "\n",
        "def _timeframe_to_minutes(timeframe: str) -> int:\n",
        "    tf = timeframe.strip().lower()\n",
        "    if tf.endswith(\"min\"):\n",
        "        return int(tf[:-3])\n",
        "    if tf.endswith(\"h\"):\n",
        "        return int(tf[:-1]) * 60\n",
        "    raise ValueError(f\"Unsupported timeframe: {timeframe}\")\n",
        "\n",
        "\n",
        "def annualization_factor(cfg: EvalConfig) -> float:\n",
        "    minutes_per_day = 390 if cfg.regular_hours_only else 24 * 60\n",
        "    minutes = _timeframe_to_minutes(cfg.timeframe)\n",
        "    bars_per_day = max(1, minutes_per_day // minutes)\n",
        "    return bars_per_day * cfg.annual_trading_days\n",
        "\n",
        "\n",
        "def action_to_weight(action) -> float:\n",
        "    if ACTION_MODE == \"discrete_3\":\n",
        "        discrete_actions = np.array([-1.0, 0.0, 1.0], dtype=np.float32)\n",
        "        idx = int(np.asarray(action).reshape(-1)[0])\n",
        "        idx = int(np.clip(idx, 0, len(discrete_actions) - 1))\n",
        "        w_t = float(discrete_actions[idx])\n",
        "    else:\n",
        "        w_t = float(np.clip(np.asarray(action).reshape(-1)[0], -1.0, 1.0))\n",
        "    if not ALLOW_SHORT:\n",
        "        w_t = max(0.0, w_t)\n",
        "    return w_t\n",
        "\n",
        "\n",
        "def compute_drawdown(equity: np.ndarray) -> float:\n",
        "    if equity.size == 0:\n",
        "        return float(\"nan\")\n",
        "    peak = np.maximum.accumulate(equity)\n",
        "    drawdown = (equity - peak) / peak\n",
        "    return float(np.min(drawdown))\n",
        "\n",
        "\n",
        "def safe_sharpe(mean: float, std: float, ann_factor: float) -> float:\n",
        "    if std <= 0 or np.isnan(std):\n",
        "        return float(\"nan\")\n",
        "    return float(mean / std * np.sqrt(ann_factor))\n",
        "\n",
        "\n",
        "def build_jepa_model(device: str, num_assets: int) -> JEPA:\n",
        "    encoder_num_assets = num_assets if jepa_cfg.get(\"use_asset_embeddings\", True) else None\n",
        "\n",
        "    jepa_context_encoder = PatchTSTEncoder(\n",
        "        patch_len=jepa_cfg[\"patch_len\"],\n",
        "        d_model=jepa_cfg[\"d_model\"],\n",
        "        n_features=jepa_cfg[\"n_features\"],\n",
        "        n_time_features=jepa_cfg[\"n_time_features\"],\n",
        "        nhead=jepa_cfg[\"nhead\"],\n",
        "        num_layers=jepa_cfg[\"num_layers\"],\n",
        "        dim_ff=jepa_cfg[\"dim_ff\"],\n",
        "        dropout=jepa_cfg[\"dropout\"],\n",
        "        add_cls=jepa_cfg.get(\"add_cls\", True),\n",
        "        pooling=jepa_cfg[\"pooling\"],\n",
        "        pred_len=jepa_cfg[\"pred_len\"],\n",
        "        num_assets=encoder_num_assets,\n",
        "    )\n",
        "    jepa_target_encoder = copy.deepcopy(jepa_context_encoder)\n",
        "\n",
        "    jepa_model = JEPA(\n",
        "        jepa_context_encoder,\n",
        "        jepa_target_encoder,\n",
        "        d_model=jepa_cfg[\"d_model\"],\n",
        "        ema_tau_min=jepa_cfg[\"ema_tau_min\"],\n",
        "        ema_tau_max=jepa_cfg[\"ema_tau_max\"],\n",
        "    )\n",
        "\n",
        "    for param in jepa_model.parameters():\n",
        "        param.requires_grad = False\n",
        "    jepa_model.eval()\n",
        "    return jepa_model.to(device)\n",
        "\n",
        "\n",
        "def extract_jepa_state_dict_from_ppo_zip(model_path: str) -> Dict[str, torch.Tensor]:\n",
        "    with zipfile.ZipFile(model_path, \"r\") as zf:\n",
        "        with zf.open(\"policy.pth\", \"r\") as f:\n",
        "            policy_state = torch.load(io.BytesIO(f.read()), map_location=\"cpu\")\n",
        "\n",
        "    prefix = \"features_extractor.jepa_model.\"\n",
        "    jepa_state = {}\n",
        "    for k, v in policy_state.items():\n",
        "        if k.startswith(prefix):\n",
        "            jepa_state[k[len(prefix):]] = v\n",
        "    if not jepa_state:\n",
        "        raise RuntimeError(\"No JEPA weights found in PPO zip policy state.\")\n",
        "    return jepa_state\n",
        "\n",
        "\n",
        "def load_ppo_model(model_path: str, device: str, policy_kwargs: Dict) -> PPOWithJEPA:\n",
        "    try:\n",
        "        print(\"Loading PPO (and embedded JEPA) directly from PPO zip...\")\n",
        "        return PPOWithJEPA.load(model_path, device=device)\n",
        "    except Exception as exc:\n",
        "        print(f\"Primary PPO load failed ({exc}); retrying with custom policy_kwargs and JEPA weights from PPO zip.\")\n",
        "\n",
        "        fx_kwargs = policy_kwargs.get(\"features_extractor_kwargs\", {})\n",
        "        jepa_model = fx_kwargs.get(\"jepa_model\")\n",
        "        if jepa_model is None:\n",
        "            raise RuntimeError(\"Fallback requires policy_kwargs.features_extractor_kwargs.jepa_model\")\n",
        "\n",
        "        jepa_state = extract_jepa_state_dict_from_ppo_zip(model_path)\n",
        "        missing, unexpected = jepa_model.load_state_dict(jepa_state, strict=False)\n",
        "        if missing:\n",
        "            print(f\"Missing keys when loading JEPA from PPO zip: {missing}\")\n",
        "        if unexpected:\n",
        "            print(f\"Unexpected keys when loading JEPA from PPO zip: {unexpected}\")\n",
        "\n",
        "        return PPOWithJEPA.load(model_path, device=device, custom_objects={\"policy_kwargs\": policy_kwargs})\n",
        "\n",
        "\n",
        "def eval_asset(model: PPOWithJEPA, dataset: Dataset_Finance_MultiAsset, asset_id: str, cfg: EvalConfig) -> Dict[str, float]:\n",
        "    asset_idx = dataset.asset_id_to_idx.get(asset_id, -1)\n",
        "    X = dataset.data_x[asset_id]\n",
        "    dates = dataset.dates[asset_id]\n",
        "    ohlcv = dataset.ohlcv[asset_id]\n",
        "\n",
        "    seq_len = dataset.seq_len\n",
        "    pred_len = dataset.pred_len\n",
        "    n_steps = len(X) - seq_len - pred_len\n",
        "    if n_steps <= 0:\n",
        "        return {}\n",
        "\n",
        "    w_prev = 0.0\n",
        "    wealth = 1.0\n",
        "    rewards, asset_returns, positions, turnovers, equity = [], [], [], [], []\n",
        "\n",
        "    for cursor in range(n_steps):\n",
        "        x_context = X[cursor : cursor + seq_len].astype(np.float32)\n",
        "        t_context = dates[cursor : cursor + seq_len].astype(np.float32)\n",
        "        x_target = X[cursor + seq_len : cursor + seq_len + pred_len].astype(np.float32)\n",
        "        t_target = dates[cursor + seq_len : cursor + seq_len + pred_len].astype(np.float32)\n",
        "\n",
        "        obs = {\n",
        "            \"x_context\": x_context,\n",
        "            \"t_context\": t_context,\n",
        "            \"x_target\": x_target,\n",
        "            \"t_target\": t_target,\n",
        "            \"asset_id\": np.int64(asset_idx),\n",
        "            \"w_prev\": np.array([w_prev], dtype=np.float32),\n",
        "        }\n",
        "        if INCLUDE_WEALTH:\n",
        "            obs[\"wealth_feats\"] = np.array([np.log(wealth)], dtype=np.float32)\n",
        "\n",
        "        action, _ = model.predict(obs, deterministic=DETERMINISTIC)\n",
        "        w_t = action_to_weight(action)\n",
        "\n",
        "        close_t = float(ohlcv[cursor + seq_len - 1][3])\n",
        "        close_tp1 = float(ohlcv[cursor + seq_len][3])\n",
        "        r_tp1 = float(np.log(close_tp1 / close_t))\n",
        "\n",
        "        turnover = abs(w_t - w_prev)\n",
        "        cost = min(TRANSACTION_COST * turnover, 0.99)\n",
        "        reward = w_t * r_tp1 + float(np.log1p(-cost))\n",
        "        wealth *= float(np.exp(reward))\n",
        "\n",
        "        rewards.append(reward)\n",
        "        asset_returns.append(r_tp1)\n",
        "        positions.append(w_t)\n",
        "        turnovers.append(turnover)\n",
        "        equity.append(wealth)\n",
        "        w_prev = w_t\n",
        "\n",
        "    rewards = np.asarray(rewards, dtype=np.float64)\n",
        "    asset_returns = np.asarray(asset_returns, dtype=np.float64)\n",
        "    positions = np.asarray(positions, dtype=np.float64)\n",
        "    turnovers = np.asarray(turnovers, dtype=np.float64)\n",
        "    equity = np.asarray(equity, dtype=np.float64)\n",
        "\n",
        "    ann_factor = annualization_factor(cfg)\n",
        "    mean_reward = float(np.mean(rewards)) if rewards.size else float(\"nan\")\n",
        "    std_reward = float(np.std(rewards, ddof=1)) if rewards.size > 1 else float(\"nan\")\n",
        "\n",
        "    total_log_return = float(np.sum(rewards)) if rewards.size else float(\"nan\")\n",
        "    total_return = float(np.exp(total_log_return) - 1.0) if rewards.size else float(\"nan\")\n",
        "    annualized_return = float(np.exp(mean_reward * ann_factor) - 1.0) if rewards.size else float(\"nan\")\n",
        "    annualized_vol = float(std_reward * np.sqrt(ann_factor)) if rewards.size > 1 else float(\"nan\")\n",
        "    sharpe = safe_sharpe(mean_reward, std_reward, ann_factor)\n",
        "\n",
        "    downside = rewards[rewards < 0]\n",
        "    downside_std = float(np.std(downside, ddof=1)) if downside.size > 1 else float(\"nan\")\n",
        "    sortino = safe_sharpe(mean_reward, downside_std, ann_factor)\n",
        "\n",
        "    max_drawdown = compute_drawdown(equity)\n",
        "    calmar = float(annualized_return / abs(max_drawdown)) if max_drawdown < 0 else float(\"nan\")\n",
        "\n",
        "    win_rate = float(np.mean(rewards > 0)) if rewards.size else float(\"nan\")\n",
        "    avg_turnover = float(np.mean(turnovers)) if turnovers.size else float(\"nan\")\n",
        "    total_turnover = float(np.sum(turnovers)) if turnovers.size else float(\"nan\")\n",
        "    avg_position = float(np.mean(positions)) if positions.size else float(\"nan\")\n",
        "    pos_std = float(np.std(positions, ddof=1)) if positions.size > 1 else float(\"nan\")\n",
        "    abs_pos = float(np.mean(np.abs(positions))) if positions.size else float(\"nan\")\n",
        "\n",
        "    flat_mask = np.abs(positions) <= cfg.flat_threshold\n",
        "    long_mask = positions > cfg.flat_threshold\n",
        "    short_mask = positions < -cfg.flat_threshold\n",
        "    flat_frac = float(np.mean(flat_mask)) if positions.size else float(\"nan\")\n",
        "    long_frac = float(np.mean(long_mask)) if positions.size else float(\"nan\")\n",
        "    short_frac = float(np.mean(short_mask)) if positions.size else float(\"nan\")\n",
        "\n",
        "    trade_count = int(np.sum(np.abs(np.diff(positions)) > cfg.flat_threshold)) if positions.size > 1 else 0\n",
        "\n",
        "    bh_mean = float(np.mean(asset_returns)) if asset_returns.size else float(\"nan\")\n",
        "    bh_std = float(np.std(asset_returns, ddof=1)) if asset_returns.size > 1 else float(\"nan\")\n",
        "    bh_total_return = float(np.exp(np.sum(asset_returns)) - 1.0) if asset_returns.size else float(\"nan\")\n",
        "    bh_annualized_return = float(np.exp(bh_mean * ann_factor) - 1.0) if asset_returns.size else float(\"nan\")\n",
        "    bh_annualized_vol = float(bh_std * np.sqrt(ann_factor)) if asset_returns.size > 1 else float(\"nan\")\n",
        "    bh_sharpe = safe_sharpe(bh_mean, bh_std, ann_factor)\n",
        "\n",
        "    return {\n",
        "        \"asset_id\": asset_id,\n",
        "        \"steps\": int(n_steps),\n",
        "        \"total_return\": total_return,\n",
        "        \"annualized_return\": annualized_return,\n",
        "        \"annualized_volatility\": annualized_vol,\n",
        "        \"sharpe\": sharpe,\n",
        "        \"sortino\": sortino,\n",
        "        \"max_drawdown\": max_drawdown,\n",
        "        \"calmar\": calmar,\n",
        "        \"avg_reward\": mean_reward,\n",
        "        \"reward_volatility\": std_reward,\n",
        "        \"win_rate\": win_rate,\n",
        "        \"avg_turnover\": avg_turnover,\n",
        "        \"total_turnover\": total_turnover,\n",
        "        \"avg_position\": avg_position,\n",
        "        \"position_std\": pos_std,\n",
        "        \"avg_abs_position\": abs_pos,\n",
        "        \"long_frac\": long_frac,\n",
        "        \"short_frac\": short_frac,\n",
        "        \"flat_frac\": flat_frac,\n",
        "        \"trade_count\": trade_count,\n",
        "        \"bh_total_return\": bh_total_return,\n",
        "        \"bh_annualized_return\": bh_annualized_return,\n",
        "        \"bh_annualized_volatility\": bh_annualized_vol,\n",
        "        \"bh_sharpe\": bh_sharpe,\n",
        "    }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "bf9ef6fd",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 11 tickers from C:\\python\\koulu\\Gradu\\configs\\assets\\tickers1.txt\n",
            "tickers: ['AMZN', 'KO', 'DIS', 'V', 'SPY', 'NKE', 'CSCO', 'JPM', 'CAT', 'AMGN', 'DIA']\n",
            "Loading evaluation dataset...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ollik\\AppData\\Local\\Temp\\ipykernel_51592\\405421948.py:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(path, map_location=\"cpu\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Dataset_Finance_MultiAsset] Global date splits: train_end=2024-08-01 15:15:00+00:00 val_end=2025-04-29 16:30:00+00:00 n_dates=33178 n_train=23224 n_val=4978 n_test=4976\n",
            "Assets to evaluate: 11\n"
          ]
        }
      ],
      "source": [
        "def _resolve_project_path(path_value: str | None) -> str | None:\n",
        "    if path_value is None:\n",
        "        return None\n",
        "    p = Path(path_value)\n",
        "    if p.is_absolute():\n",
        "        return str(p)\n",
        "    return str((PROJECT_ROOT / p).resolve())\n",
        "\n",
        "\n",
        "\n",
        "ticker_list_path = paths_cfg.get(\"ticker_list_path\")\n",
        "if not ticker_list_path:\n",
        "    raise ValueError(\"Config is missing paths.ticker_list_path\")\n",
        "\n",
        "# Build dataset from the same config used in training\n",
        "tickers_path = PROJECT_ROOT / ticker_list_path\n",
        "tickers = load_tickers(str(tickers_path))\n",
        "if not tickers:\n",
        "    raise RuntimeError(f\"No tickers loaded from {tickers_path}\")\n",
        "\n",
        "dataset_kwargs = {\n",
        "    \"root_path\": _resolve_project_path(dataset_cfg[\"root_path\"]),\n",
        "    \"data_path\": dataset_cfg[\"data_path\"],\n",
        "    \"start_date\": dataset_cfg.get(\"start_date\"),\n",
        "    \"split\": \"val\",\n",
        "    \"size\": [dataset_cfg[\"context_len\"], dataset_cfg[\"target_len\"]],\n",
        "    \"use_time_features\": dataset_cfg.get(\"use_time_features\", True),\n",
        "    \"rolling_window\": dataset_cfg[\"rolling_window\"],\n",
        "    \"train_split\": dataset_cfg[\"train_split\"],\n",
        "    \"test_split\": dataset_cfg[\"test_split\"],\n",
        "    \"regular_hours_only\": dataset_cfg.get(\"regular_hours_only\", True),\n",
        "    \"timeframe\": dataset_cfg.get(\"timeframe\", \"15min\"),\n",
        "    \"tickers\": tickers,\n",
        "}\n",
        "\n",
        "asset_universe = load_asset_universe_from_checkpoint(JEPA_CHECKPOINT_PATH)\n",
        "if asset_universe:\n",
        "    dataset_kwargs[\"asset_universe\"] = asset_universe\n",
        "\n",
        "dataset_kwargs[\"tickers\"] = tickers\n",
        "print(f\"Loaded {len(tickers)} tickers from {tickers_path}\")\n",
        "print(f\"tickers: {tickers}\")\n",
        "\n",
        "print(\"Loading evaluation dataset...\")\n",
        "test_dataset = Dataset_Finance_MultiAsset(**dataset_kwargs)\n",
        "if not test_dataset.asset_ids:\n",
        "    raise RuntimeError(\"No assets found in the validation dataset.\")\n",
        "\n",
        "if MAX_ASSETS is not None:\n",
        "    test_dataset.asset_ids = test_dataset.asset_ids[: int(MAX_ASSETS)]\n",
        "\n",
        "print(f\"Assets to evaluate: {len(test_dataset.asset_ids)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "fba4965e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading JEPA model...\n",
            "Loading PPO model from C:\\python\\koulu\\Gradu\\checkpoints\\jepa6_ppo_final1\\ppo_6400000_steps.zip...\n",
            "Loading PPO (and embedded JEPA) directly from PPO zip...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ollik\\miniconda3\\envs\\.graduenv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "MultiInputActorCriticPolicy(\n",
              "  (features_extractor): JEPAAuxFeatureExtractor(\n",
              "    (jepa_model): JEPA(\n",
              "      (context_enc): PatchTSTEncoder(\n",
              "        (proj_price): Linear(in_features=72, out_features=192, bias=True)\n",
              "        (proj_time): Linear(in_features=32, out_features=192, bias=True)\n",
              "        (posenc): PositionalEncoding()\n",
              "        (encoder): TransformerEncoder(\n",
              "          (layers): ModuleList(\n",
              "            (0-3): 4 x TransformerEncoderLayer(\n",
              "              (self_attn): MultiheadAttention(\n",
              "                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
              "              )\n",
              "              (linear1): Linear(in_features=192, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "              (linear2): Linear(in_features=768, out_features=192, bias=True)\n",
              "              (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "              (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout1): Dropout(p=0.0, inplace=False)\n",
              "              (dropout2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (final_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "        (head): Identity()\n",
              "      )\n",
              "      (target_enc): PatchTSTEncoder(\n",
              "        (proj_price): Linear(in_features=72, out_features=192, bias=True)\n",
              "        (proj_time): Linear(in_features=32, out_features=192, bias=True)\n",
              "        (posenc): PositionalEncoding()\n",
              "        (encoder): TransformerEncoder(\n",
              "          (layers): ModuleList(\n",
              "            (0-3): 4 x TransformerEncoderLayer(\n",
              "              (self_attn): MultiheadAttention(\n",
              "                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
              "              )\n",
              "              (linear1): Linear(in_features=192, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "              (linear2): Linear(in_features=768, out_features=192, bias=True)\n",
              "              (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "              (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout1): Dropout(p=0.0, inplace=False)\n",
              "              (dropout2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (final_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "        (head): Identity()\n",
              "      )\n",
              "      (predictor): Sequential(\n",
              "        (0): Linear(in_features=192, out_features=384, bias=True)\n",
              "        (1): GELU(approximate='none')\n",
              "        (2): Linear(in_features=384, out_features=384, bias=True)\n",
              "        (3): GELU(approximate='none')\n",
              "        (4): Linear(in_features=384, out_features=192, bias=True)\n",
              "        (5): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pi_features_extractor): JEPAAuxFeatureExtractor(\n",
              "    (jepa_model): JEPA(\n",
              "      (context_enc): PatchTSTEncoder(\n",
              "        (proj_price): Linear(in_features=72, out_features=192, bias=True)\n",
              "        (proj_time): Linear(in_features=32, out_features=192, bias=True)\n",
              "        (posenc): PositionalEncoding()\n",
              "        (encoder): TransformerEncoder(\n",
              "          (layers): ModuleList(\n",
              "            (0-3): 4 x TransformerEncoderLayer(\n",
              "              (self_attn): MultiheadAttention(\n",
              "                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
              "              )\n",
              "              (linear1): Linear(in_features=192, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "              (linear2): Linear(in_features=768, out_features=192, bias=True)\n",
              "              (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "              (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout1): Dropout(p=0.0, inplace=False)\n",
              "              (dropout2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (final_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "        (head): Identity()\n",
              "      )\n",
              "      (target_enc): PatchTSTEncoder(\n",
              "        (proj_price): Linear(in_features=72, out_features=192, bias=True)\n",
              "        (proj_time): Linear(in_features=32, out_features=192, bias=True)\n",
              "        (posenc): PositionalEncoding()\n",
              "        (encoder): TransformerEncoder(\n",
              "          (layers): ModuleList(\n",
              "            (0-3): 4 x TransformerEncoderLayer(\n",
              "              (self_attn): MultiheadAttention(\n",
              "                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
              "              )\n",
              "              (linear1): Linear(in_features=192, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "              (linear2): Linear(in_features=768, out_features=192, bias=True)\n",
              "              (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "              (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout1): Dropout(p=0.0, inplace=False)\n",
              "              (dropout2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (final_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "        (head): Identity()\n",
              "      )\n",
              "      (predictor): Sequential(\n",
              "        (0): Linear(in_features=192, out_features=384, bias=True)\n",
              "        (1): GELU(approximate='none')\n",
              "        (2): Linear(in_features=384, out_features=384, bias=True)\n",
              "        (3): GELU(approximate='none')\n",
              "        (4): Linear(in_features=384, out_features=192, bias=True)\n",
              "        (5): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (vf_features_extractor): JEPAAuxFeatureExtractor(\n",
              "    (jepa_model): JEPA(\n",
              "      (context_enc): PatchTSTEncoder(\n",
              "        (proj_price): Linear(in_features=72, out_features=192, bias=True)\n",
              "        (proj_time): Linear(in_features=32, out_features=192, bias=True)\n",
              "        (posenc): PositionalEncoding()\n",
              "        (encoder): TransformerEncoder(\n",
              "          (layers): ModuleList(\n",
              "            (0-3): 4 x TransformerEncoderLayer(\n",
              "              (self_attn): MultiheadAttention(\n",
              "                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
              "              )\n",
              "              (linear1): Linear(in_features=192, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "              (linear2): Linear(in_features=768, out_features=192, bias=True)\n",
              "              (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "              (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout1): Dropout(p=0.0, inplace=False)\n",
              "              (dropout2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (final_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "        (head): Identity()\n",
              "      )\n",
              "      (target_enc): PatchTSTEncoder(\n",
              "        (proj_price): Linear(in_features=72, out_features=192, bias=True)\n",
              "        (proj_time): Linear(in_features=32, out_features=192, bias=True)\n",
              "        (posenc): PositionalEncoding()\n",
              "        (encoder): TransformerEncoder(\n",
              "          (layers): ModuleList(\n",
              "            (0-3): 4 x TransformerEncoderLayer(\n",
              "              (self_attn): MultiheadAttention(\n",
              "                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
              "              )\n",
              "              (linear1): Linear(in_features=192, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "              (linear2): Linear(in_features=768, out_features=192, bias=True)\n",
              "              (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "              (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout1): Dropout(p=0.0, inplace=False)\n",
              "              (dropout2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (final_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "        (head): Identity()\n",
              "      )\n",
              "      (predictor): Sequential(\n",
              "        (0): Linear(in_features=192, out_features=384, bias=True)\n",
              "        (1): GELU(approximate='none')\n",
              "        (2): Linear(in_features=384, out_features=384, bias=True)\n",
              "        (3): GELU(approximate='none')\n",
              "        (4): Linear(in_features=384, out_features=192, bias=True)\n",
              "        (5): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (mlp_extractor): MlpExtractor(\n",
              "    (policy_net): Sequential(\n",
              "      (0): Linear(in_features=227, out_features=256, bias=True)\n",
              "      (1): Tanh()\n",
              "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (3): Tanh()\n",
              "    )\n",
              "    (value_net): Sequential(\n",
              "      (0): Linear(in_features=227, out_features=256, bias=True)\n",
              "      (1): Tanh()\n",
              "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (3): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (action_net): Linear(in_features=256, out_features=3, bias=True)\n",
              "  (value_net): Linear(in_features=256, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "num_asset_ids = int(getattr(test_dataset, \"num_asset_ids\", len(test_dataset.asset_ids)))\n",
        "\n",
        "print(\"Loading JEPA model...\")\n",
        "jepa_model = build_jepa_model(device, num_assets=num_asset_ids)\n",
        "\n",
        "policy_kwargs = dict(\n",
        "    features_extractor_class=JEPAAuxFeatureExtractor,\n",
        "    features_extractor_kwargs=dict(\n",
        "        jepa_model=jepa_model,\n",
        "        embedding_dim=jepa_cfg[\"d_model\"],\n",
        "        patch_len=jepa_cfg[\"patch_len\"],\n",
        "        patch_stride=jepa_cfg[\"patch_stride\"],\n",
        "        use_obs_targets=True,\n",
        "        target_len=test_dataset.pred_len,\n",
        "    ),\n",
        "    net_arch=dict(pi=[256, 256], vf=[256, 256]),\n",
        ")\n",
        "\n",
        "print(f\"Loading PPO model from {PPO_CHECKPOINT_PATH}...\")\n",
        "model = load_ppo_model(PPO_CHECKPOINT_PATH, device=device, policy_kwargs=policy_kwargs)\n",
        "model.policy.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "3c85627d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/11] Evaluating AMZN...\n",
            "[2/11] Evaluating KO...\n",
            "[3/11] Evaluating DIS...\n",
            "[4/11] Evaluating V...\n",
            "[5/11] Evaluating SPY...\n",
            "[6/11] Evaluating NKE...\n",
            "[7/11] Evaluating CSCO...\n",
            "[8/11] Evaluating JPM...\n",
            "[9/11] Evaluating CAT...\n",
            "[10/11] Evaluating AMGN...\n",
            "[11/11] Evaluating DIA...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>asset_id</th>\n",
              "      <th>steps</th>\n",
              "      <th>total_return</th>\n",
              "      <th>annualized_return</th>\n",
              "      <th>annualized_volatility</th>\n",
              "      <th>sharpe</th>\n",
              "      <th>sortino</th>\n",
              "      <th>max_drawdown</th>\n",
              "      <th>calmar</th>\n",
              "      <th>avg_reward</th>\n",
              "      <th>...</th>\n",
              "      <th>position_std</th>\n",
              "      <th>avg_abs_position</th>\n",
              "      <th>long_frac</th>\n",
              "      <th>short_frac</th>\n",
              "      <th>flat_frac</th>\n",
              "      <th>trade_count</th>\n",
              "      <th>bh_total_return</th>\n",
              "      <th>bh_annualized_return</th>\n",
              "      <th>bh_annualized_volatility</th>\n",
              "      <th>bh_sharpe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>AMGN</td>\n",
              "      <td>4416</td>\n",
              "      <td>0.274588</td>\n",
              "      <td>0.433300</td>\n",
              "      <td>0.302639</td>\n",
              "      <td>1.189466</td>\n",
              "      <td>1.791269</td>\n",
              "      <td>-0.176269</td>\n",
              "      <td>2.458176</td>\n",
              "      <td>0.000055</td>\n",
              "      <td>...</td>\n",
              "      <td>0.913318</td>\n",
              "      <td>0.969203</td>\n",
              "      <td>0.668478</td>\n",
              "      <td>0.300725</td>\n",
              "      <td>0.030797</td>\n",
              "      <td>75</td>\n",
              "      <td>-0.146664</td>\n",
              "      <td>-0.209680</td>\n",
              "      <td>0.305772</td>\n",
              "      <td>-0.769582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AMZN</td>\n",
              "      <td>4417</td>\n",
              "      <td>0.782635</td>\n",
              "      <td>1.357306</td>\n",
              "      <td>0.354293</td>\n",
              "      <td>2.420365</td>\n",
              "      <td>3.609958</td>\n",
              "      <td>-0.265170</td>\n",
              "      <td>5.118628</td>\n",
              "      <td>0.000131</td>\n",
              "      <td>...</td>\n",
              "      <td>0.966057</td>\n",
              "      <td>0.943853</td>\n",
              "      <td>0.523885</td>\n",
              "      <td>0.419968</td>\n",
              "      <td>0.056147</td>\n",
              "      <td>94</td>\n",
              "      <td>0.104821</td>\n",
              "      <td>0.159358</td>\n",
              "      <td>0.362985</td>\n",
              "      <td>0.407364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>CAT</td>\n",
              "      <td>4416</td>\n",
              "      <td>-0.165245</td>\n",
              "      <td>-0.235078</td>\n",
              "      <td>0.351591</td>\n",
              "      <td>-0.762195</td>\n",
              "      <td>-0.845701</td>\n",
              "      <td>-0.262493</td>\n",
              "      <td>-0.895560</td>\n",
              "      <td>-0.000041</td>\n",
              "      <td>...</td>\n",
              "      <td>0.830052</td>\n",
              "      <td>0.970335</td>\n",
              "      <td>0.750453</td>\n",
              "      <td>0.219882</td>\n",
              "      <td>0.029665</td>\n",
              "      <td>55</td>\n",
              "      <td>-0.130198</td>\n",
              "      <td>-0.186948</td>\n",
              "      <td>0.354228</td>\n",
              "      <td>-0.584258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>CSCO</td>\n",
              "      <td>4416</td>\n",
              "      <td>0.240335</td>\n",
              "      <td>0.376522</td>\n",
              "      <td>0.229905</td>\n",
              "      <td>1.389965</td>\n",
              "      <td>1.884579</td>\n",
              "      <td>-0.161022</td>\n",
              "      <td>2.338323</td>\n",
              "      <td>0.000049</td>\n",
              "      <td>...</td>\n",
              "      <td>0.905360</td>\n",
              "      <td>0.964221</td>\n",
              "      <td>0.672328</td>\n",
              "      <td>0.291893</td>\n",
              "      <td>0.035779</td>\n",
              "      <td>75</td>\n",
              "      <td>0.130017</td>\n",
              "      <td>0.198842</td>\n",
              "      <td>0.235809</td>\n",
              "      <td>0.769079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>DIA</td>\n",
              "      <td>4408</td>\n",
              "      <td>-0.033127</td>\n",
              "      <td>-0.048841</td>\n",
              "      <td>0.184774</td>\n",
              "      <td>-0.271000</td>\n",
              "      <td>-0.303610</td>\n",
              "      <td>-0.186009</td>\n",
              "      <td>-0.262571</td>\n",
              "      <td>-0.000008</td>\n",
              "      <td>...</td>\n",
              "      <td>0.919096</td>\n",
              "      <td>0.845735</td>\n",
              "      <td>0.405626</td>\n",
              "      <td>0.440109</td>\n",
              "      <td>0.154265</td>\n",
              "      <td>129</td>\n",
              "      <td>-0.031810</td>\n",
              "      <td>-0.046914</td>\n",
              "      <td>0.195193</td>\n",
              "      <td>-0.246168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>DIS</td>\n",
              "      <td>4370</td>\n",
              "      <td>-0.078248</td>\n",
              "      <td>-0.114996</td>\n",
              "      <td>0.299184</td>\n",
              "      <td>-0.408323</td>\n",
              "      <td>-0.435266</td>\n",
              "      <td>-0.252933</td>\n",
              "      <td>-0.454651</td>\n",
              "      <td>-0.000019</td>\n",
              "      <td>...</td>\n",
              "      <td>0.906125</td>\n",
              "      <td>0.943936</td>\n",
              "      <td>0.647368</td>\n",
              "      <td>0.296568</td>\n",
              "      <td>0.056064</td>\n",
              "      <td>97</td>\n",
              "      <td>0.007318</td>\n",
              "      <td>0.010991</td>\n",
              "      <td>0.306695</td>\n",
              "      <td>0.035642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>JPM</td>\n",
              "      <td>4416</td>\n",
              "      <td>-0.116273</td>\n",
              "      <td>-0.167561</td>\n",
              "      <td>0.316859</td>\n",
              "      <td>-0.578790</td>\n",
              "      <td>-0.599890</td>\n",
              "      <td>-0.253414</td>\n",
              "      <td>-0.661212</td>\n",
              "      <td>-0.000028</td>\n",
              "      <td>...</td>\n",
              "      <td>0.949751</td>\n",
              "      <td>0.927310</td>\n",
              "      <td>0.543478</td>\n",
              "      <td>0.383832</td>\n",
              "      <td>0.072690</td>\n",
              "      <td>111</td>\n",
              "      <td>0.093133</td>\n",
              "      <td>0.141246</td>\n",
              "      <td>0.323585</td>\n",
              "      <td>0.408302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>KO</td>\n",
              "      <td>4416</td>\n",
              "      <td>0.111965</td>\n",
              "      <td>0.170537</td>\n",
              "      <td>0.183128</td>\n",
              "      <td>0.859851</td>\n",
              "      <td>1.116355</td>\n",
              "      <td>-0.128254</td>\n",
              "      <td>1.329678</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>...</td>\n",
              "      <td>0.873206</td>\n",
              "      <td>0.967844</td>\n",
              "      <td>0.710598</td>\n",
              "      <td>0.257246</td>\n",
              "      <td>0.032156</td>\n",
              "      <td>45</td>\n",
              "      <td>0.003404</td>\n",
              "      <td>0.005055</td>\n",
              "      <td>0.187840</td>\n",
              "      <td>0.026841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>NKE</td>\n",
              "      <td>4416</td>\n",
              "      <td>0.052594</td>\n",
              "      <td>0.079017</td>\n",
              "      <td>0.417309</td>\n",
              "      <td>0.182239</td>\n",
              "      <td>0.198712</td>\n",
              "      <td>-0.295009</td>\n",
              "      <td>0.267844</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>...</td>\n",
              "      <td>0.810411</td>\n",
              "      <td>0.966938</td>\n",
              "      <td>0.762002</td>\n",
              "      <td>0.204937</td>\n",
              "      <td>0.033062</td>\n",
              "      <td>45</td>\n",
              "      <td>-0.319929</td>\n",
              "      <td>-0.435633</td>\n",
              "      <td>0.419046</td>\n",
              "      <td>-1.365125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SPY</td>\n",
              "      <td>4417</td>\n",
              "      <td>-0.049380</td>\n",
              "      <td>-0.072367</td>\n",
              "      <td>0.210327</td>\n",
              "      <td>-0.357156</td>\n",
              "      <td>-0.370645</td>\n",
              "      <td>-0.219679</td>\n",
              "      <td>-0.329422</td>\n",
              "      <td>-0.000011</td>\n",
              "      <td>...</td>\n",
              "      <td>0.894014</td>\n",
              "      <td>0.948608</td>\n",
              "      <td>0.667648</td>\n",
              "      <td>0.280960</td>\n",
              "      <td>0.051392</td>\n",
              "      <td>81</td>\n",
              "      <td>-0.016873</td>\n",
              "      <td>-0.024926</td>\n",
              "      <td>0.213149</td>\n",
              "      <td>-0.118423</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>V</td>\n",
              "      <td>4416</td>\n",
              "      <td>0.111496</td>\n",
              "      <td>0.169805</td>\n",
              "      <td>0.236429</td>\n",
              "      <td>0.663360</td>\n",
              "      <td>0.784781</td>\n",
              "      <td>-0.154086</td>\n",
              "      <td>1.102016</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>...</td>\n",
              "      <td>0.884035</td>\n",
              "      <td>0.936594</td>\n",
              "      <td>0.665308</td>\n",
              "      <td>0.271286</td>\n",
              "      <td>0.063406</td>\n",
              "      <td>81</td>\n",
              "      <td>0.236605</td>\n",
              "      <td>0.370385</td>\n",
              "      <td>0.239610</td>\n",
              "      <td>1.315020</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11 rows  25 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   asset_id  steps  total_return  annualized_return  annualized_volatility  \\\n",
              "9      AMGN   4416      0.274588           0.433300               0.302639   \n",
              "0      AMZN   4417      0.782635           1.357306               0.354293   \n",
              "8       CAT   4416     -0.165245          -0.235078               0.351591   \n",
              "6      CSCO   4416      0.240335           0.376522               0.229905   \n",
              "10      DIA   4408     -0.033127          -0.048841               0.184774   \n",
              "2       DIS   4370     -0.078248          -0.114996               0.299184   \n",
              "7       JPM   4416     -0.116273          -0.167561               0.316859   \n",
              "1        KO   4416      0.111965           0.170537               0.183128   \n",
              "5       NKE   4416      0.052594           0.079017               0.417309   \n",
              "4       SPY   4417     -0.049380          -0.072367               0.210327   \n",
              "3         V   4416      0.111496           0.169805               0.236429   \n",
              "\n",
              "      sharpe   sortino  max_drawdown    calmar  avg_reward  ...  position_std  \\\n",
              "9   1.189466  1.791269     -0.176269  2.458176    0.000055  ...      0.913318   \n",
              "0   2.420365  3.609958     -0.265170  5.118628    0.000131  ...      0.966057   \n",
              "8  -0.762195 -0.845701     -0.262493 -0.895560   -0.000041  ...      0.830052   \n",
              "6   1.389965  1.884579     -0.161022  2.338323    0.000049  ...      0.905360   \n",
              "10 -0.271000 -0.303610     -0.186009 -0.262571   -0.000008  ...      0.919096   \n",
              "2  -0.408323 -0.435266     -0.252933 -0.454651   -0.000019  ...      0.906125   \n",
              "7  -0.578790 -0.599890     -0.253414 -0.661212   -0.000028  ...      0.949751   \n",
              "1   0.859851  1.116355     -0.128254  1.329678    0.000024  ...      0.873206   \n",
              "5   0.182239  0.198712     -0.295009  0.267844    0.000012  ...      0.810411   \n",
              "4  -0.357156 -0.370645     -0.219679 -0.329422   -0.000011  ...      0.894014   \n",
              "3   0.663360  0.784781     -0.154086  1.102016    0.000024  ...      0.884035   \n",
              "\n",
              "    avg_abs_position  long_frac  short_frac  flat_frac  trade_count  \\\n",
              "9           0.969203   0.668478    0.300725   0.030797           75   \n",
              "0           0.943853   0.523885    0.419968   0.056147           94   \n",
              "8           0.970335   0.750453    0.219882   0.029665           55   \n",
              "6           0.964221   0.672328    0.291893   0.035779           75   \n",
              "10          0.845735   0.405626    0.440109   0.154265          129   \n",
              "2           0.943936   0.647368    0.296568   0.056064           97   \n",
              "7           0.927310   0.543478    0.383832   0.072690          111   \n",
              "1           0.967844   0.710598    0.257246   0.032156           45   \n",
              "5           0.966938   0.762002    0.204937   0.033062           45   \n",
              "4           0.948608   0.667648    0.280960   0.051392           81   \n",
              "3           0.936594   0.665308    0.271286   0.063406           81   \n",
              "\n",
              "    bh_total_return  bh_annualized_return  bh_annualized_volatility  bh_sharpe  \n",
              "9         -0.146664             -0.209680                  0.305772  -0.769582  \n",
              "0          0.104821              0.159358                  0.362985   0.407364  \n",
              "8         -0.130198             -0.186948                  0.354228  -0.584258  \n",
              "6          0.130017              0.198842                  0.235809   0.769079  \n",
              "10        -0.031810             -0.046914                  0.195193  -0.246168  \n",
              "2          0.007318              0.010991                  0.306695   0.035642  \n",
              "7          0.093133              0.141246                  0.323585   0.408302  \n",
              "1          0.003404              0.005055                  0.187840   0.026841  \n",
              "5         -0.319929             -0.435633                  0.419046  -1.365125  \n",
              "4         -0.016873             -0.024926                  0.213149  -0.118423  \n",
              "3          0.236605              0.370385                  0.239610   1.315020  \n",
              "\n",
              "[11 rows x 25 columns]"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eval_cfg = EvalConfig(\n",
        "    annual_trading_days=252,\n",
        "    regular_hours_only=dataset_kwargs.get(\"regular_hours_only\", True),\n",
        "    timeframe=dataset_kwargs.get(\"timeframe\", \"15min\"),\n",
        ")\n",
        "\n",
        "results: List[Dict[str, float]] = []\n",
        "for idx, asset_id in enumerate(test_dataset.asset_ids, start=1):\n",
        "    print(f\"[{idx}/{len(test_dataset.asset_ids)}] Evaluating {asset_id}...\")\n",
        "    metrics = eval_asset(model, test_dataset, asset_id, eval_cfg)\n",
        "    if metrics:\n",
        "        results.append(metrics)\n",
        "\n",
        "if not results:\n",
        "    raise RuntimeError(\"No evaluation results produced.\")\n",
        "\n",
        "df = pd.DataFrame(results).sort_values(\"asset_id\")\n",
        "df.head(11)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "id": "6a86b146",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>asset_id</th>\n",
              "      <th>total_return</th>\n",
              "      <th>bh_total_return</th>\n",
              "      <th>sharpe</th>\n",
              "      <th>bh_sharpe</th>\n",
              "      <th>ret_diff</th>\n",
              "      <th>sharpe_diff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>AMGN</td>\n",
              "      <td>0.274588</td>\n",
              "      <td>-0.146664</td>\n",
              "      <td>1.189466</td>\n",
              "      <td>-0.769582</td>\n",
              "      <td>0.421252</td>\n",
              "      <td>1.959048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AMZN</td>\n",
              "      <td>0.782635</td>\n",
              "      <td>0.104821</td>\n",
              "      <td>2.420365</td>\n",
              "      <td>0.407364</td>\n",
              "      <td>0.677814</td>\n",
              "      <td>2.013002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>CAT</td>\n",
              "      <td>-0.165245</td>\n",
              "      <td>-0.130198</td>\n",
              "      <td>-0.762195</td>\n",
              "      <td>-0.584258</td>\n",
              "      <td>-0.035047</td>\n",
              "      <td>-0.177937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>CSCO</td>\n",
              "      <td>0.240335</td>\n",
              "      <td>0.130017</td>\n",
              "      <td>1.389965</td>\n",
              "      <td>0.769079</td>\n",
              "      <td>0.110318</td>\n",
              "      <td>0.620886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>DIA</td>\n",
              "      <td>-0.033127</td>\n",
              "      <td>-0.031810</td>\n",
              "      <td>-0.271000</td>\n",
              "      <td>-0.246168</td>\n",
              "      <td>-0.001317</td>\n",
              "      <td>-0.024832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>DIS</td>\n",
              "      <td>-0.078248</td>\n",
              "      <td>0.007318</td>\n",
              "      <td>-0.408323</td>\n",
              "      <td>0.035642</td>\n",
              "      <td>-0.085566</td>\n",
              "      <td>-0.443965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>JPM</td>\n",
              "      <td>-0.116273</td>\n",
              "      <td>0.093133</td>\n",
              "      <td>-0.578790</td>\n",
              "      <td>0.408302</td>\n",
              "      <td>-0.209406</td>\n",
              "      <td>-0.987092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>KO</td>\n",
              "      <td>0.111965</td>\n",
              "      <td>0.003404</td>\n",
              "      <td>0.859851</td>\n",
              "      <td>0.026841</td>\n",
              "      <td>0.108561</td>\n",
              "      <td>0.833010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>NKE</td>\n",
              "      <td>0.052594</td>\n",
              "      <td>-0.319929</td>\n",
              "      <td>0.182239</td>\n",
              "      <td>-1.365125</td>\n",
              "      <td>0.372522</td>\n",
              "      <td>1.547363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SPY</td>\n",
              "      <td>-0.049380</td>\n",
              "      <td>-0.016873</td>\n",
              "      <td>-0.357156</td>\n",
              "      <td>-0.118423</td>\n",
              "      <td>-0.032508</td>\n",
              "      <td>-0.238733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>V</td>\n",
              "      <td>0.111496</td>\n",
              "      <td>0.236605</td>\n",
              "      <td>0.663360</td>\n",
              "      <td>1.315020</td>\n",
              "      <td>-0.125109</td>\n",
              "      <td>-0.651660</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   asset_id  total_return  bh_total_return    sharpe  bh_sharpe  ret_diff  \\\n",
              "9      AMGN      0.274588        -0.146664  1.189466  -0.769582  0.421252   \n",
              "0      AMZN      0.782635         0.104821  2.420365   0.407364  0.677814   \n",
              "8       CAT     -0.165245        -0.130198 -0.762195  -0.584258 -0.035047   \n",
              "6      CSCO      0.240335         0.130017  1.389965   0.769079  0.110318   \n",
              "10      DIA     -0.033127        -0.031810 -0.271000  -0.246168 -0.001317   \n",
              "2       DIS     -0.078248         0.007318 -0.408323   0.035642 -0.085566   \n",
              "7       JPM     -0.116273         0.093133 -0.578790   0.408302 -0.209406   \n",
              "1        KO      0.111965         0.003404  0.859851   0.026841  0.108561   \n",
              "5       NKE      0.052594        -0.319929  0.182239  -1.365125  0.372522   \n",
              "4       SPY     -0.049380        -0.016873 -0.357156  -0.118423 -0.032508   \n",
              "3         V      0.111496         0.236605  0.663360   1.315020 -0.125109   \n",
              "\n",
              "    sharpe_diff  \n",
              "9      1.959048  \n",
              "0      2.013002  \n",
              "8     -0.177937  \n",
              "6      0.620886  \n",
              "10    -0.024832  \n",
              "2     -0.443965  \n",
              "7     -0.987092  \n",
              "1      0.833010  \n",
              "5      1.547363  \n",
              "4     -0.238733  \n",
              "3     -0.651660  "
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ret_analysis = df[[\"asset_id\", \"total_return\", \"bh_total_return\", \"sharpe\", \"bh_sharpe\"]].copy()\n",
        "ret_analysis[\"ret_diff\"] = ret_analysis[\"total_return\"] - ret_analysis[\"bh_total_return\"]\n",
        "ret_analysis[\"sharpe_diff\"] = ret_analysis[\"sharpe\"] - ret_analysis[\"bh_sharpe\"]\n",
        "ret_analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "id": "79f59c1e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved per-asset metrics to C:\\python\\koulu\\Gradu\\logs\\jepa6_ppo_final1_test_metrics.csv\n",
            "Saved summary to C:\\python\\koulu\\Gradu\\logs\\jepa6_ppo_final1_test_summary.csv\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>steps</th>\n",
              "      <th>total_return</th>\n",
              "      <th>annualized_return</th>\n",
              "      <th>annualized_volatility</th>\n",
              "      <th>sharpe</th>\n",
              "      <th>sortino</th>\n",
              "      <th>max_drawdown</th>\n",
              "      <th>calmar</th>\n",
              "      <th>avg_reward</th>\n",
              "      <th>reward_volatility</th>\n",
              "      <th>...</th>\n",
              "      <th>position_std</th>\n",
              "      <th>avg_abs_position</th>\n",
              "      <th>long_frac</th>\n",
              "      <th>short_frac</th>\n",
              "      <th>flat_frac</th>\n",
              "      <th>trade_count</th>\n",
              "      <th>bh_total_return</th>\n",
              "      <th>bh_annualized_return</th>\n",
              "      <th>bh_annualized_volatility</th>\n",
              "      <th>bh_sharpe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>4411.272727</td>\n",
              "      <td>0.102849</td>\n",
              "      <td>0.177058</td>\n",
              "      <td>0.280585</td>\n",
              "      <td>0.393435</td>\n",
              "      <td>0.620958</td>\n",
              "      <td>-0.214031</td>\n",
              "      <td>0.910113</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>0.003466</td>\n",
              "      <td>...</td>\n",
              "      <td>0.895584</td>\n",
              "      <td>0.944053</td>\n",
              "      <td>0.637925</td>\n",
              "      <td>0.306128</td>\n",
              "      <td>0.055947</td>\n",
              "      <td>80.727273</td>\n",
              "      <td>-0.006380</td>\n",
              "      <td>-0.001657</td>\n",
              "      <td>0.285810</td>\n",
              "      <td>-0.011028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>median</th>\n",
              "      <td>4416.000000</td>\n",
              "      <td>0.052594</td>\n",
              "      <td>0.079017</td>\n",
              "      <td>0.299184</td>\n",
              "      <td>0.182239</td>\n",
              "      <td>0.198712</td>\n",
              "      <td>-0.219679</td>\n",
              "      <td>0.267844</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.003696</td>\n",
              "      <td>...</td>\n",
              "      <td>0.905360</td>\n",
              "      <td>0.948608</td>\n",
              "      <td>0.667648</td>\n",
              "      <td>0.291893</td>\n",
              "      <td>0.051392</td>\n",
              "      <td>81.000000</td>\n",
              "      <td>0.003404</td>\n",
              "      <td>0.005055</td>\n",
              "      <td>0.305772</td>\n",
              "      <td>0.026841</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows  24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              steps  total_return  annualized_return  annualized_volatility  \\\n",
              "mean    4411.272727      0.102849           0.177058               0.280585   \n",
              "median  4416.000000      0.052594           0.079017               0.299184   \n",
              "\n",
              "          sharpe   sortino  max_drawdown    calmar  avg_reward  \\\n",
              "mean    0.393435  0.620958     -0.214031  0.910113    0.000017   \n",
              "median  0.182239  0.198712     -0.219679  0.267844    0.000012   \n",
              "\n",
              "        reward_volatility  ...  position_std  avg_abs_position  long_frac  \\\n",
              "mean             0.003466  ...      0.895584          0.944053   0.637925   \n",
              "median           0.003696  ...      0.905360          0.948608   0.667648   \n",
              "\n",
              "        short_frac  flat_frac  trade_count  bh_total_return  \\\n",
              "mean      0.306128   0.055947    80.727273        -0.006380   \n",
              "median    0.291893   0.051392    81.000000         0.003404   \n",
              "\n",
              "        bh_annualized_return  bh_annualized_volatility  bh_sharpe  \n",
              "mean               -0.001657                  0.285810  -0.011028  \n",
              "median              0.005055                  0.305772   0.026841  \n",
              "\n",
              "[2 rows x 24 columns]"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save outputs\n",
        "os.makedirs(PROJECT_ROOT / log_root, exist_ok=True)\n",
        "metrics_path = PROJECT_ROOT / log_root / f\"{model_name}_test_metrics.csv\"\n",
        "summary_path = PROJECT_ROOT / log_root / f\"{model_name}_test_summary.csv\"\n",
        "\n",
        "df.to_csv(metrics_path, index=False)\n",
        "summary = df.drop(columns=[\"asset_id\"]).agg([\"mean\", \"median\"])\n",
        "summary.to_csv(summary_path)\n",
        "\n",
        "print(f\"Saved per-asset metrics to {metrics_path}\")\n",
        "print(f\"Saved summary to {summary_path}\")\n",
        "summary\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".graduenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
