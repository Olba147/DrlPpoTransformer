{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PPO Model Testing\n",
        "\n",
        "Evaluate a trained PPO+JEPA model using a single training config file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project root: C:\\python\\koulu\\Gradu\n"
          ]
        }
      ],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import io\n",
        "import zipfile\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "from typing import Dict, List\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "# Resolve project root robustly when notebook is launched from different cwd\n",
        "def find_project_root(start: Path) -> Path:\n",
        "    p = start.resolve()\n",
        "    for candidate in [p, *p.parents]:\n",
        "        if (candidate / \"src\").exists() and (candidate / \"configs\").exists():\n",
        "            return candidate\n",
        "    raise RuntimeError(\"Could not locate project root containing src/ and configs/\")\n",
        "\n",
        "PROJECT_ROOT = find_project_root(Path.cwd())\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(PROJECT_ROOT))\n",
        "if str(PROJECT_ROOT / \"src\") not in sys.path:\n",
        "    sys.path.insert(0, str(PROJECT_ROOT / \"src\"))\n",
        "\n",
        "from config.config_utils import load_json_config\n",
        "from Datasets.multi_asset_dataset import Dataset_Finance_MultiAsset\n",
        "from Training.sb3_jepa_ppo import JEPAAuxFeatureExtractor, PPOWithJEPA\n",
        "from models.jepa.jepa import JEPA\n",
        "from models.time_series.patchTransformer import PatchTSTEncoder\n",
        "\n",
        "print(f\"Project root: {PROJECT_ROOT}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -----------------------------\n",
        "# User parameters\n",
        "# -----------------------------\n",
        "# Config used for training this PPO model\n",
        "PPO_CONFIG_PATH = \"configs/ppo_jepa_final_1.json\"\n",
        "\n",
        "# Optional overrides (set to None to auto-resolve from config)\n",
        "PPO_CHECKPOINT_PATH = \"checkpoints/jepa6_ppo_final1/ppo_4800000_steps.zip\"\n",
        "# Optional: used only for asset_universe lookup, not for JEPA model weights\n",
        "JEPA_CHECKPOINT_PATH = \"checkpoints/jepa6_ppo_final1/jepa_step_300000.pt\"\n",
        "\n",
        "# If None, evaluate all assets available in validation split\n",
        "MAX_ASSETS = None\n",
        "\n",
        "# Deterministic policy during evaluation\n",
        "DETERMINISTIC = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model name: jepa6_ppo_final1\n",
            "PPO checkpoint: C:\\python\\koulu\\Gradu\\checkpoints\\jepa6_ppo_final1\\ppo_4800000_steps.zip\n",
            "JEPA checkpoint: C:\\python\\koulu\\Gradu\\checkpoints\\jepa6_ppo_final1\\jepa_step_300000.pt\n",
            "Action mode: discrete_3\n",
            "Asset universe: None\n"
          ]
        }
      ],
      "source": [
        "def get_latest_ppo_checkpoint(checkpoint_dir: str) -> str | None:\n",
        "    if not os.path.isdir(checkpoint_dir):\n",
        "        return None\n",
        "    ckpts = []\n",
        "    for fname in os.listdir(checkpoint_dir):\n",
        "        if fname.startswith(\"ppo_\") and fname.endswith(\"_steps.zip\"):\n",
        "            ckpts.append(os.path.join(checkpoint_dir, fname))\n",
        "    if not ckpts:\n",
        "        return None\n",
        "    ckpts.sort(key=lambda p: os.path.getmtime(p))\n",
        "    return ckpts[-1]\n",
        "\n",
        "\n",
        "def load_tickers(path: str) -> list | None:\n",
        "    if not path or not os.path.exists(path):\n",
        "        return None\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        tickers = [line.strip() for line in f if line.strip()]\n",
        "    return tickers or None\n",
        "\n",
        "\n",
        "def load_asset_universe_from_checkpoint(path: str | None) -> list | None:\n",
        "    if not path or not os.path.exists(path):\n",
        "        return None\n",
        "    try:\n",
        "        checkpoint = torch.load(path, map_location=\"cpu\")\n",
        "    except Exception:\n",
        "        return None\n",
        "    asset_universe = checkpoint.get(\"asset_universe\")\n",
        "    return list(asset_universe) if asset_universe else None\n",
        "\n",
        "\n",
        "cfg = load_json_config(str(PROJECT_ROOT / PPO_CONFIG_PATH), \"\", str(PROJECT_ROOT / \"notebooks\" / \"ppo_model_test.ipynb\"))\n",
        "\n",
        "model_name = cfg[\"model_name\"]\n",
        "paths_cfg = cfg[\"paths\"]\n",
        "dataset_cfg = cfg[\"dataset\"]\n",
        "env_cfg = cfg[\"env\"]\n",
        "ppo_cfg = cfg[\"ppo\"]\n",
        "jepa_cfg = cfg[\"jepa_model\"]\n",
        "\n",
        "checkpoint_root = paths_cfg.get(\"checkpoint_root\", \"checkpoints\")\n",
        "log_root = paths_cfg.get(\"log_root\", \"logs\")\n",
        "ppo_checkpoint_dir = str(PROJECT_ROOT / checkpoint_root / model_name)\n",
        "\n",
        "if PPO_CHECKPOINT_PATH is None:\n",
        "    PPO_CHECKPOINT_PATH = get_latest_ppo_checkpoint(ppo_checkpoint_dir)\n",
        "if PPO_CHECKPOINT_PATH is None:\n",
        "    raise FileNotFoundError(f\"No PPO checkpoint found under {ppo_checkpoint_dir}\")\n",
        "if not os.path.isabs(PPO_CHECKPOINT_PATH):\n",
        "    PPO_CHECKPOINT_PATH = str(PROJECT_ROOT / PPO_CHECKPOINT_PATH)\n",
        "\n",
        "if JEPA_CHECKPOINT_PATH is None and paths_cfg.get(\"jepa_checkpoint_dir\"):\n",
        "    jepa_checkpoint_dir = paths_cfg[\"jepa_checkpoint_dir\"]\n",
        "    JEPA_CHECKPOINT_PATH = str(PROJECT_ROOT / jepa_checkpoint_dir / \"best.pt\")\n",
        "if JEPA_CHECKPOINT_PATH is not None and not os.path.isabs(JEPA_CHECKPOINT_PATH):\n",
        "    JEPA_CHECKPOINT_PATH = str(PROJECT_ROOT / JEPA_CHECKPOINT_PATH)\n",
        "\n",
        "ACTION_MODE = env_cfg.get(\"action_mode\", \"continuous\")\n",
        "ALLOW_SHORT = env_cfg.get(\"allow_short\", True)\n",
        "INCLUDE_WEALTH = env_cfg.get(\"include_wealth\", True)\n",
        "TRANSACTION_COST = 0.0005\n",
        "\n",
        "print(\"Model name:\", model_name)\n",
        "print(\"PPO checkpoint:\", PPO_CHECKPOINT_PATH)\n",
        "print(\"JEPA checkpoint:\", JEPA_CHECKPOINT_PATH)\n",
        "print(\"Action mode:\", ACTION_MODE)\n",
        "print(\"Asset universe:\", paths_cfg[\"asset_universe_path\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class EvalConfig:\n",
        "    annual_trading_days: int = 252\n",
        "    regular_hours_only: bool = True\n",
        "    timeframe: str = \"15min\"\n",
        "    flat_threshold: float = 1e-3\n",
        "\n",
        "\n",
        "def _timeframe_to_minutes(timeframe: str) -> int:\n",
        "    tf = timeframe.strip().lower()\n",
        "    if tf.endswith(\"min\"):\n",
        "        return int(tf[:-3])\n",
        "    if tf.endswith(\"h\"):\n",
        "        return int(tf[:-1]) * 60\n",
        "    raise ValueError(f\"Unsupported timeframe: {timeframe}\")\n",
        "\n",
        "\n",
        "def annualization_factor(cfg: EvalConfig) -> float:\n",
        "    minutes_per_day = 390 if cfg.regular_hours_only else 24 * 60\n",
        "    minutes = _timeframe_to_minutes(cfg.timeframe)\n",
        "    bars_per_day = max(1, minutes_per_day // minutes)\n",
        "    return bars_per_day * cfg.annual_trading_days\n",
        "\n",
        "\n",
        "def action_to_weight(action) -> float:\n",
        "    if ACTION_MODE == \"discrete_3\":\n",
        "        discrete_actions = np.array([-1.0, 0.0, 1.0], dtype=np.float32)\n",
        "        idx = int(np.asarray(action).reshape(-1)[0])\n",
        "        idx = int(np.clip(idx, 0, len(discrete_actions) - 1))\n",
        "        w_t = float(discrete_actions[idx])\n",
        "    else:\n",
        "        w_t = float(np.clip(np.asarray(action).reshape(-1)[0], -1.0, 1.0))\n",
        "    if not ALLOW_SHORT:\n",
        "        w_t = max(0.0, w_t)\n",
        "    return w_t\n",
        "\n",
        "\n",
        "def compute_drawdown(equity: np.ndarray) -> float:\n",
        "    if equity.size == 0:\n",
        "        return float(\"nan\")\n",
        "    peak = np.maximum.accumulate(equity)\n",
        "    drawdown = (equity - peak) / peak\n",
        "    return float(np.min(drawdown))\n",
        "\n",
        "\n",
        "def safe_sharpe(mean: float, std: float, ann_factor: float) -> float:\n",
        "    if std <= 0 or np.isnan(std):\n",
        "        return float(\"nan\")\n",
        "    return float(mean / std * np.sqrt(ann_factor))\n",
        "\n",
        "\n",
        "def build_jepa_model(device: str, num_assets: int) -> JEPA:\n",
        "    encoder_num_assets = num_assets if jepa_cfg.get(\"use_asset_embeddings\", True) else None\n",
        "\n",
        "    jepa_context_encoder = PatchTSTEncoder(\n",
        "        patch_len=jepa_cfg[\"patch_len\"],\n",
        "        d_model=jepa_cfg[\"d_model\"],\n",
        "        n_features=jepa_cfg[\"n_features\"],\n",
        "        n_time_features=jepa_cfg[\"n_time_features\"],\n",
        "        nhead=jepa_cfg[\"nhead\"],\n",
        "        num_layers=jepa_cfg[\"num_layers\"],\n",
        "        dim_ff=jepa_cfg[\"dim_ff\"],\n",
        "        dropout=jepa_cfg[\"dropout\"],\n",
        "        add_cls=jepa_cfg.get(\"add_cls\", True),\n",
        "        pooling=jepa_cfg[\"pooling\"],\n",
        "        pred_len=jepa_cfg[\"pred_len\"],\n",
        "        num_assets=encoder_num_assets,\n",
        "    )\n",
        "    jepa_target_encoder = copy.deepcopy(jepa_context_encoder)\n",
        "\n",
        "    jepa_model = JEPA(\n",
        "        jepa_context_encoder,\n",
        "        jepa_target_encoder,\n",
        "        d_model=jepa_cfg[\"d_model\"],\n",
        "        ema_tau_min=jepa_cfg[\"ema_tau_min\"],\n",
        "        ema_tau_max=jepa_cfg[\"ema_tau_max\"],\n",
        "    )\n",
        "\n",
        "    for param in jepa_model.parameters():\n",
        "        param.requires_grad = False\n",
        "    jepa_model.eval()\n",
        "    return jepa_model.to(device)\n",
        "\n",
        "\n",
        "def extract_jepa_state_dict_from_ppo_zip(model_path: str) -> Dict[str, torch.Tensor]:\n",
        "    with zipfile.ZipFile(model_path, \"r\") as zf:\n",
        "        with zf.open(\"policy.pth\", \"r\") as f:\n",
        "            policy_state = torch.load(io.BytesIO(f.read()), map_location=\"cpu\")\n",
        "\n",
        "    prefix = \"features_extractor.jepa_model.\"\n",
        "    jepa_state = {}\n",
        "    for k, v in policy_state.items():\n",
        "        if k.startswith(prefix):\n",
        "            jepa_state[k[len(prefix):]] = v\n",
        "    if not jepa_state:\n",
        "        raise RuntimeError(\"No JEPA weights found in PPO zip policy state.\")\n",
        "    return jepa_state\n",
        "\n",
        "\n",
        "def load_ppo_model(model_path: str, device: str, policy_kwargs: Dict) -> PPOWithJEPA:\n",
        "    try:\n",
        "        print(\"Loading PPO (and embedded JEPA) directly from PPO zip...\")\n",
        "        return PPOWithJEPA.load(model_path, device=device)\n",
        "    except Exception as exc:\n",
        "        print(f\"Primary PPO load failed ({exc}); retrying with custom policy_kwargs and JEPA weights from PPO zip.\")\n",
        "\n",
        "        fx_kwargs = policy_kwargs.get(\"features_extractor_kwargs\", {})\n",
        "        jepa_model = fx_kwargs.get(\"jepa_model\")\n",
        "        if jepa_model is None:\n",
        "            raise RuntimeError(\"Fallback requires policy_kwargs.features_extractor_kwargs.jepa_model\")\n",
        "\n",
        "        jepa_state = extract_jepa_state_dict_from_ppo_zip(model_path)\n",
        "        missing, unexpected = jepa_model.load_state_dict(jepa_state, strict=False)\n",
        "        if missing:\n",
        "            print(f\"Missing keys when loading JEPA from PPO zip: {missing}\")\n",
        "        if unexpected:\n",
        "            print(f\"Unexpected keys when loading JEPA from PPO zip: {unexpected}\")\n",
        "\n",
        "        return PPOWithJEPA.load(model_path, device=device, custom_objects={\"policy_kwargs\": policy_kwargs})\n",
        "\n",
        "\n",
        "def eval_asset(model: PPOWithJEPA, dataset: Dataset_Finance_MultiAsset, asset_id: str, cfg: EvalConfig) -> Dict[str, float]:\n",
        "    asset_idx = dataset.asset_id_to_idx.get(asset_id, -1)\n",
        "    X = dataset.data_x[asset_id]\n",
        "    dates = dataset.dates[asset_id]\n",
        "    ohlcv = dataset.ohlcv[asset_id]\n",
        "\n",
        "    seq_len = dataset.seq_len\n",
        "    pred_len = dataset.pred_len\n",
        "    n_steps = len(X) - seq_len - pred_len\n",
        "    if n_steps <= 0:\n",
        "        return {}\n",
        "\n",
        "    w_prev = 0.0\n",
        "    wealth = 1.0\n",
        "    rewards, asset_returns, positions, turnovers, equity = [], [], [], [], []\n",
        "\n",
        "    for cursor in range(n_steps):\n",
        "        x_context = X[cursor : cursor + seq_len].astype(np.float32)\n",
        "        t_context = dates[cursor : cursor + seq_len].astype(np.float32)\n",
        "        x_target = X[cursor + seq_len : cursor + seq_len + pred_len].astype(np.float32)\n",
        "        t_target = dates[cursor + seq_len : cursor + seq_len + pred_len].astype(np.float32)\n",
        "\n",
        "        obs = {\n",
        "            \"x_context\": x_context,\n",
        "            \"t_context\": t_context,\n",
        "            \"x_target\": x_target,\n",
        "            \"t_target\": t_target,\n",
        "            \"asset_id\": np.int64(asset_idx),\n",
        "            \"w_prev\": np.array([w_prev], dtype=np.float32),\n",
        "        }\n",
        "        if INCLUDE_WEALTH:\n",
        "            obs[\"wealth_feats\"] = np.array([np.log(wealth)], dtype=np.float32)\n",
        "\n",
        "        action, _ = model.predict(obs, deterministic=DETERMINISTIC)\n",
        "        w_t = action_to_weight(action)\n",
        "\n",
        "        close_t = float(ohlcv[cursor + seq_len - 1][3])\n",
        "        close_tp1 = float(ohlcv[cursor + seq_len][3])\n",
        "        r_tp1 = float(np.log(close_tp1 / close_t))\n",
        "\n",
        "        turnover = abs(w_t - w_prev)\n",
        "        reward = w_t * r_tp1 - TRANSACTION_COST * turnover\n",
        "        wealth *= float(np.exp(reward))\n",
        "\n",
        "        rewards.append(reward)\n",
        "        asset_returns.append(r_tp1)\n",
        "        positions.append(w_t)\n",
        "        turnovers.append(turnover)\n",
        "        equity.append(wealth)\n",
        "        w_prev = w_t\n",
        "\n",
        "    rewards = np.asarray(rewards, dtype=np.float64)\n",
        "    asset_returns = np.asarray(asset_returns, dtype=np.float64)\n",
        "    positions = np.asarray(positions, dtype=np.float64)\n",
        "    turnovers = np.asarray(turnovers, dtype=np.float64)\n",
        "    equity = np.asarray(equity, dtype=np.float64)\n",
        "\n",
        "    ann_factor = annualization_factor(cfg)\n",
        "    mean_reward = float(np.mean(rewards)) if rewards.size else float(\"nan\")\n",
        "    std_reward = float(np.std(rewards, ddof=1)) if rewards.size > 1 else float(\"nan\")\n",
        "\n",
        "    total_log_return = float(np.sum(rewards)) if rewards.size else float(\"nan\")\n",
        "    total_return = float(np.exp(total_log_return) - 1.0) if rewards.size else float(\"nan\")\n",
        "    annualized_return = float(np.exp(mean_reward * ann_factor) - 1.0) if rewards.size else float(\"nan\")\n",
        "    annualized_vol = float(std_reward * np.sqrt(ann_factor)) if rewards.size > 1 else float(\"nan\")\n",
        "    sharpe = safe_sharpe(mean_reward, std_reward, ann_factor)\n",
        "\n",
        "    downside = rewards[rewards < 0]\n",
        "    downside_std = float(np.std(downside, ddof=1)) if downside.size > 1 else float(\"nan\")\n",
        "    sortino = safe_sharpe(mean_reward, downside_std, ann_factor)\n",
        "\n",
        "    max_drawdown = compute_drawdown(equity)\n",
        "    calmar = float(annualized_return / abs(max_drawdown)) if max_drawdown < 0 else float(\"nan\")\n",
        "\n",
        "    win_rate = float(np.mean(rewards > 0)) if rewards.size else float(\"nan\")\n",
        "    avg_turnover = float(np.mean(turnovers)) if turnovers.size else float(\"nan\")\n",
        "    total_turnover = float(np.sum(turnovers)) if turnovers.size else float(\"nan\")\n",
        "    avg_position = float(np.mean(positions)) if positions.size else float(\"nan\")\n",
        "    pos_std = float(np.std(positions, ddof=1)) if positions.size > 1 else float(\"nan\")\n",
        "    abs_pos = float(np.mean(np.abs(positions))) if positions.size else float(\"nan\")\n",
        "\n",
        "    flat_mask = np.abs(positions) <= cfg.flat_threshold\n",
        "    long_mask = positions > cfg.flat_threshold\n",
        "    short_mask = positions < -cfg.flat_threshold\n",
        "    flat_frac = float(np.mean(flat_mask)) if positions.size else float(\"nan\")\n",
        "    long_frac = float(np.mean(long_mask)) if positions.size else float(\"nan\")\n",
        "    short_frac = float(np.mean(short_mask)) if positions.size else float(\"nan\")\n",
        "\n",
        "    trade_count = int(np.sum(np.abs(np.diff(positions)) > cfg.flat_threshold)) if positions.size > 1 else 0\n",
        "\n",
        "    bh_mean = float(np.mean(asset_returns)) if asset_returns.size else float(\"nan\")\n",
        "    bh_std = float(np.std(asset_returns, ddof=1)) if asset_returns.size > 1 else float(\"nan\")\n",
        "    bh_total_return = float(np.exp(np.sum(asset_returns)) - 1.0) if asset_returns.size else float(\"nan\")\n",
        "    bh_annualized_return = float(np.exp(bh_mean * ann_factor) - 1.0) if asset_returns.size else float(\"nan\")\n",
        "    bh_annualized_vol = float(bh_std * np.sqrt(ann_factor)) if asset_returns.size > 1 else float(\"nan\")\n",
        "    bh_sharpe = safe_sharpe(bh_mean, bh_std, ann_factor)\n",
        "\n",
        "    return {\n",
        "        \"asset_id\": asset_id,\n",
        "        \"steps\": int(n_steps),\n",
        "        \"total_return\": total_return,\n",
        "        \"annualized_return\": annualized_return,\n",
        "        \"annualized_volatility\": annualized_vol,\n",
        "        \"sharpe\": sharpe,\n",
        "        \"sortino\": sortino,\n",
        "        \"max_drawdown\": max_drawdown,\n",
        "        \"calmar\": calmar,\n",
        "        \"avg_reward\": mean_reward,\n",
        "        \"reward_volatility\": std_reward,\n",
        "        \"win_rate\": win_rate,\n",
        "        \"avg_turnover\": avg_turnover,\n",
        "        \"total_turnover\": total_turnover,\n",
        "        \"avg_position\": avg_position,\n",
        "        \"position_std\": pos_std,\n",
        "        \"avg_abs_position\": abs_pos,\n",
        "        \"long_frac\": long_frac,\n",
        "        \"short_frac\": short_frac,\n",
        "        \"flat_frac\": flat_frac,\n",
        "        \"trade_count\": trade_count,\n",
        "        \"bh_total_return\": bh_total_return,\n",
        "        \"bh_annualized_return\": bh_annualized_return,\n",
        "        \"bh_annualized_volatility\": bh_annualized_vol,\n",
        "        \"bh_sharpe\": bh_sharpe,\n",
        "    }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 11 tickers from C:\\python\\koulu\\Gradu\\configs\\assets\\tickers1.txt\n",
            "tickers: ['AMZN', 'KO', 'DIS', 'V', 'SPY', 'NKE', 'CSCO', 'JPM', 'CAT', 'AMGN', 'DIA']\n",
            "Loading evaluation dataset...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ollik\\AppData\\Local\\Temp\\ipykernel_51592\\2409997490.py:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(path, map_location=\"cpu\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Dataset_Finance_MultiAsset] Global date splits: train_end=2024-08-01 15:15:00+00:00 val_end=2025-04-29 16:30:00+00:00 n_dates=33178 n_train=23224 n_val=4978 n_test=4976\n",
            "Assets to evaluate: 11\n"
          ]
        }
      ],
      "source": [
        "def _resolve_project_path(path_value: str | None) -> str | None:\n",
        "    if path_value is None:\n",
        "        return None\n",
        "    p = Path(path_value)\n",
        "    if p.is_absolute():\n",
        "        return str(p)\n",
        "    return str((PROJECT_ROOT / p).resolve())\n",
        "\n",
        "\n",
        "\n",
        "ticker_list_path = paths_cfg.get(\"ticker_list_path\")\n",
        "if not ticker_list_path:\n",
        "    raise ValueError(\"Config is missing paths.ticker_list_path\")\n",
        "\n",
        "# Build dataset from the same config used in training\n",
        "tickers_path = PROJECT_ROOT / ticker_list_path\n",
        "tickers = load_tickers(str(tickers_path))\n",
        "if not tickers:\n",
        "    raise RuntimeError(f\"No tickers loaded from {tickers_path}\")\n",
        "\n",
        "dataset_kwargs = {\n",
        "    \"root_path\": _resolve_project_path(dataset_cfg[\"root_path\"]),\n",
        "    \"data_path\": dataset_cfg[\"data_path\"],\n",
        "    \"start_date\": dataset_cfg.get(\"start_date\"),\n",
        "    \"split\": \"val\",\n",
        "    \"size\": [dataset_cfg[\"context_len\"], dataset_cfg[\"target_len\"]],\n",
        "    \"use_time_features\": dataset_cfg.get(\"use_time_features\", True),\n",
        "    \"rolling_window\": dataset_cfg[\"rolling_window\"],\n",
        "    \"train_split\": dataset_cfg[\"train_split\"],\n",
        "    \"test_split\": dataset_cfg[\"test_split\"],\n",
        "    \"regular_hours_only\": dataset_cfg.get(\"regular_hours_only\", True),\n",
        "    \"timeframe\": dataset_cfg.get(\"timeframe\", \"15min\"),\n",
        "    \"tickers\": tickers,\n",
        "}\n",
        "\n",
        "asset_universe = load_asset_universe_from_checkpoint(JEPA_CHECKPOINT_PATH)\n",
        "if asset_universe:\n",
        "    dataset_kwargs[\"asset_universe\"] = asset_universe\n",
        "\n",
        "dataset_kwargs[\"tickers\"] = tickers\n",
        "print(f\"Loaded {len(tickers)} tickers from {tickers_path}\")\n",
        "print(f\"tickers: {tickers}\")\n",
        "\n",
        "print(\"Loading evaluation dataset...\")\n",
        "test_dataset = Dataset_Finance_MultiAsset(**dataset_kwargs)\n",
        "if not test_dataset.asset_ids:\n",
        "    raise RuntimeError(\"No assets found in the validation dataset.\")\n",
        "\n",
        "if MAX_ASSETS is not None:\n",
        "    test_dataset.asset_ids = test_dataset.asset_ids[: int(MAX_ASSETS)]\n",
        "\n",
        "print(f\"Assets to evaluate: {len(test_dataset.asset_ids)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading JEPA model...\n",
            "Loading PPO model from C:\\python\\koulu\\Gradu\\checkpoints\\jepa6_ppo_final1\\ppo_4800000_steps.zip...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ollik\\miniconda3\\envs\\.graduenv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "  warnings.warn(\n",
            "C:\\Users\\ollik\\AppData\\Local\\Temp\\ipykernel_51592\\517600101.py:80: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(JEPA_CHECKPOINT_PATH, map_location=\"cpu\")\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "MultiInputActorCriticPolicy(\n",
              "  (features_extractor): JEPAAuxFeatureExtractor(\n",
              "    (jepa_model): JEPA(\n",
              "      (context_enc): PatchTSTEncoder(\n",
              "        (proj_price): Linear(in_features=72, out_features=192, bias=True)\n",
              "        (proj_time): Linear(in_features=32, out_features=192, bias=True)\n",
              "        (posenc): PositionalEncoding()\n",
              "        (encoder): TransformerEncoder(\n",
              "          (layers): ModuleList(\n",
              "            (0-3): 4 x TransformerEncoderLayer(\n",
              "              (self_attn): MultiheadAttention(\n",
              "                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
              "              )\n",
              "              (linear1): Linear(in_features=192, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "              (linear2): Linear(in_features=768, out_features=192, bias=True)\n",
              "              (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "              (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout1): Dropout(p=0.0, inplace=False)\n",
              "              (dropout2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (final_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "        (head): Identity()\n",
              "      )\n",
              "      (target_enc): PatchTSTEncoder(\n",
              "        (proj_price): Linear(in_features=72, out_features=192, bias=True)\n",
              "        (proj_time): Linear(in_features=32, out_features=192, bias=True)\n",
              "        (posenc): PositionalEncoding()\n",
              "        (encoder): TransformerEncoder(\n",
              "          (layers): ModuleList(\n",
              "            (0-3): 4 x TransformerEncoderLayer(\n",
              "              (self_attn): MultiheadAttention(\n",
              "                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
              "              )\n",
              "              (linear1): Linear(in_features=192, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "              (linear2): Linear(in_features=768, out_features=192, bias=True)\n",
              "              (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "              (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout1): Dropout(p=0.0, inplace=False)\n",
              "              (dropout2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (final_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "        (head): Identity()\n",
              "      )\n",
              "      (predictor): Sequential(\n",
              "        (0): Linear(in_features=192, out_features=384, bias=True)\n",
              "        (1): GELU(approximate='none')\n",
              "        (2): Linear(in_features=384, out_features=384, bias=True)\n",
              "        (3): GELU(approximate='none')\n",
              "        (4): Linear(in_features=384, out_features=192, bias=True)\n",
              "        (5): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pi_features_extractor): JEPAAuxFeatureExtractor(\n",
              "    (jepa_model): JEPA(\n",
              "      (context_enc): PatchTSTEncoder(\n",
              "        (proj_price): Linear(in_features=72, out_features=192, bias=True)\n",
              "        (proj_time): Linear(in_features=32, out_features=192, bias=True)\n",
              "        (posenc): PositionalEncoding()\n",
              "        (encoder): TransformerEncoder(\n",
              "          (layers): ModuleList(\n",
              "            (0-3): 4 x TransformerEncoderLayer(\n",
              "              (self_attn): MultiheadAttention(\n",
              "                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
              "              )\n",
              "              (linear1): Linear(in_features=192, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "              (linear2): Linear(in_features=768, out_features=192, bias=True)\n",
              "              (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "              (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout1): Dropout(p=0.0, inplace=False)\n",
              "              (dropout2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (final_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "        (head): Identity()\n",
              "      )\n",
              "      (target_enc): PatchTSTEncoder(\n",
              "        (proj_price): Linear(in_features=72, out_features=192, bias=True)\n",
              "        (proj_time): Linear(in_features=32, out_features=192, bias=True)\n",
              "        (posenc): PositionalEncoding()\n",
              "        (encoder): TransformerEncoder(\n",
              "          (layers): ModuleList(\n",
              "            (0-3): 4 x TransformerEncoderLayer(\n",
              "              (self_attn): MultiheadAttention(\n",
              "                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
              "              )\n",
              "              (linear1): Linear(in_features=192, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "              (linear2): Linear(in_features=768, out_features=192, bias=True)\n",
              "              (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "              (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout1): Dropout(p=0.0, inplace=False)\n",
              "              (dropout2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (final_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "        (head): Identity()\n",
              "      )\n",
              "      (predictor): Sequential(\n",
              "        (0): Linear(in_features=192, out_features=384, bias=True)\n",
              "        (1): GELU(approximate='none')\n",
              "        (2): Linear(in_features=384, out_features=384, bias=True)\n",
              "        (3): GELU(approximate='none')\n",
              "        (4): Linear(in_features=384, out_features=192, bias=True)\n",
              "        (5): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (vf_features_extractor): JEPAAuxFeatureExtractor(\n",
              "    (jepa_model): JEPA(\n",
              "      (context_enc): PatchTSTEncoder(\n",
              "        (proj_price): Linear(in_features=72, out_features=192, bias=True)\n",
              "        (proj_time): Linear(in_features=32, out_features=192, bias=True)\n",
              "        (posenc): PositionalEncoding()\n",
              "        (encoder): TransformerEncoder(\n",
              "          (layers): ModuleList(\n",
              "            (0-3): 4 x TransformerEncoderLayer(\n",
              "              (self_attn): MultiheadAttention(\n",
              "                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
              "              )\n",
              "              (linear1): Linear(in_features=192, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "              (linear2): Linear(in_features=768, out_features=192, bias=True)\n",
              "              (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "              (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout1): Dropout(p=0.0, inplace=False)\n",
              "              (dropout2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (final_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "        (head): Identity()\n",
              "      )\n",
              "      (target_enc): PatchTSTEncoder(\n",
              "        (proj_price): Linear(in_features=72, out_features=192, bias=True)\n",
              "        (proj_time): Linear(in_features=32, out_features=192, bias=True)\n",
              "        (posenc): PositionalEncoding()\n",
              "        (encoder): TransformerEncoder(\n",
              "          (layers): ModuleList(\n",
              "            (0-3): 4 x TransformerEncoderLayer(\n",
              "              (self_attn): MultiheadAttention(\n",
              "                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
              "              )\n",
              "              (linear1): Linear(in_features=192, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "              (linear2): Linear(in_features=768, out_features=192, bias=True)\n",
              "              (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "              (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout1): Dropout(p=0.0, inplace=False)\n",
              "              (dropout2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (final_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "        (head): Identity()\n",
              "      )\n",
              "      (predictor): Sequential(\n",
              "        (0): Linear(in_features=192, out_features=384, bias=True)\n",
              "        (1): GELU(approximate='none')\n",
              "        (2): Linear(in_features=384, out_features=384, bias=True)\n",
              "        (3): GELU(approximate='none')\n",
              "        (4): Linear(in_features=384, out_features=192, bias=True)\n",
              "        (5): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (mlp_extractor): MlpExtractor(\n",
              "    (policy_net): Sequential(\n",
              "      (0): Linear(in_features=227, out_features=256, bias=True)\n",
              "      (1): Tanh()\n",
              "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (3): Tanh()\n",
              "    )\n",
              "    (value_net): Sequential(\n",
              "      (0): Linear(in_features=227, out_features=256, bias=True)\n",
              "      (1): Tanh()\n",
              "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (3): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (action_net): Linear(in_features=256, out_features=3, bias=True)\n",
              "  (value_net): Linear(in_features=256, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "num_asset_ids = int(getattr(test_dataset, \"num_asset_ids\", len(test_dataset.asset_ids)))\n",
        "\n",
        "print(\"Loading JEPA model...\")\n",
        "jepa_model = build_jepa_model(device, num_assets=num_asset_ids)\n",
        "\n",
        "policy_kwargs = dict(\n",
        "    features_extractor_class=JEPAAuxFeatureExtractor,\n",
        "    features_extractor_kwargs=dict(\n",
        "        jepa_model=jepa_model,\n",
        "        embedding_dim=jepa_cfg[\"d_model\"],\n",
        "        patch_len=jepa_cfg[\"patch_len\"],\n",
        "        patch_stride=jepa_cfg[\"patch_stride\"],\n",
        "        use_obs_targets=True,\n",
        "        target_len=test_dataset.pred_len,\n",
        "    ),\n",
        "    net_arch=dict(pi=[256, 256], vf=[256, 256]),\n",
        ")\n",
        "\n",
        "print(f\"Loading PPO model from {PPO_CHECKPOINT_PATH}...\")\n",
        "model = load_ppo_model(PPO_CHECKPOINT_PATH, device=device, policy_kwargs=policy_kwargs)\n",
        "model.policy.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/11] Evaluating AMZN...\n",
            "[2/11] Evaluating KO...\n",
            "[3/11] Evaluating DIS...\n",
            "[4/11] Evaluating V...\n",
            "[5/11] Evaluating SPY...\n",
            "[6/11] Evaluating NKE...\n",
            "[7/11] Evaluating CSCO...\n",
            "[8/11] Evaluating JPM...\n",
            "[9/11] Evaluating CAT...\n",
            "[10/11] Evaluating AMGN...\n",
            "[11/11] Evaluating DIA...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>asset_id</th>\n",
              "      <th>steps</th>\n",
              "      <th>total_return</th>\n",
              "      <th>annualized_return</th>\n",
              "      <th>annualized_volatility</th>\n",
              "      <th>sharpe</th>\n",
              "      <th>sortino</th>\n",
              "      <th>max_drawdown</th>\n",
              "      <th>calmar</th>\n",
              "      <th>avg_reward</th>\n",
              "      <th>...</th>\n",
              "      <th>position_std</th>\n",
              "      <th>avg_abs_position</th>\n",
              "      <th>long_frac</th>\n",
              "      <th>short_frac</th>\n",
              "      <th>flat_frac</th>\n",
              "      <th>trade_count</th>\n",
              "      <th>bh_total_return</th>\n",
              "      <th>bh_annualized_return</th>\n",
              "      <th>bh_annualized_volatility</th>\n",
              "      <th>bh_sharpe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>AMGN</td>\n",
              "      <td>4416</td>\n",
              "      <td>0.078785</td>\n",
              "      <td>0.119090</td>\n",
              "      <td>0.294530</td>\n",
              "      <td>0.382020</td>\n",
              "      <td>0.419802</td>\n",
              "      <td>-0.246258</td>\n",
              "      <td>0.483601</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>...</td>\n",
              "      <td>0.963226</td>\n",
              "      <td>0.939312</td>\n",
              "      <td>0.415534</td>\n",
              "      <td>0.523777</td>\n",
              "      <td>0.060688</td>\n",
              "      <td>84</td>\n",
              "      <td>-0.146664</td>\n",
              "      <td>-0.209680</td>\n",
              "      <td>0.305772</td>\n",
              "      <td>-0.769582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AMZN</td>\n",
              "      <td>4417</td>\n",
              "      <td>-0.263604</td>\n",
              "      <td>-0.364847</td>\n",
              "      <td>0.354345</td>\n",
              "      <td>-1.280925</td>\n",
              "      <td>-1.407798</td>\n",
              "      <td>-0.396878</td>\n",
              "      <td>-0.919292</td>\n",
              "      <td>-0.000069</td>\n",
              "      <td>...</td>\n",
              "      <td>0.921993</td>\n",
              "      <td>0.938646</td>\n",
              "      <td>0.320353</td>\n",
              "      <td>0.618293</td>\n",
              "      <td>0.061354</td>\n",
              "      <td>73</td>\n",
              "      <td>0.104821</td>\n",
              "      <td>0.159358</td>\n",
              "      <td>0.362985</td>\n",
              "      <td>0.407364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>CAT</td>\n",
              "      <td>4416</td>\n",
              "      <td>-0.158503</td>\n",
              "      <td>-0.225893</td>\n",
              "      <td>0.347918</td>\n",
              "      <td>-0.735937</td>\n",
              "      <td>-0.817875</td>\n",
              "      <td>-0.271705</td>\n",
              "      <td>-0.831390</td>\n",
              "      <td>-0.000039</td>\n",
              "      <td>...</td>\n",
              "      <td>0.950269</td>\n",
              "      <td>0.944067</td>\n",
              "      <td>0.573596</td>\n",
              "      <td>0.370471</td>\n",
              "      <td>0.055933</td>\n",
              "      <td>81</td>\n",
              "      <td>-0.130198</td>\n",
              "      <td>-0.186948</td>\n",
              "      <td>0.354228</td>\n",
              "      <td>-0.584258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>CSCO</td>\n",
              "      <td>4416</td>\n",
              "      <td>-0.267382</td>\n",
              "      <td>-0.369741</td>\n",
              "      <td>0.234086</td>\n",
              "      <td>-1.972031</td>\n",
              "      <td>-2.286557</td>\n",
              "      <td>-0.311985</td>\n",
              "      <td>-1.185122</td>\n",
              "      <td>-0.000070</td>\n",
              "      <td>...</td>\n",
              "      <td>0.978960</td>\n",
              "      <td>0.961051</td>\n",
              "      <td>0.507473</td>\n",
              "      <td>0.453578</td>\n",
              "      <td>0.038949</td>\n",
              "      <td>61</td>\n",
              "      <td>0.130017</td>\n",
              "      <td>0.198842</td>\n",
              "      <td>0.235809</td>\n",
              "      <td>0.769079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>DIA</td>\n",
              "      <td>4408</td>\n",
              "      <td>-0.082453</td>\n",
              "      <td>-0.120064</td>\n",
              "      <td>0.193355</td>\n",
              "      <td>-0.661511</td>\n",
              "      <td>-0.761481</td>\n",
              "      <td>-0.224900</td>\n",
              "      <td>-0.533855</td>\n",
              "      <td>-0.000020</td>\n",
              "      <td>...</td>\n",
              "      <td>0.870610</td>\n",
              "      <td>0.979809</td>\n",
              "      <td>0.725499</td>\n",
              "      <td>0.254310</td>\n",
              "      <td>0.020191</td>\n",
              "      <td>47</td>\n",
              "      <td>-0.031810</td>\n",
              "      <td>-0.046914</td>\n",
              "      <td>0.195193</td>\n",
              "      <td>-0.246168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>DIS</td>\n",
              "      <td>4370</td>\n",
              "      <td>-0.242630</td>\n",
              "      <td>-0.340758</td>\n",
              "      <td>0.295608</td>\n",
              "      <td>-1.409521</td>\n",
              "      <td>-1.432984</td>\n",
              "      <td>-0.281929</td>\n",
              "      <td>-1.208668</td>\n",
              "      <td>-0.000064</td>\n",
              "      <td>...</td>\n",
              "      <td>0.944200</td>\n",
              "      <td>0.908924</td>\n",
              "      <td>0.520824</td>\n",
              "      <td>0.388101</td>\n",
              "      <td>0.091076</td>\n",
              "      <td>84</td>\n",
              "      <td>0.007318</td>\n",
              "      <td>0.010991</td>\n",
              "      <td>0.306695</td>\n",
              "      <td>0.035642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>JPM</td>\n",
              "      <td>4416</td>\n",
              "      <td>-0.372595</td>\n",
              "      <td>-0.499248</td>\n",
              "      <td>0.321658</td>\n",
              "      <td>-2.150243</td>\n",
              "      <td>-2.160641</td>\n",
              "      <td>-0.495557</td>\n",
              "      <td>-1.007449</td>\n",
              "      <td>-0.000106</td>\n",
              "      <td>...</td>\n",
              "      <td>0.953801</td>\n",
              "      <td>0.971241</td>\n",
              "      <td>0.361413</td>\n",
              "      <td>0.609828</td>\n",
              "      <td>0.028759</td>\n",
              "      <td>53</td>\n",
              "      <td>0.093133</td>\n",
              "      <td>0.141246</td>\n",
              "      <td>0.323585</td>\n",
              "      <td>0.408302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>KO</td>\n",
              "      <td>4416</td>\n",
              "      <td>0.110848</td>\n",
              "      <td>0.168792</td>\n",
              "      <td>0.186566</td>\n",
              "      <td>0.836008</td>\n",
              "      <td>1.101752</td>\n",
              "      <td>-0.116962</td>\n",
              "      <td>1.443140</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>...</td>\n",
              "      <td>0.988402</td>\n",
              "      <td>0.976902</td>\n",
              "      <td>0.495245</td>\n",
              "      <td>0.481658</td>\n",
              "      <td>0.023098</td>\n",
              "      <td>61</td>\n",
              "      <td>0.003404</td>\n",
              "      <td>0.005055</td>\n",
              "      <td>0.187840</td>\n",
              "      <td>0.026841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>NKE</td>\n",
              "      <td>4416</td>\n",
              "      <td>-0.200960</td>\n",
              "      <td>-0.283128</td>\n",
              "      <td>0.417414</td>\n",
              "      <td>-0.797429</td>\n",
              "      <td>-0.814938</td>\n",
              "      <td>-0.349062</td>\n",
              "      <td>-0.811112</td>\n",
              "      <td>-0.000051</td>\n",
              "      <td>...</td>\n",
              "      <td>0.733227</td>\n",
              "      <td>0.964900</td>\n",
              "      <td>0.809330</td>\n",
              "      <td>0.155571</td>\n",
              "      <td>0.035100</td>\n",
              "      <td>47</td>\n",
              "      <td>-0.319929</td>\n",
              "      <td>-0.435633</td>\n",
              "      <td>0.419046</td>\n",
              "      <td>-1.365125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SPY</td>\n",
              "      <td>4417</td>\n",
              "      <td>-0.092966</td>\n",
              "      <td>-0.134752</td>\n",
              "      <td>0.212124</td>\n",
              "      <td>-0.682334</td>\n",
              "      <td>-0.747779</td>\n",
              "      <td>-0.240745</td>\n",
              "      <td>-0.559730</td>\n",
              "      <td>-0.000022</td>\n",
              "      <td>...</td>\n",
              "      <td>0.866528</td>\n",
              "      <td>0.970115</td>\n",
              "      <td>0.719266</td>\n",
              "      <td>0.250849</td>\n",
              "      <td>0.029885</td>\n",
              "      <td>47</td>\n",
              "      <td>-0.016873</td>\n",
              "      <td>-0.024926</td>\n",
              "      <td>0.213149</td>\n",
              "      <td>-0.118423</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>V</td>\n",
              "      <td>4416</td>\n",
              "      <td>-0.127093</td>\n",
              "      <td>-0.182638</td>\n",
              "      <td>0.229383</td>\n",
              "      <td>-0.879196</td>\n",
              "      <td>-1.103704</td>\n",
              "      <td>-0.222321</td>\n",
              "      <td>-0.821503</td>\n",
              "      <td>-0.000031</td>\n",
              "      <td>...</td>\n",
              "      <td>0.954474</td>\n",
              "      <td>0.964900</td>\n",
              "      <td>0.598732</td>\n",
              "      <td>0.366168</td>\n",
              "      <td>0.035100</td>\n",
              "      <td>81</td>\n",
              "      <td>0.236605</td>\n",
              "      <td>0.370385</td>\n",
              "      <td>0.239610</td>\n",
              "      <td>1.315020</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11 rows \u00d7 25 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   asset_id  steps  total_return  annualized_return  annualized_volatility  \\\n",
              "9      AMGN   4416      0.078785           0.119090               0.294530   \n",
              "0      AMZN   4417     -0.263604          -0.364847               0.354345   \n",
              "8       CAT   4416     -0.158503          -0.225893               0.347918   \n",
              "6      CSCO   4416     -0.267382          -0.369741               0.234086   \n",
              "10      DIA   4408     -0.082453          -0.120064               0.193355   \n",
              "2       DIS   4370     -0.242630          -0.340758               0.295608   \n",
              "7       JPM   4416     -0.372595          -0.499248               0.321658   \n",
              "1        KO   4416      0.110848           0.168792               0.186566   \n",
              "5       NKE   4416     -0.200960          -0.283128               0.417414   \n",
              "4       SPY   4417     -0.092966          -0.134752               0.212124   \n",
              "3         V   4416     -0.127093          -0.182638               0.229383   \n",
              "\n",
              "      sharpe   sortino  max_drawdown    calmar  avg_reward  ...  position_std  \\\n",
              "9   0.382020  0.419802     -0.246258  0.483601    0.000017  ...      0.963226   \n",
              "0  -1.280925 -1.407798     -0.396878 -0.919292   -0.000069  ...      0.921993   \n",
              "8  -0.735937 -0.817875     -0.271705 -0.831390   -0.000039  ...      0.950269   \n",
              "6  -1.972031 -2.286557     -0.311985 -1.185122   -0.000070  ...      0.978960   \n",
              "10 -0.661511 -0.761481     -0.224900 -0.533855   -0.000020  ...      0.870610   \n",
              "2  -1.409521 -1.432984     -0.281929 -1.208668   -0.000064  ...      0.944200   \n",
              "7  -2.150243 -2.160641     -0.495557 -1.007449   -0.000106  ...      0.953801   \n",
              "1   0.836008  1.101752     -0.116962  1.443140    0.000024  ...      0.988402   \n",
              "5  -0.797429 -0.814938     -0.349062 -0.811112   -0.000051  ...      0.733227   \n",
              "4  -0.682334 -0.747779     -0.240745 -0.559730   -0.000022  ...      0.866528   \n",
              "3  -0.879196 -1.103704     -0.222321 -0.821503   -0.000031  ...      0.954474   \n",
              "\n",
              "    avg_abs_position  long_frac  short_frac  flat_frac  trade_count  \\\n",
              "9           0.939312   0.415534    0.523777   0.060688           84   \n",
              "0           0.938646   0.320353    0.618293   0.061354           73   \n",
              "8           0.944067   0.573596    0.370471   0.055933           81   \n",
              "6           0.961051   0.507473    0.453578   0.038949           61   \n",
              "10          0.979809   0.725499    0.254310   0.020191           47   \n",
              "2           0.908924   0.520824    0.388101   0.091076           84   \n",
              "7           0.971241   0.361413    0.609828   0.028759           53   \n",
              "1           0.976902   0.495245    0.481658   0.023098           61   \n",
              "5           0.964900   0.809330    0.155571   0.035100           47   \n",
              "4           0.970115   0.719266    0.250849   0.029885           47   \n",
              "3           0.964900   0.598732    0.366168   0.035100           81   \n",
              "\n",
              "    bh_total_return  bh_annualized_return  bh_annualized_volatility  bh_sharpe  \n",
              "9         -0.146664             -0.209680                  0.305772  -0.769582  \n",
              "0          0.104821              0.159358                  0.362985   0.407364  \n",
              "8         -0.130198             -0.186948                  0.354228  -0.584258  \n",
              "6          0.130017              0.198842                  0.235809   0.769079  \n",
              "10        -0.031810             -0.046914                  0.195193  -0.246168  \n",
              "2          0.007318              0.010991                  0.306695   0.035642  \n",
              "7          0.093133              0.141246                  0.323585   0.408302  \n",
              "1          0.003404              0.005055                  0.187840   0.026841  \n",
              "5         -0.319929             -0.435633                  0.419046  -1.365125  \n",
              "4         -0.016873             -0.024926                  0.213149  -0.118423  \n",
              "3          0.236605              0.370385                  0.239610   1.315020  \n",
              "\n",
              "[11 rows x 25 columns]"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eval_cfg = EvalConfig(\n",
        "    annual_trading_days=252,\n",
        "    regular_hours_only=dataset_kwargs.get(\"regular_hours_only\", True),\n",
        "    timeframe=dataset_kwargs.get(\"timeframe\", \"15min\"),\n",
        ")\n",
        "\n",
        "results: List[Dict[str, float]] = []\n",
        "for idx, asset_id in enumerate(test_dataset.asset_ids, start=1):\n",
        "    print(f\"[{idx}/{len(test_dataset.asset_ids)}] Evaluating {asset_id}...\")\n",
        "    metrics = eval_asset(model, test_dataset, asset_id, eval_cfg)\n",
        "    if metrics:\n",
        "        results.append(metrics)\n",
        "\n",
        "if not results:\n",
        "    raise RuntimeError(\"No evaluation results produced.\")\n",
        "\n",
        "df = pd.DataFrame(results).sort_values(\"asset_id\")\n",
        "df.head(11)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "6a86b146",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>asset_id</th>\n",
              "      <th>total_return</th>\n",
              "      <th>bh_total_return</th>\n",
              "      <th>sharpe</th>\n",
              "      <th>bh_sharpe</th>\n",
              "      <th>ret_diff</th>\n",
              "      <th>sharpe_diff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>AMGN</td>\n",
              "      <td>0.078785</td>\n",
              "      <td>-0.146664</td>\n",
              "      <td>0.382020</td>\n",
              "      <td>-0.769582</td>\n",
              "      <td>0.225449</td>\n",
              "      <td>1.151602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AMZN</td>\n",
              "      <td>-0.263604</td>\n",
              "      <td>0.104821</td>\n",
              "      <td>-1.280925</td>\n",
              "      <td>0.407364</td>\n",
              "      <td>-0.368426</td>\n",
              "      <td>-1.688289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>CAT</td>\n",
              "      <td>-0.158503</td>\n",
              "      <td>-0.130198</td>\n",
              "      <td>-0.735937</td>\n",
              "      <td>-0.584258</td>\n",
              "      <td>-0.028305</td>\n",
              "      <td>-0.151679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>CSCO</td>\n",
              "      <td>-0.267382</td>\n",
              "      <td>0.130017</td>\n",
              "      <td>-1.972031</td>\n",
              "      <td>0.769079</td>\n",
              "      <td>-0.397399</td>\n",
              "      <td>-2.741110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>DIA</td>\n",
              "      <td>-0.082453</td>\n",
              "      <td>-0.031810</td>\n",
              "      <td>-0.661511</td>\n",
              "      <td>-0.246168</td>\n",
              "      <td>-0.050643</td>\n",
              "      <td>-0.415343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>DIS</td>\n",
              "      <td>-0.242630</td>\n",
              "      <td>0.007318</td>\n",
              "      <td>-1.409521</td>\n",
              "      <td>0.035642</td>\n",
              "      <td>-0.249948</td>\n",
              "      <td>-1.445163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>JPM</td>\n",
              "      <td>-0.372595</td>\n",
              "      <td>0.093133</td>\n",
              "      <td>-2.150243</td>\n",
              "      <td>0.408302</td>\n",
              "      <td>-0.465728</td>\n",
              "      <td>-2.558544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>KO</td>\n",
              "      <td>0.110848</td>\n",
              "      <td>0.003404</td>\n",
              "      <td>0.836008</td>\n",
              "      <td>0.026841</td>\n",
              "      <td>0.107444</td>\n",
              "      <td>0.809166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>NKE</td>\n",
              "      <td>-0.200960</td>\n",
              "      <td>-0.319929</td>\n",
              "      <td>-0.797429</td>\n",
              "      <td>-1.365125</td>\n",
              "      <td>0.118969</td>\n",
              "      <td>0.567695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SPY</td>\n",
              "      <td>-0.092966</td>\n",
              "      <td>-0.016873</td>\n",
              "      <td>-0.682334</td>\n",
              "      <td>-0.118423</td>\n",
              "      <td>-0.076093</td>\n",
              "      <td>-0.563911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>V</td>\n",
              "      <td>-0.127093</td>\n",
              "      <td>0.236605</td>\n",
              "      <td>-0.879196</td>\n",
              "      <td>1.315020</td>\n",
              "      <td>-0.363698</td>\n",
              "      <td>-2.194217</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   asset_id  total_return  bh_total_return    sharpe  bh_sharpe  ret_diff  \\\n",
              "9      AMGN      0.078785        -0.146664  0.382020  -0.769582  0.225449   \n",
              "0      AMZN     -0.263604         0.104821 -1.280925   0.407364 -0.368426   \n",
              "8       CAT     -0.158503        -0.130198 -0.735937  -0.584258 -0.028305   \n",
              "6      CSCO     -0.267382         0.130017 -1.972031   0.769079 -0.397399   \n",
              "10      DIA     -0.082453        -0.031810 -0.661511  -0.246168 -0.050643   \n",
              "2       DIS     -0.242630         0.007318 -1.409521   0.035642 -0.249948   \n",
              "7       JPM     -0.372595         0.093133 -2.150243   0.408302 -0.465728   \n",
              "1        KO      0.110848         0.003404  0.836008   0.026841  0.107444   \n",
              "5       NKE     -0.200960        -0.319929 -0.797429  -1.365125  0.118969   \n",
              "4       SPY     -0.092966        -0.016873 -0.682334  -0.118423 -0.076093   \n",
              "3         V     -0.127093         0.236605 -0.879196   1.315020 -0.363698   \n",
              "\n",
              "    sharpe_diff  \n",
              "9      1.151602  \n",
              "0     -1.688289  \n",
              "8     -0.151679  \n",
              "6     -2.741110  \n",
              "10    -0.415343  \n",
              "2     -1.445163  \n",
              "7     -2.558544  \n",
              "1      0.809166  \n",
              "5      0.567695  \n",
              "4     -0.563911  \n",
              "3     -2.194217  "
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ret_analysis = df[[\"asset_id\", \"total_return\", \"bh_total_return\", \"sharpe\", \"bh_sharpe\"]].copy()\n",
        "ret_analysis[\"ret_diff\"] = ret_analysis[\"total_return\"] - ret_analysis[\"bh_total_return\"]\n",
        "ret_analysis[\"sharpe_diff\"] = ret_analysis[\"sharpe\"] - ret_analysis[\"bh_sharpe\"]\n",
        "ret_analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved per-asset metrics to C:\\python\\koulu\\Gradu\\logs\\jepa6_ppo_final1_test_metrics.csv\n",
            "Saved summary to C:\\python\\koulu\\Gradu\\logs\\jepa6_ppo_final1_test_summary.csv\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>steps</th>\n",
              "      <th>total_return</th>\n",
              "      <th>annualized_return</th>\n",
              "      <th>annualized_volatility</th>\n",
              "      <th>sharpe</th>\n",
              "      <th>sortino</th>\n",
              "      <th>max_drawdown</th>\n",
              "      <th>calmar</th>\n",
              "      <th>avg_reward</th>\n",
              "      <th>reward_volatility</th>\n",
              "      <th>...</th>\n",
              "      <th>position_std</th>\n",
              "      <th>avg_abs_position</th>\n",
              "      <th>long_frac</th>\n",
              "      <th>short_frac</th>\n",
              "      <th>flat_frac</th>\n",
              "      <th>trade_count</th>\n",
              "      <th>bh_total_return</th>\n",
              "      <th>bh_annualized_return</th>\n",
              "      <th>bh_annualized_volatility</th>\n",
              "      <th>bh_sharpe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>4411.272727</td>\n",
              "      <td>-0.147141</td>\n",
              "      <td>-0.203017</td>\n",
              "      <td>0.280635</td>\n",
              "      <td>-0.850100</td>\n",
              "      <td>-0.910200</td>\n",
              "      <td>-0.287118</td>\n",
              "      <td>-0.541034</td>\n",
              "      <td>-0.000039</td>\n",
              "      <td>0.003467</td>\n",
              "      <td>...</td>\n",
              "      <td>0.920517</td>\n",
              "      <td>0.956352</td>\n",
              "      <td>0.549751</td>\n",
              "      <td>0.406600</td>\n",
              "      <td>0.043648</td>\n",
              "      <td>65.363636</td>\n",
              "      <td>-0.006380</td>\n",
              "      <td>-0.001657</td>\n",
              "      <td>0.285810</td>\n",
              "      <td>-0.011028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>median</th>\n",
              "      <td>4416.000000</td>\n",
              "      <td>-0.158503</td>\n",
              "      <td>-0.225893</td>\n",
              "      <td>0.294530</td>\n",
              "      <td>-0.797429</td>\n",
              "      <td>-0.817875</td>\n",
              "      <td>-0.271705</td>\n",
              "      <td>-0.821503</td>\n",
              "      <td>-0.000039</td>\n",
              "      <td>0.003639</td>\n",
              "      <td>...</td>\n",
              "      <td>0.950269</td>\n",
              "      <td>0.964900</td>\n",
              "      <td>0.520824</td>\n",
              "      <td>0.388101</td>\n",
              "      <td>0.035100</td>\n",
              "      <td>61.000000</td>\n",
              "      <td>0.003404</td>\n",
              "      <td>0.005055</td>\n",
              "      <td>0.305772</td>\n",
              "      <td>0.026841</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows \u00d7 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              steps  total_return  annualized_return  annualized_volatility  \\\n",
              "mean    4411.272727     -0.147141          -0.203017               0.280635   \n",
              "median  4416.000000     -0.158503          -0.225893               0.294530   \n",
              "\n",
              "          sharpe   sortino  max_drawdown    calmar  avg_reward  \\\n",
              "mean   -0.850100 -0.910200     -0.287118 -0.541034   -0.000039   \n",
              "median -0.797429 -0.817875     -0.271705 -0.821503   -0.000039   \n",
              "\n",
              "        reward_volatility  ...  position_std  avg_abs_position  long_frac  \\\n",
              "mean             0.003467  ...      0.920517          0.956352   0.549751   \n",
              "median           0.003639  ...      0.950269          0.964900   0.520824   \n",
              "\n",
              "        short_frac  flat_frac  trade_count  bh_total_return  \\\n",
              "mean      0.406600   0.043648    65.363636        -0.006380   \n",
              "median    0.388101   0.035100    61.000000         0.003404   \n",
              "\n",
              "        bh_annualized_return  bh_annualized_volatility  bh_sharpe  \n",
              "mean               -0.001657                  0.285810  -0.011028  \n",
              "median              0.005055                  0.305772   0.026841  \n",
              "\n",
              "[2 rows x 24 columns]"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save outputs\n",
        "os.makedirs(PROJECT_ROOT / log_root, exist_ok=True)\n",
        "metrics_path = PROJECT_ROOT / log_root / f\"{model_name}_test_metrics.csv\"\n",
        "summary_path = PROJECT_ROOT / log_root / f\"{model_name}_test_summary.csv\"\n",
        "\n",
        "df.to_csv(metrics_path, index=False)\n",
        "summary = df.drop(columns=[\"asset_id\"]).agg([\"mean\", \"median\"])\n",
        "summary.to_csv(summary_path)\n",
        "\n",
        "print(f\"Saved per-asset metrics to {metrics_path}\")\n",
        "print(f\"Saved summary to {summary_path}\")\n",
        "summary\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".graduenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}