python: can't open file '/root/DrlPpoTransformer/train_ppo.py': [Errno 2] No such file or directory
python: can't open file '/root/DrlPpoTransformer/train_PPO_initial.py.py': [Errno 2] No such file or directory
python: can't open file '/root/DrlPpoTransformer/train_PPO_initial.py.py': [Errno 2] No such file or directory
Loading datasets...
[Dataset_Finance_MultiAsset] Global date splits: train_end=2024-07-26 14:20:00+00:00 val_end=2025-04-25 15:45:00+00:00 n_dates=96878 n_train=67814 n_val=14533 n_test=14531
[Dataset_Finance_MultiAsset] Global date splits: train_end=2024-07-26 14:20:00+00:00 val_end=2025-04-25 15:45:00+00:00 n_dates=96878 n_train=67814 n_val=14533 n_test=14531
Building environments...
Loading JEPA encoder...
/root/DrlPpoTransformer/.venv/lib/python3.11/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(
Loading JEPA weights from checkpoints/jepa_initial/best.pt
/root/DrlPpoTransformer/train_PPO_initial.py:113: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(checkpoint_path, map_location="cpu")
Using cuda device
Logging to logs/PPO_6
/root/DrlPpoTransformer/.venv/lib/python3.11/site-packages/stable_baselines3/common/callbacks.py:418: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.subproc_vec_env.SubprocVecEnv object at 0x75530e16bf50> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x75530e9e8c50>
  warnings.warn("Training and eval env are not of the same type" f"{self.training_env} != {self.eval_env}")
-----------------------------
| time/              |      |
|    fps             | 1835 |
|    iterations      | 1    |
|    time_elapsed    | 4    |
|    total_timesteps | 8192 |
-----------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1199         |
|    iterations           | 2            |
|    time_elapsed         | 13           |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 0.0013038549 |
|    clip_fraction        | 0.00711      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.42        |
|    explained_variance   | -5.5         |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0104      |
|    n_updates            | 8            |
|    policy_gradient_loss | -0.00117     |
|    std                  | 1.01         |
|    value_loss           | 0.0442       |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1159         |
|    iterations           | 3            |
|    time_elapsed         | 21           |
|    total_timesteps      | 24576        |
| train/                  |              |
|    approx_kl            | 0.0024424733 |
|    clip_fraction        | 0.0138       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.43        |
|    explained_variance   | -3.08        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0173      |
|    n_updates            | 16           |
|    policy_gradient_loss | -0.00164     |
|    std                  | 1.01         |
|    value_loss           | 0.0052       |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 1181        |
|    iterations           | 4           |
|    time_elapsed         | 27          |
|    total_timesteps      | 32768       |
| train/                  |             |
|    approx_kl            | 0.004034692 |
|    clip_fraction        | 0.0345      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.42       |
|    explained_variance   | -2.46       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0151     |
|    n_updates            | 24          |
|    policy_gradient_loss | -0.00346    |
|    std                  | 1           |
|    value_loss           | 0.00259     |
-----------------------------------------
/root/DrlPpoTransformer/.venv/lib/python3.11/site-packages/stable_baselines3/common/evaluation.py:70: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.
  warnings.warn(
Eval num_timesteps=40000, episode_reward=-0.34 +/- 0.02
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | -0.339       |
| time/                   |              |
|    total_timesteps      | 40000        |
| train/                  |              |
|    approx_kl            | 0.0034716013 |
|    clip_fraction        | 0.0305       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.42        |
|    explained_variance   | -3.36        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0201      |
|    n_updates            | 32           |
|    policy_gradient_loss | -0.00254     |
|    std                  | 1            |
|    value_loss           | 0.00174      |
------------------------------------------
New best mean reward!
------------------------------
| time/              |       |
|    fps             | 766   |
|    iterations      | 5     |
|    time_elapsed    | 53    |
|    total_timesteps | 40960 |
------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 854         |
|    iterations           | 6           |
|    time_elapsed         | 57          |
|    total_timesteps      | 49152       |
| train/                  |             |
|    approx_kl            | 0.004083233 |
|    clip_fraction        | 0.0299      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.42       |
|    explained_variance   | -4.38       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0227     |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.00335    |
|    std                  | 0.995       |
|    value_loss           | 0.0012      |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 930          |
|    iterations           | 7            |
|    time_elapsed         | 61           |
|    total_timesteps      | 57344        |
| train/                  |              |
|    approx_kl            | 0.0045348834 |
|    clip_fraction        | 0.0396       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.41        |
|    explained_variance   | -6.14        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.019       |
|    n_updates            | 48           |
|    policy_gradient_loss | -0.00217     |
|    std                  | 0.99         |
|    value_loss           | 0.000908     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 993         |
|    iterations           | 8           |
|    time_elapsed         | 65          |
|    total_timesteps      | 65536       |
| train/                  |             |
|    approx_kl            | 0.007421758 |
|    clip_fraction        | 0.0629      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.41       |
|    explained_variance   | -8.42       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0197     |
|    n_updates            | 56          |
|    policy_gradient_loss | -0.0039     |
|    std                  | 0.988       |
|    value_loss           | 0.000744    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 1045        |
|    iterations           | 9           |
|    time_elapsed         | 70          |
|    total_timesteps      | 73728       |
| train/                  |             |
|    approx_kl            | 0.005182715 |
|    clip_fraction        | 0.059       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.4        |
|    explained_variance   | -8.59       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.021      |
|    n_updates            | 64          |
|    policy_gradient_loss | -0.00159    |
|    std                  | 0.983       |
|    value_loss           | 0.00056     |
-----------------------------------------
/root/DrlPpoTransformer/.venv/lib/python3.11/site-packages/stable_baselines3/common/evaluation.py:70: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.
  warnings.warn(
Eval num_timesteps=80000, episode_reward=-0.50 +/- 0.03
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.502      |
| time/                   |             |
|    total_timesteps      | 80000       |
| train/                  |             |
|    approx_kl            | 0.005750312 |
|    clip_fraction        | 0.0581      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.4        |
|    explained_variance   | -7.21       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0193     |
|    n_updates            | 72          |
|    policy_gradient_loss | -0.00305    |
|    std                  | 0.98        |
|    value_loss           | 0.000484    |
-----------------------------------------
------------------------------
| time/              |       |
|    fps             | 858   |
|    iterations      | 10    |
|    time_elapsed    | 95    |
|    total_timesteps | 81920 |
------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 893         |
|    iterations           | 11          |
|    time_elapsed         | 100         |
|    total_timesteps      | 90112       |
| train/                  |             |
|    approx_kl            | 0.006954588 |
|    clip_fraction        | 0.0534      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.39       |
|    explained_variance   | -8.11       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0185     |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.00237    |
|    std                  | 0.968       |
|    value_loss           | 0.000396    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 926         |
|    iterations           | 12          |
|    time_elapsed         | 106         |
|    total_timesteps      | 98304       |
| train/                  |             |
|    approx_kl            | 0.008324382 |
|    clip_fraction        | 0.082       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.39       |
|    explained_variance   | -8.8        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0214     |
|    n_updates            | 88          |
|    policy_gradient_loss | -0.00171    |
|    std                  | 0.971       |
|    value_loss           | 0.000354    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 954          |
|    iterations           | 13           |
|    time_elapsed         | 111          |
|    total_timesteps      | 106496       |
| train/                  |              |
|    approx_kl            | 0.0053307926 |
|    clip_fraction        | 0.0628       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.39        |
|    explained_variance   | -7.01        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.019       |
|    n_updates            | 96           |
|    policy_gradient_loss | -0.00207     |
|    std                  | 0.97         |
|    value_loss           | 0.000305     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 979          |
|    iterations           | 14           |
|    time_elapsed         | 117          |
|    total_timesteps      | 114688       |
| train/                  |              |
|    approx_kl            | 0.0073299147 |
|    clip_fraction        | 0.0683       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.39        |
|    explained_variance   | -6.2         |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0185      |
|    n_updates            | 104          |
|    policy_gradient_loss | -0.00108     |
|    std                  | 0.964        |
|    value_loss           | 0.00026      |
------------------------------------------
Eval num_timesteps=120000, episode_reward=-0.49 +/- 0.06
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | -0.49        |
| time/                   |              |
|    total_timesteps      | 120000       |
| train/                  |              |
|    approx_kl            | 0.0066465284 |
|    clip_fraction        | 0.0714       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.38        |
|    explained_variance   | -4.14        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0163      |
|    n_updates            | 112          |
|    policy_gradient_loss | -0.00196     |
|    std                  | 0.953        |
|    value_loss           | 0.000245     |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 829    |
|    iterations      | 15     |
|    time_elapsed    | 148    |
|    total_timesteps | 122880 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 847          |
|    iterations           | 16           |
|    time_elapsed         | 154          |
|    total_timesteps      | 131072       |
| train/                  |              |
|    approx_kl            | 0.0062263673 |
|    clip_fraction        | 0.0811       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.37        |
|    explained_variance   | -4.96        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0198      |
|    n_updates            | 120          |
|    policy_gradient_loss | -0.00183     |
|    std                  | 0.95         |
|    value_loss           | 0.000199     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 865          |
|    iterations           | 17           |
|    time_elapsed         | 160          |
|    total_timesteps      | 139264       |
| train/                  |              |
|    approx_kl            | 0.0067600817 |
|    clip_fraction        | 0.0804       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.36        |
|    explained_variance   | -4.56        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0193      |
|    n_updates            | 128          |
|    policy_gradient_loss | -0.00255     |
|    std                  | 0.943        |
|    value_loss           | 0.000179     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 880         |
|    iterations           | 18          |
|    time_elapsed         | 167         |
|    total_timesteps      | 147456      |
| train/                  |             |
|    approx_kl            | 0.006358889 |
|    clip_fraction        | 0.0837      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.36       |
|    explained_variance   | -3.92       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0177     |
|    n_updates            | 136         |
|    policy_gradient_loss | -0.00224    |
|    std                  | 0.94        |
|    value_loss           | 0.000169    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 894          |
|    iterations           | 19           |
|    time_elapsed         | 174          |
|    total_timesteps      | 155648       |
| train/                  |              |
|    approx_kl            | 0.0080414405 |
|    clip_fraction        | 0.0762       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.35        |
|    explained_variance   | -3.65        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0144      |
|    n_updates            | 144          |
|    policy_gradient_loss | -0.0025      |
|    std                  | 0.933        |
|    value_loss           | 0.00016      |
------------------------------------------
Eval num_timesteps=160000, episode_reward=-0.15 +/- 0.09
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | -0.15        |
| time/                   |              |
|    total_timesteps      | 160000       |
| train/                  |              |
|    approx_kl            | 0.0075300112 |
|    clip_fraction        | 0.101        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.35        |
|    explained_variance   | -2.72        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.02        |
|    n_updates            | 152          |
|    policy_gradient_loss | -0.00109     |
|    std                  | 0.931        |
|    value_loss           | 0.000156     |
------------------------------------------
New best mean reward!
-------------------------------
| time/              |        |
|    fps             | 800    |
|    iterations      | 20     |
|    time_elapsed    | 204    |
|    total_timesteps | 163840 |
-------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 817        |
|    iterations           | 21         |
|    time_elapsed         | 210        |
|    total_timesteps      | 172032     |
| train/                  |            |
|    approx_kl            | 0.00990569 |
|    clip_fraction        | 0.0956     |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.34      |
|    explained_variance   | -2.87      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0141    |
|    n_updates            | 160        |
|    policy_gradient_loss | 0.00028    |
|    std                  | 0.924      |
|    value_loss           | 0.000161   |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 837         |
|    iterations           | 22          |
|    time_elapsed         | 215         |
|    total_timesteps      | 180224      |
| train/                  |             |
|    approx_kl            | 0.013109299 |
|    clip_fraction        | 0.0951      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.34       |
|    explained_variance   | -2.75       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0152     |
|    n_updates            | 168         |
|    policy_gradient_loss | -0.00114    |
|    std                  | 0.917       |
|    value_loss           | 0.000135    |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 856        |
|    iterations           | 23         |
|    time_elapsed         | 220        |
|    total_timesteps      | 188416     |
| train/                  |            |
|    approx_kl            | 0.00845536 |
|    clip_fraction        | 0.0848     |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.33      |
|    explained_variance   | -2.39      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0157    |
|    n_updates            | 176        |
|    policy_gradient_loss | -0.00274   |
|    std                  | 0.907      |
|    value_loss           | 0.00013    |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 874         |
|    iterations           | 24          |
|    time_elapsed         | 224         |
|    total_timesteps      | 196608      |
| train/                  |             |
|    approx_kl            | 0.008821815 |
|    clip_fraction        | 0.0961      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.31       |
|    explained_variance   | -2.01       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0205     |
|    n_updates            | 184         |
|    policy_gradient_loss | -0.00227    |
|    std                  | 0.894       |
|    value_loss           | 0.000124    |
-----------------------------------------
Eval num_timesteps=200000, episode_reward=-0.02 +/- 0.10
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.0236     |
| time/                   |             |
|    total_timesteps      | 200000      |
| train/                  |             |
|    approx_kl            | 0.008383422 |
|    clip_fraction        | 0.0922      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.3        |
|    explained_variance   | -1.97       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0168     |
|    n_updates            | 192         |
|    policy_gradient_loss | -0.00311    |
|    std                  | 0.889       |
|    value_loss           | 0.000113    |
-----------------------------------------
New best mean reward!
-------------------------------
| time/              |        |
|    fps             | 817    |
|    iterations      | 25     |
|    time_elapsed    | 250    |
|    total_timesteps | 204800 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 835         |
|    iterations           | 26          |
|    time_elapsed         | 254         |
|    total_timesteps      | 212992      |
| train/                  |             |
|    approx_kl            | 0.007686638 |
|    clip_fraction        | 0.102       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.3        |
|    explained_variance   | -2.84       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0126     |
|    n_updates            | 200         |
|    policy_gradient_loss | -0.00123    |
|    std                  | 0.885       |
|    value_loss           | 0.000264    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 853          |
|    iterations           | 27           |
|    time_elapsed         | 259          |
|    total_timesteps      | 221184       |
| train/                  |              |
|    approx_kl            | 0.0075691673 |
|    clip_fraction        | 0.0863       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.29        |
|    explained_variance   | -1.76        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0149      |
|    n_updates            | 208          |
|    policy_gradient_loss | -0.00317     |
|    std                  | 0.875        |
|    value_loss           | 0.000114     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 871         |
|    iterations           | 28          |
|    time_elapsed         | 263         |
|    total_timesteps      | 229376      |
| train/                  |             |
|    approx_kl            | 0.011234863 |
|    clip_fraction        | 0.103       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.28       |
|    explained_variance   | -2.05       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0189     |
|    n_updates            | 216         |
|    policy_gradient_loss | -0.00143    |
|    std                  | 0.863       |
|    value_loss           | 0.000104    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 888         |
|    iterations           | 29          |
|    time_elapsed         | 267         |
|    total_timesteps      | 237568      |
| train/                  |             |
|    approx_kl            | 0.005547364 |
|    clip_fraction        | 0.0831      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.27       |
|    explained_variance   | -1.53       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0116     |
|    n_updates            | 224         |
|    policy_gradient_loss | -3.31e-05   |
|    std                  | 0.855       |
|    value_loss           | 0.00013     |
-----------------------------------------
Eval num_timesteps=240000, episode_reward=0.00 +/- 0.08
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | 0.00123     |
| time/                   |             |
|    total_timesteps      | 240000      |
| train/                  |             |
|    approx_kl            | 0.007964453 |
|    clip_fraction        | 0.0881      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.26       |
|    explained_variance   | -1.49       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00903    |
|    n_updates            | 232         |
|    policy_gradient_loss | -0.00107    |
|    std                  | 0.852       |
|    value_loss           | 0.000105    |
-----------------------------------------
New best mean reward!
-------------------------------
| time/              |        |
|    fps             | 841    |
|    iterations      | 30     |
|    time_elapsed    | 292    |
|    total_timesteps | 245760 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 854          |
|    iterations           | 31           |
|    time_elapsed         | 297          |
|    total_timesteps      | 253952       |
| train/                  |              |
|    approx_kl            | 0.0088297045 |
|    clip_fraction        | 0.0846       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.25        |
|    explained_variance   | -1.3         |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0145      |
|    n_updates            | 240          |
|    policy_gradient_loss | -0.000339    |
|    std                  | 0.844        |
|    value_loss           | 9.95e-05     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 867         |
|    iterations           | 32          |
|    time_elapsed         | 302         |
|    total_timesteps      | 262144      |
| train/                  |             |
|    approx_kl            | 0.008263223 |
|    clip_fraction        | 0.0942      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.24       |
|    explained_variance   | -2.4        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0159     |
|    n_updates            | 248         |
|    policy_gradient_loss | -0.00117    |
|    std                  | 0.835       |
|    value_loss           | 6.99e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 880         |
|    iterations           | 33          |
|    time_elapsed         | 307         |
|    total_timesteps      | 270336      |
| train/                  |             |
|    approx_kl            | 0.008321985 |
|    clip_fraction        | 0.101       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.23       |
|    explained_variance   | -2.81       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0131     |
|    n_updates            | 256         |
|    policy_gradient_loss | -0.000332   |
|    std                  | 0.824       |
|    value_loss           | 8.71e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 898         |
|    iterations           | 34          |
|    time_elapsed         | 309         |
|    total_timesteps      | 278528      |
| train/                  |             |
|    approx_kl            | 0.014896866 |
|    clip_fraction        | 0.182       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.23       |
|    explained_variance   | -0.943      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00978     |
|    n_updates            | 257         |
|    policy_gradient_loss | 0.00532     |
|    std                  | 0.824       |
|    value_loss           | 0.000176    |
-----------------------------------------
Eval num_timesteps=280000, episode_reward=-0.04 +/- 0.09
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | -0.0384      |
| time/                   |              |
|    total_timesteps      | 280000       |
| train/                  |              |
|    approx_kl            | 0.0061863665 |
|    clip_fraction        | 0.0745       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.22        |
|    explained_variance   | -0.633       |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0119      |
|    n_updates            | 265          |
|    policy_gradient_loss | 0.000113     |
|    std                  | 0.82         |
|    value_loss           | 0.00116      |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 844    |
|    iterations      | 35     |
|    time_elapsed    | 339    |
|    total_timesteps | 286720 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 857          |
|    iterations           | 36           |
|    time_elapsed         | 343          |
|    total_timesteps      | 294912       |
| train/                  |              |
|    approx_kl            | 0.0071837106 |
|    clip_fraction        | 0.0885       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.22        |
|    explained_variance   | -1.08        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0193      |
|    n_updates            | 273          |
|    policy_gradient_loss | -0.000148    |
|    std                  | 0.818        |
|    value_loss           | 0.000497     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 870          |
|    iterations           | 37           |
|    time_elapsed         | 348          |
|    total_timesteps      | 303104       |
| train/                  |              |
|    approx_kl            | 0.0070196916 |
|    clip_fraction        | 0.0732       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.22        |
|    explained_variance   | -1.72        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0132      |
|    n_updates            | 281          |
|    policy_gradient_loss | -0.000836    |
|    std                  | 0.814        |
|    value_loss           | 8.58e-05     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 883         |
|    iterations           | 38          |
|    time_elapsed         | 352         |
|    total_timesteps      | 311296      |
| train/                  |             |
|    approx_kl            | 0.006271419 |
|    clip_fraction        | 0.0675      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.21       |
|    explained_variance   | -1.29       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0174     |
|    n_updates            | 289         |
|    policy_gradient_loss | -0.00127    |
|    std                  | 0.804       |
|    value_loss           | 5.99e-05    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 895          |
|    iterations           | 39           |
|    time_elapsed         | 356          |
|    total_timesteps      | 319488       |
| train/                  |              |
|    approx_kl            | 0.0076826382 |
|    clip_fraction        | 0.0816       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.2         |
|    explained_variance   | -0.806       |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00964     |
|    n_updates            | 297          |
|    policy_gradient_loss | 0.00091      |
|    std                  | 0.798        |
|    value_loss           | 7.1e-05      |
------------------------------------------
Eval num_timesteps=320000, episode_reward=0.03 +/- 0.10
Episode length: 2340.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 2.34e+03   |
|    mean_reward          | 0.0319     |
| time/                   |            |
|    total_timesteps      | 320000     |
| train/                  |            |
|    approx_kl            | 0.01031594 |
|    clip_fraction        | 0.0925     |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.19      |
|    explained_variance   | -0.804     |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00607   |
|    n_updates            | 305        |
|    policy_gradient_loss | 0.00124    |
|    std                  | 0.795      |
|    value_loss           | 7.9e-05    |
----------------------------------------
New best mean reward!
-------------------------------
| time/              |        |
|    fps             | 853    |
|    iterations      | 40     |
|    time_elapsed    | 383    |
|    total_timesteps | 327680 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 861         |
|    iterations           | 41          |
|    time_elapsed         | 389         |
|    total_timesteps      | 335872      |
| train/                  |             |
|    approx_kl            | 0.008004029 |
|    clip_fraction        | 0.0865      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.19       |
|    explained_variance   | -1.29       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00885    |
|    n_updates            | 313         |
|    policy_gradient_loss | 0.00011     |
|    std                  | 0.792       |
|    value_loss           | 5.81e-05    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 869          |
|    iterations           | 42           |
|    time_elapsed         | 395          |
|    total_timesteps      | 344064       |
| train/                  |              |
|    approx_kl            | 0.0074413954 |
|    clip_fraction        | 0.0953       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.18        |
|    explained_variance   | -1.65        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0156      |
|    n_updates            | 321          |
|    policy_gradient_loss | 0.000471     |
|    std                  | 0.786        |
|    value_loss           | 4.65e-05     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 877         |
|    iterations           | 43          |
|    time_elapsed         | 401         |
|    total_timesteps      | 352256      |
| train/                  |             |
|    approx_kl            | 0.009171458 |
|    clip_fraction        | 0.0856      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.18       |
|    explained_variance   | -0.474      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0107     |
|    n_updates            | 329         |
|    policy_gradient_loss | -0.00116    |
|    std                  | 0.785       |
|    value_loss           | 8.03e-05    |
-----------------------------------------
Eval num_timesteps=360000, episode_reward=0.02 +/- 0.11
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | 0.0192      |
| time/                   |             |
|    total_timesteps      | 360000      |
| train/                  |             |
|    approx_kl            | 0.009250247 |
|    clip_fraction        | 0.094       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.17       |
|    explained_variance   | -1.01       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00893    |
|    n_updates            | 337         |
|    policy_gradient_loss | -0.00013    |
|    std                  | 0.78        |
|    value_loss           | 8.02e-05    |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 837    |
|    iterations      | 44     |
|    time_elapsed    | 430    |
|    total_timesteps | 360448 |
-------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 845        |
|    iterations           | 45         |
|    time_elapsed         | 436        |
|    total_timesteps      | 368640     |
| train/                  |            |
|    approx_kl            | 0.01067979 |
|    clip_fraction        | 0.112      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.17      |
|    explained_variance   | -0.748     |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0107    |
|    n_updates            | 345        |
|    policy_gradient_loss | 0.000441   |
|    std                  | 0.774      |
|    value_loss           | 9.87e-05   |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 850         |
|    iterations           | 46          |
|    time_elapsed         | 443         |
|    total_timesteps      | 376832      |
| train/                  |             |
|    approx_kl            | 0.009774332 |
|    clip_fraction        | 0.11        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.16       |
|    explained_variance   | -0.627      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0144     |
|    n_updates            | 353         |
|    policy_gradient_loss | -0.000863   |
|    std                  | 0.767       |
|    value_loss           | 6.85e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 854         |
|    iterations           | 47          |
|    time_elapsed         | 450         |
|    total_timesteps      | 385024      |
| train/                  |             |
|    approx_kl            | 0.010020058 |
|    clip_fraction        | 0.118       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.46       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.016      |
|    n_updates            | 361         |
|    policy_gradient_loss | 0.00133     |
|    std                  | 0.765       |
|    value_loss           | 8.27e-05    |
-----------------------------------------
Early stopping at step 2 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 863         |
|    iterations           | 48          |
|    time_elapsed         | 455         |
|    total_timesteps      | 393216      |
| train/                  |             |
|    approx_kl            | 0.017853169 |
|    clip_fraction        | 0.143       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.543      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.000388    |
|    n_updates            | 364         |
|    policy_gradient_loss | 0.00447     |
|    std                  | 0.764       |
|    value_loss           | 6.25e-05    |
-----------------------------------------
Early stopping at step 5 due to reaching max kl: 0.03
Eval num_timesteps=400000, episode_reward=-0.06 +/- 0.08
Episode length: 2340.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 2.34e+03   |
|    mean_reward          | -0.0568    |
| time/                   |            |
|    total_timesteps      | 400000     |
| train/                  |            |
|    approx_kl            | 0.01947566 |
|    clip_fraction        | 0.125      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.702     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.00354    |
|    n_updates            | 370        |
|    policy_gradient_loss | 1.2e-05    |
|    std                  | 0.759      |
|    value_loss           | 5.46e-05   |
----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 826    |
|    iterations      | 49     |
|    time_elapsed    | 485    |
|    total_timesteps | 401408 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 833         |
|    iterations           | 50          |
|    time_elapsed         | 491         |
|    total_timesteps      | 409600      |
| train/                  |             |
|    approx_kl            | 0.010068546 |
|    clip_fraction        | 0.102       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.14       |
|    explained_variance   | -0.594      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00456    |
|    n_updates            | 378         |
|    policy_gradient_loss | -0.000729   |
|    std                  | 0.754       |
|    value_loss           | 5.47e-05    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 841          |
|    iterations           | 51           |
|    time_elapsed         | 496          |
|    total_timesteps      | 417792       |
| train/                  |              |
|    approx_kl            | 0.0119785555 |
|    clip_fraction        | 0.131        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.13        |
|    explained_variance   | -0.636       |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0102      |
|    n_updates            | 386          |
|    policy_gradient_loss | 0.000558     |
|    std                  | 0.75         |
|    value_loss           | 6.2e-05      |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 848         |
|    iterations           | 52          |
|    time_elapsed         | 501         |
|    total_timesteps      | 425984      |
| train/                  |             |
|    approx_kl            | 0.010632647 |
|    clip_fraction        | 0.121       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.13       |
|    explained_variance   | -0.758      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0181     |
|    n_updates            | 394         |
|    policy_gradient_loss | 0.00208     |
|    std                  | 0.747       |
|    value_loss           | 4.95e-05    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 855          |
|    iterations           | 53           |
|    time_elapsed         | 507          |
|    total_timesteps      | 434176       |
| train/                  |              |
|    approx_kl            | 0.0124223195 |
|    clip_fraction        | 0.139        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.12        |
|    explained_variance   | -1.05        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00531     |
|    n_updates            | 402          |
|    policy_gradient_loss | 0.00307      |
|    std                  | 0.741        |
|    value_loss           | 4.1e-05      |
------------------------------------------
Eval num_timesteps=440000, episode_reward=0.01 +/- 0.07
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | 0.0147      |
| time/                   |             |
|    total_timesteps      | 440000      |
| train/                  |             |
|    approx_kl            | 0.010899214 |
|    clip_fraction        | 0.114       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.12       |
|    explained_variance   | -0.848      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0102     |
|    n_updates            | 410         |
|    policy_gradient_loss | -0.000645   |
|    std                  | 0.738       |
|    value_loss           | 4.14e-05    |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 827    |
|    iterations      | 54     |
|    time_elapsed    | 534    |
|    total_timesteps | 442368 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 834         |
|    iterations           | 55          |
|    time_elapsed         | 539         |
|    total_timesteps      | 450560      |
| train/                  |             |
|    approx_kl            | 0.010917992 |
|    clip_fraction        | 0.121       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.11       |
|    explained_variance   | -0.741      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0167     |
|    n_updates            | 418         |
|    policy_gradient_loss | 0.00108     |
|    std                  | 0.732       |
|    value_loss           | 5.28e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 841         |
|    iterations           | 56          |
|    time_elapsed         | 545         |
|    total_timesteps      | 458752      |
| train/                  |             |
|    approx_kl            | 0.012217013 |
|    clip_fraction        | 0.123       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.1        |
|    explained_variance   | -0.807      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.000682   |
|    n_updates            | 426         |
|    policy_gradient_loss | 0.00176     |
|    std                  | 0.725       |
|    value_loss           | 4.09e-05    |
-----------------------------------------
Early stopping at step 2 due to reaching max kl: 0.02
----------------------------------------
| time/                   |            |
|    fps                  | 850        |
|    iterations           | 57         |
|    time_elapsed         | 549        |
|    total_timesteps      | 466944     |
| train/                  |            |
|    approx_kl            | 0.01914025 |
|    clip_fraction        | 0.139      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.1       |
|    explained_variance   | -0.7       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00172   |
|    n_updates            | 429        |
|    policy_gradient_loss | 0.00511    |
|    std                  | 0.722      |
|    value_loss           | 4.09e-05   |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 857         |
|    iterations           | 58          |
|    time_elapsed         | 554         |
|    total_timesteps      | 475136      |
| train/                  |             |
|    approx_kl            | 0.013438644 |
|    clip_fraction        | 0.145       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.09       |
|    explained_variance   | -0.997      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00864    |
|    n_updates            | 437         |
|    policy_gradient_loss | 0.00215     |
|    std                  | 0.712       |
|    value_loss           | 0.00109     |
-----------------------------------------
Early stopping at step 6 due to reaching max kl: 0.02
Eval num_timesteps=480000, episode_reward=-0.05 +/- 0.07
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.0529     |
| time/                   |             |
|    total_timesteps      | 480000      |
| train/                  |             |
|    approx_kl            | 0.022299252 |
|    clip_fraction        | 0.151       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.08       |
|    explained_variance   | -0.412      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00235    |
|    n_updates            | 444         |
|    policy_gradient_loss | 0.00258     |
|    std                  | 0.708       |
|    value_loss           | 8.65e-05    |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 833    |
|    iterations      | 59     |
|    time_elapsed    | 579    |
|    total_timesteps | 483328 |
-------------------------------
Early stopping at step 4 due to reaching max kl: 0.02
-----------------------------------------
| time/                   |             |
|    fps                  | 841         |
|    iterations           | 60          |
|    time_elapsed         | 584         |
|    total_timesteps      | 491520      |
| train/                  |             |
|    approx_kl            | 0.024497952 |
|    clip_fraction        | 0.146       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.07       |
|    explained_variance   | -0.36       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00694    |
|    n_updates            | 449         |
|    policy_gradient_loss | 0.00495     |
|    std                  | 0.706       |
|    value_loss           | 6.04e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 846         |
|    iterations           | 61          |
|    time_elapsed         | 590         |
|    total_timesteps      | 499712      |
| train/                  |             |
|    approx_kl            | 0.009862393 |
|    clip_fraction        | 0.123       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.07       |
|    explained_variance   | -0.791      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0104     |
|    n_updates            | 457         |
|    policy_gradient_loss | 0.00199     |
|    std                  | 0.704       |
|    value_loss           | 4.3e-05     |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 851          |
|    iterations           | 62           |
|    time_elapsed         | 596          |
|    total_timesteps      | 507904       |
| train/                  |              |
|    approx_kl            | 0.0104428865 |
|    clip_fraction        | 0.137        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.07        |
|    explained_variance   | -0.649       |
|    learning_rate        | 0.0003       |
|    loss                 | -0.00849     |
|    n_updates            | 465          |
|    policy_gradient_loss | 0.00246      |
|    std                  | 0.703        |
|    value_loss           | 5.02e-05     |
------------------------------------------
Early stopping at step 6 due to reaching max kl: 0.02
-----------------------------------------
| time/                   |             |
|    fps                  | 856         |
|    iterations           | 63          |
|    time_elapsed         | 602         |
|    total_timesteps      | 516096      |
| train/                  |             |
|    approx_kl            | 0.014456863 |
|    clip_fraction        | 0.136       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.06       |
|    explained_variance   | -0.516      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0085      |
|    n_updates            | 472         |
|    policy_gradient_loss | 0.00245     |
|    std                  | 0.697       |
|    value_loss           | 4.47e-05    |
-----------------------------------------
Early stopping at step 6 due to reaching max kl: 0.02
Eval num_timesteps=520000, episode_reward=0.00 +/- 0.07
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | 0.00497     |
| time/                   |             |
|    total_timesteps      | 520000      |
| train/                  |             |
|    approx_kl            | 0.012104618 |
|    clip_fraction        | 0.118       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.05       |
|    explained_variance   | -0.352      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00711    |
|    n_updates            | 479         |
|    policy_gradient_loss | 0.00303     |
|    std                  | 0.691       |
|    value_loss           | 6.36e-05    |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 832    |
|    iterations      | 64     |
|    time_elapsed    | 630    |
|    total_timesteps | 524288 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 836         |
|    iterations           | 65          |
|    time_elapsed         | 636         |
|    total_timesteps      | 532480      |
| train/                  |             |
|    approx_kl            | 0.013942371 |
|    clip_fraction        | 0.139       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.05       |
|    explained_variance   | -0.303      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00869    |
|    n_updates            | 487         |
|    policy_gradient_loss | 0.003       |
|    std                  | 0.691       |
|    value_loss           | 0.000127    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 842         |
|    iterations           | 66          |
|    time_elapsed         | 642         |
|    total_timesteps      | 540672      |
| train/                  |             |
|    approx_kl            | 0.014112808 |
|    clip_fraction        | 0.153       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.05       |
|    explained_variance   | -0.585      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00836    |
|    n_updates            | 495         |
|    policy_gradient_loss | 0.00508     |
|    std                  | 0.685       |
|    value_loss           | 6.44e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 846         |
|    iterations           | 67          |
|    time_elapsed         | 648         |
|    total_timesteps      | 548864      |
| train/                  |             |
|    approx_kl            | 0.013956226 |
|    clip_fraction        | 0.161       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.04       |
|    explained_variance   | -0.43       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0157     |
|    n_updates            | 503         |
|    policy_gradient_loss | 0.00409     |
|    std                  | 0.68        |
|    value_loss           | 4.09e-05    |
-----------------------------------------
Early stopping at step 3 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 853         |
|    iterations           | 68          |
|    time_elapsed         | 652         |
|    total_timesteps      | 557056      |
| train/                  |             |
|    approx_kl            | 0.017329562 |
|    clip_fraction        | 0.155       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.03       |
|    explained_variance   | -0.713      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00318    |
|    n_updates            | 507         |
|    policy_gradient_loss | 0.00611     |
|    std                  | 0.676       |
|    value_loss           | 3.39e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.02
Eval num_timesteps=560000, episode_reward=0.01 +/- 0.08
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | 0.00532     |
| time/                   |             |
|    total_timesteps      | 560000      |
| train/                  |             |
|    approx_kl            | 0.014874339 |
|    clip_fraction        | 0.165       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.03       |
|    explained_variance   | -0.32       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00801     |
|    n_updates            | 508         |
|    policy_gradient_loss | 0.0105      |
|    std                  | 0.676       |
|    value_loss           | 4.47e-05    |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 832    |
|    iterations      | 69     |
|    time_elapsed    | 679    |
|    total_timesteps | 565248 |
-------------------------------
Early stopping at step 1 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 839         |
|    iterations           | 70          |
|    time_elapsed         | 682         |
|    total_timesteps      | 573440      |
| train/                  |             |
|    approx_kl            | 0.015996372 |
|    clip_fraction        | 0.158       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.03       |
|    explained_variance   | -0.314      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00618     |
|    n_updates            | 510         |
|    policy_gradient_loss | 0.00859     |
|    std                  | 0.675       |
|    value_loss           | 5.04e-05    |
-----------------------------------------
Early stopping at step 1 due to reaching max kl: 0.02
-----------------------------------------
| time/                   |             |
|    fps                  | 847         |
|    iterations           | 71          |
|    time_elapsed         | 686         |
|    total_timesteps      | 581632      |
| train/                  |             |
|    approx_kl            | 0.024969205 |
|    clip_fraction        | 0.159       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.03       |
|    explained_variance   | -0.32       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0116      |
|    n_updates            | 512         |
|    policy_gradient_loss | 0.00869     |
|    std                  | 0.674       |
|    value_loss           | 4.45e-05    |
-----------------------------------------
Early stopping at step 7 due to reaching max kl: 0.02
-----------------------------------------
| time/                   |             |
|    fps                  | 853         |
|    iterations           | 72          |
|    time_elapsed         | 690         |
|    total_timesteps      | 589824      |
| train/                  |             |
|    approx_kl            | 0.017900158 |
|    clip_fraction        | 0.165       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.02       |
|    explained_variance   | -0.414      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00487    |
|    n_updates            | 520         |
|    policy_gradient_loss | 0.0038      |
|    std                  | 0.671       |
|    value_loss           | 3.57e-05    |
-----------------------------------------
Early stopping at step 1 due to reaching max kl: 0.02
-----------------------------------------
| time/                   |             |
|    fps                  | 862         |
|    iterations           | 73          |
|    time_elapsed         | 693         |
|    total_timesteps      | 598016      |
| train/                  |             |
|    approx_kl            | 0.022590756 |
|    clip_fraction        | 0.191       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.02       |
|    explained_variance   | -0.581      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0101      |
|    n_updates            | 522         |
|    policy_gradient_loss | 0.013       |
|    std                  | 0.671       |
|    value_loss           | 2.89e-05    |
-----------------------------------------
Eval num_timesteps=600000, episode_reward=-0.00 +/- 0.09
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.00335    |
| time/                   |             |
|    total_timesteps      | 600000      |
| train/                  |             |
|    approx_kl            | 0.017499503 |
|    clip_fraction        | 0.17        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.361      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00786    |
|    n_updates            | 530         |
|    policy_gradient_loss | 0.00459     |
|    std                  | 0.664       |
|    value_loss           | 4.42e-05    |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 841    |
|    iterations      | 74     |
|    time_elapsed    | 720    |
|    total_timesteps | 606208 |
-------------------------------
Early stopping at step 1 due to reaching max kl: 0.02
-----------------------------------------
| time/                   |             |
|    fps                  | 848         |
|    iterations           | 75          |
|    time_elapsed         | 723         |
|    total_timesteps      | 614400      |
| train/                  |             |
|    approx_kl            | 0.014650083 |
|    clip_fraction        | 0.14        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.329      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00178    |
|    n_updates            | 532         |
|    policy_gradient_loss | 0.00536     |
|    std                  | 0.662       |
|    value_loss           | 9e-05       |
-----------------------------------------
Early stopping at step 1 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 856         |
|    iterations           | 76          |
|    time_elapsed         | 727         |
|    total_timesteps      | 622592      |
| train/                  |             |
|    approx_kl            | 0.017353028 |
|    clip_fraction        | 0.167       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.323      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00305     |
|    n_updates            | 534         |
|    policy_gradient_loss | 0.00958     |
|    std                  | 0.661       |
|    value_loss           | 5.92e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.02
-----------------------------------------
| time/                   |             |
|    fps                  | 863         |
|    iterations           | 77          |
|    time_elapsed         | 730         |
|    total_timesteps      | 630784      |
| train/                  |             |
|    approx_kl            | 0.022622287 |
|    clip_fraction        | 0.207       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.36       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00373     |
|    n_updates            | 535         |
|    policy_gradient_loss | 0.0138      |
|    std                  | 0.661       |
|    value_loss           | 3.36e-05    |
-----------------------------------------
Early stopping at step 3 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 870         |
|    iterations           | 78          |
|    time_elapsed         | 734         |
|    total_timesteps      | 638976      |
| train/                  |             |
|    approx_kl            | 0.020461848 |
|    clip_fraction        | 0.18        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1          |
|    explained_variance   | -0.37       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00157     |
|    n_updates            | 539         |
|    policy_gradient_loss | 0.006       |
|    std                  | 0.66        |
|    value_loss           | 3.4e-05     |
-----------------------------------------
Early stopping at step 1 due to reaching max kl: 0.02
Eval num_timesteps=640000, episode_reward=-0.01 +/- 0.10
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.00707    |
| time/                   |             |
|    total_timesteps      | 640000      |
| train/                  |             |
|    approx_kl            | 0.021486474 |
|    clip_fraction        | 0.184       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1          |
|    explained_variance   | -0.313      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00926     |
|    n_updates            | 541         |
|    policy_gradient_loss | 0.0132      |
|    std                  | 0.661       |
|    value_loss           | 4.34e-05    |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 851    |
|    iterations      | 79     |
|    time_elapsed    | 759    |
|    total_timesteps | 647168 |
-------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 859         |
|    iterations           | 80          |
|    time_elapsed         | 762         |
|    total_timesteps      | 655360      |
| train/                  |             |
|    approx_kl            | 0.022032049 |
|    clip_fraction        | 0.217       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1          |
|    explained_variance   | -0.28       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00268     |
|    n_updates            | 542         |
|    policy_gradient_loss | 0.0133      |
|    std                  | 0.661       |
|    value_loss           | 4.47e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.02
----------------------------------------
| time/                   |            |
|    fps                  | 866        |
|    iterations           | 81         |
|    time_elapsed         | 765        |
|    total_timesteps      | 663552     |
| train/                  |            |
|    approx_kl            | 0.02405877 |
|    clip_fraction        | 0.215      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1         |
|    explained_variance   | -0.388     |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00359   |
|    n_updates            | 543        |
|    policy_gradient_loss | 0.00645    |
|    std                  | 0.661      |
|    value_loss           | 3.19e-05   |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.02
-----------------------------------------
| time/                   |             |
|    fps                  | 873         |
|    iterations           | 82          |
|    time_elapsed         | 768         |
|    total_timesteps      | 671744      |
| train/                  |             |
|    approx_kl            | 0.022549063 |
|    clip_fraction        | 0.217       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1          |
|    explained_variance   | -0.381      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00798     |
|    n_updates            | 544         |
|    policy_gradient_loss | 0.018       |
|    std                  | 0.661       |
|    value_loss           | 3.31e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
----------------------------------------
| time/                   |            |
|    fps                  | 880        |
|    iterations           | 83         |
|    time_elapsed         | 771        |
|    total_timesteps      | 679936     |
| train/                  |            |
|    approx_kl            | 0.02548489 |
|    clip_fraction        | 0.213      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1         |
|    explained_variance   | -0.375     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.00772    |
|    n_updates            | 545        |
|    policy_gradient_loss | 0.0177     |
|    std                  | 0.661      |
|    value_loss           | 3.77e-05   |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.02
Eval num_timesteps=680000, episode_reward=-0.03 +/- 0.08
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.0253     |
| time/                   |             |
|    total_timesteps      | 680000      |
| train/                  |             |
|    approx_kl            | 0.021832295 |
|    clip_fraction        | 0.224       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1          |
|    explained_variance   | -0.259      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.000698   |
|    n_updates            | 546         |
|    policy_gradient_loss | 0.0141      |
|    std                  | 0.661       |
|    value_loss           | 3.75e-05    |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 863    |
|    iterations      | 84     |
|    time_elapsed    | 797    |
|    total_timesteps | 688128 |
-------------------------------
Early stopping at step 0 due to reaching max kl: 0.02
-----------------------------------------
| time/                   |             |
|    fps                  | 870         |
|    iterations           | 85          |
|    time_elapsed         | 800         |
|    total_timesteps      | 696320      |
| train/                  |             |
|    approx_kl            | 0.023429751 |
|    clip_fraction        | 0.229       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1          |
|    explained_variance   | -0.242      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00393     |
|    n_updates            | 547         |
|    policy_gradient_loss | 0.014       |
|    std                  | 0.661       |
|    value_loss           | 3.9e-05     |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 877         |
|    iterations           | 86          |
|    time_elapsed         | 803         |
|    total_timesteps      | 704512      |
| train/                  |             |
|    approx_kl            | 0.025387032 |
|    clip_fraction        | 0.225       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1          |
|    explained_variance   | -0.505      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00549     |
|    n_updates            | 548         |
|    policy_gradient_loss | 0.0167      |
|    std                  | 0.661       |
|    value_loss           | 3.22e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 884         |
|    iterations           | 87          |
|    time_elapsed         | 806         |
|    total_timesteps      | 712704      |
| train/                  |             |
|    approx_kl            | 0.029292816 |
|    clip_fraction        | 0.237       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.272      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.004       |
|    n_updates            | 549         |
|    policy_gradient_loss | 0.014       |
|    std                  | 0.661       |
|    value_loss           | 3.81e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
Eval num_timesteps=720000, episode_reward=-0.08 +/- 0.12
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.0783     |
| time/                   |             |
|    total_timesteps      | 720000      |
| train/                  |             |
|    approx_kl            | 0.030460948 |
|    clip_fraction        | 0.225       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.362      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.000951    |
|    n_updates            | 550         |
|    policy_gradient_loss | 0.011       |
|    std                  | 0.661       |
|    value_loss           | 3.32e-05    |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 868    |
|    iterations      | 88     |
|    time_elapsed    | 830    |
|    total_timesteps | 720896 |
-------------------------------
Early stopping at step 0 due to reaching max kl: 0.02
----------------------------------------
| time/                   |            |
|    fps                  | 875        |
|    iterations           | 89         |
|    time_elapsed         | 832        |
|    total_timesteps      | 729088     |
| train/                  |            |
|    approx_kl            | 0.02481103 |
|    clip_fraction        | 0.219      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.01      |
|    explained_variance   | -0.199     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0069     |
|    n_updates            | 551        |
|    policy_gradient_loss | 0.0169     |
|    std                  | 0.661      |
|    value_loss           | 5.3e-05    |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.02
-----------------------------------------
| time/                   |             |
|    fps                  | 882         |
|    iterations           | 90          |
|    time_elapsed         | 835         |
|    total_timesteps      | 737280      |
| train/                  |             |
|    approx_kl            | 0.024280671 |
|    clip_fraction        | 0.234       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.403      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00536    |
|    n_updates            | 552         |
|    policy_gradient_loss | 0.00468     |
|    std                  | 0.661       |
|    value_loss           | 3.45e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.02
-----------------------------------------
| time/                   |             |
|    fps                  | 889         |
|    iterations           | 91          |
|    time_elapsed         | 838         |
|    total_timesteps      | 745472      |
| train/                  |             |
|    approx_kl            | 0.022160692 |
|    clip_fraction        | 0.215       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.0646     |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00655    |
|    n_updates            | 553         |
|    policy_gradient_loss | 0.0068      |
|    std                  | 0.661       |
|    value_loss           | 0.000102    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 896         |
|    iterations           | 92          |
|    time_elapsed         | 840         |
|    total_timesteps      | 753664      |
| train/                  |             |
|    approx_kl            | 0.026857363 |
|    clip_fraction        | 0.221       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.101      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0113      |
|    n_updates            | 554         |
|    policy_gradient_loss | 0.0213      |
|    std                  | 0.661       |
|    value_loss           | 0.00011     |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
Eval num_timesteps=760000, episode_reward=-0.07 +/- 0.07
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.0743     |
| time/                   |             |
|    total_timesteps      | 760000      |
| train/                  |             |
|    approx_kl            | 0.026426136 |
|    clip_fraction        | 0.247       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.335      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00396     |
|    n_updates            | 555         |
|    policy_gradient_loss | 0.014       |
|    std                  | 0.661       |
|    value_loss           | 3.99e-05    |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 882    |
|    iterations      | 93     |
|    time_elapsed    | 863    |
|    total_timesteps | 761856 |
-------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 889         |
|    iterations           | 94          |
|    time_elapsed         | 865         |
|    total_timesteps      | 770048      |
| train/                  |             |
|    approx_kl            | 0.026243947 |
|    clip_fraction        | 0.253       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.359      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00291     |
|    n_updates            | 556         |
|    policy_gradient_loss | 0.0129      |
|    std                  | 0.661       |
|    value_loss           | 3.16e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 896         |
|    iterations           | 95          |
|    time_elapsed         | 868         |
|    total_timesteps      | 778240      |
| train/                  |             |
|    approx_kl            | 0.028117374 |
|    clip_fraction        | 0.224       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.49       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.000407    |
|    n_updates            | 557         |
|    policy_gradient_loss | 0.0104      |
|    std                  | 0.661       |
|    value_loss           | 2.76e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
----------------------------------------
| time/                   |            |
|    fps                  | 903        |
|    iterations           | 96         |
|    time_elapsed         | 870        |
|    total_timesteps      | 786432     |
| train/                  |            |
|    approx_kl            | 0.02951799 |
|    clip_fraction        | 0.245      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.01      |
|    explained_variance   | -0.252     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.00576    |
|    n_updates            | 558        |
|    policy_gradient_loss | 0.0158     |
|    std                  | 0.661      |
|    value_loss           | 3.81e-05   |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
---------------------------------------
| time/                   |           |
|    fps                  | 910       |
|    iterations           | 97        |
|    time_elapsed         | 872       |
|    total_timesteps      | 794624    |
| train/                  |           |
|    approx_kl            | 0.0282362 |
|    clip_fraction        | 0.242     |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.01     |
|    explained_variance   | -0.337    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.00256   |
|    n_updates            | 559       |
|    policy_gradient_loss | 0.0126    |
|    std                  | 0.661     |
|    value_loss           | 3.52e-05  |
---------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
Eval num_timesteps=800000, episode_reward=-0.14 +/- 0.11
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.144      |
| time/                   |             |
|    total_timesteps      | 800000      |
| train/                  |             |
|    approx_kl            | 0.025899777 |
|    clip_fraction        | 0.233       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.299      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00139     |
|    n_updates            | 560         |
|    policy_gradient_loss | 0.0114      |
|    std                  | 0.661       |
|    value_loss           | 3.29e-05    |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 896    |
|    iterations      | 98     |
|    time_elapsed    | 895    |
|    total_timesteps | 802816 |
-------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
----------------------------------------
| time/                   |            |
|    fps                  | 903        |
|    iterations           | 99         |
|    time_elapsed         | 897        |
|    total_timesteps      | 811008     |
| train/                  |            |
|    approx_kl            | 0.02756356 |
|    clip_fraction        | 0.258      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.01      |
|    explained_variance   | -0.446     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0109     |
|    n_updates            | 561        |
|    policy_gradient_loss | 0.0209     |
|    std                  | 0.661      |
|    value_loss           | 2.9e-05    |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 910         |
|    iterations           | 100         |
|    time_elapsed         | 899         |
|    total_timesteps      | 819200      |
| train/                  |             |
|    approx_kl            | 0.038292084 |
|    clip_fraction        | 0.246       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.437      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.012       |
|    n_updates            | 562         |
|    policy_gradient_loss | 0.022       |
|    std                  | 0.661       |
|    value_loss           | 3.13e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 917         |
|    iterations           | 101         |
|    time_elapsed         | 902         |
|    total_timesteps      | 827392      |
| train/                  |             |
|    approx_kl            | 0.027504675 |
|    clip_fraction        | 0.235       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.264      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00381    |
|    n_updates            | 563         |
|    policy_gradient_loss | 0.00622     |
|    std                  | 0.661       |
|    value_loss           | 4.26e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 923         |
|    iterations           | 102         |
|    time_elapsed         | 904         |
|    total_timesteps      | 835584      |
| train/                  |             |
|    approx_kl            | 0.030425025 |
|    clip_fraction        | 0.226       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.28       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.011       |
|    n_updates            | 564         |
|    policy_gradient_loss | 0.021       |
|    std                  | 0.661       |
|    value_loss           | 4.32e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
Eval num_timesteps=840000, episode_reward=-0.08 +/- 0.14
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.0777     |
| time/                   |             |
|    total_timesteps      | 840000      |
| train/                  |             |
|    approx_kl            | 0.032906096 |
|    clip_fraction        | 0.246       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.399      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00802     |
|    n_updates            | 565         |
|    policy_gradient_loss | 0.0181      |
|    std                  | 0.661       |
|    value_loss           | 2.91e-05    |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 910    |
|    iterations      | 103    |
|    time_elapsed    | 926    |
|    total_timesteps | 843776 |
-------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
----------------------------------------
| time/                   |            |
|    fps                  | 917        |
|    iterations           | 104        |
|    time_elapsed         | 928        |
|    total_timesteps      | 851968     |
| train/                  |            |
|    approx_kl            | 0.02828488 |
|    clip_fraction        | 0.23       |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.01      |
|    explained_variance   | -0.435     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.00685    |
|    n_updates            | 566        |
|    policy_gradient_loss | 0.0169     |
|    std                  | 0.661      |
|    value_loss           | 2.64e-05   |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 923         |
|    iterations           | 105         |
|    time_elapsed         | 931         |
|    total_timesteps      | 860160      |
| train/                  |             |
|    approx_kl            | 0.031483155 |
|    clip_fraction        | 0.246       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.472      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0152      |
|    n_updates            | 567         |
|    policy_gradient_loss | 0.0253      |
|    std                  | 0.661       |
|    value_loss           | 2.96e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.02
-----------------------------------------
| time/                   |             |
|    fps                  | 930         |
|    iterations           | 106         |
|    time_elapsed         | 933         |
|    total_timesteps      | 868352      |
| train/                  |             |
|    approx_kl            | 0.023564879 |
|    clip_fraction        | 0.235       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.148      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00315    |
|    n_updates            | 568         |
|    policy_gradient_loss | 0.00687     |
|    std                  | 0.661       |
|    value_loss           | 6.34e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
----------------------------------------
| time/                   |            |
|    fps                  | 936        |
|    iterations           | 107        |
|    time_elapsed         | 935        |
|    total_timesteps      | 876544     |
| train/                  |            |
|    approx_kl            | 0.02996131 |
|    clip_fraction        | 0.218      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.01      |
|    explained_variance   | -0.207     |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00186   |
|    n_updates            | 569        |
|    policy_gradient_loss | 0.00817    |
|    std                  | 0.661      |
|    value_loss           | 5.25e-05   |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
Eval num_timesteps=880000, episode_reward=-0.11 +/- 0.07
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.114      |
| time/                   |             |
|    total_timesteps      | 880000      |
| train/                  |             |
|    approx_kl            | 0.030765211 |
|    clip_fraction        | 0.266       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.249      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0098      |
|    n_updates            | 570         |
|    policy_gradient_loss | 0.0198      |
|    std                  | 0.661       |
|    value_loss           | 5.6e-05     |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 923    |
|    iterations      | 108    |
|    time_elapsed    | 957    |
|    total_timesteps | 884736 |
-------------------------------
Early stopping at step 0 due to reaching max kl: 0.02
-----------------------------------------
| time/                   |             |
|    fps                  | 930         |
|    iterations           | 109         |
|    time_elapsed         | 960         |
|    total_timesteps      | 892928      |
| train/                  |             |
|    approx_kl            | 0.024784997 |
|    clip_fraction        | 0.234       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.244      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00341     |
|    n_updates            | 571         |
|    policy_gradient_loss | 0.0134      |
|    std                  | 0.661       |
|    value_loss           | 4.81e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.02
-----------------------------------------
| time/                   |             |
|    fps                  | 936         |
|    iterations           | 110         |
|    time_elapsed         | 962         |
|    total_timesteps      | 901120      |
| train/                  |             |
|    approx_kl            | 0.024777565 |
|    clip_fraction        | 0.236       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.219      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00558     |
|    n_updates            | 572         |
|    policy_gradient_loss | 0.0156      |
|    std                  | 0.661       |
|    value_loss           | 6.35e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 942         |
|    iterations           | 111         |
|    time_elapsed         | 964         |
|    total_timesteps      | 909312      |
| train/                  |             |
|    approx_kl            | 0.027914077 |
|    clip_fraction        | 0.24        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.575      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0118      |
|    n_updates            | 573         |
|    policy_gradient_loss | 0.0218      |
|    std                  | 0.661       |
|    value_loss           | 2.55e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 948         |
|    iterations           | 112         |
|    time_elapsed         | 967         |
|    total_timesteps      | 917504      |
| train/                  |             |
|    approx_kl            | 0.027410667 |
|    clip_fraction        | 0.25        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.713      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0214      |
|    n_updates            | 574         |
|    policy_gradient_loss | 0.0314      |
|    std                  | 0.661       |
|    value_loss           | 2.03e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
Eval num_timesteps=920000, episode_reward=-0.11 +/- 0.08
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.11       |
| time/                   |             |
|    total_timesteps      | 920000      |
| train/                  |             |
|    approx_kl            | 0.029159911 |
|    clip_fraction        | 0.251       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.469      |
|    learning_rate        | 0.0003      |
|    loss                 | 5.12e-05    |
|    n_updates            | 575         |
|    policy_gradient_loss | 0.0101      |
|    std                  | 0.661       |
|    value_loss           | 2.87e-05    |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 935    |
|    iterations      | 113    |
|    time_elapsed    | 989    |
|    total_timesteps | 925696 |
-------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 941         |
|    iterations           | 114         |
|    time_elapsed         | 991         |
|    total_timesteps      | 933888      |
| train/                  |             |
|    approx_kl            | 0.027711893 |
|    clip_fraction        | 0.228       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.588      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00196     |
|    n_updates            | 576         |
|    policy_gradient_loss | 0.012       |
|    std                  | 0.661       |
|    value_loss           | 2.36e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 947         |
|    iterations           | 115         |
|    time_elapsed         | 993         |
|    total_timesteps      | 942080      |
| train/                  |             |
|    approx_kl            | 0.031434294 |
|    clip_fraction        | 0.257       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.243      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00585     |
|    n_updates            | 577         |
|    policy_gradient_loss | 0.0159      |
|    std                  | 0.661       |
|    value_loss           | 3.96e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.02
-----------------------------------------
| time/                   |             |
|    fps                  | 953         |
|    iterations           | 116         |
|    time_elapsed         | 996         |
|    total_timesteps      | 950272      |
| train/                  |             |
|    approx_kl            | 0.024960019 |
|    clip_fraction        | 0.247       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.201      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00133     |
|    n_updates            | 578         |
|    policy_gradient_loss | 0.0114      |
|    std                  | 0.661       |
|    value_loss           | 5.22e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 959         |
|    iterations           | 117         |
|    time_elapsed         | 998         |
|    total_timesteps      | 958464      |
| train/                  |             |
|    approx_kl            | 0.027586212 |
|    clip_fraction        | 0.254       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.319      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0044      |
|    n_updates            | 579         |
|    policy_gradient_loss | 0.0144      |
|    std                  | 0.661       |
|    value_loss           | 3.82e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
Eval num_timesteps=960000, episode_reward=-0.05 +/- 0.07
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.0524     |
| time/                   |             |
|    total_timesteps      | 960000      |
| train/                  |             |
|    approx_kl            | 0.025531631 |
|    clip_fraction        | 0.256       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.192      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00932     |
|    n_updates            | 580         |
|    policy_gradient_loss | 0.0193      |
|    std                  | 0.661       |
|    value_loss           | 5.14e-05    |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 947    |
|    iterations      | 118    |
|    time_elapsed    | 1020   |
|    total_timesteps | 966656 |
-------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 953         |
|    iterations           | 119         |
|    time_elapsed         | 1022        |
|    total_timesteps      | 974848      |
| train/                  |             |
|    approx_kl            | 0.036154747 |
|    clip_fraction        | 0.243       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.258      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0122      |
|    n_updates            | 581         |
|    policy_gradient_loss | 0.0222      |
|    std                  | 0.661       |
|    value_loss           | 4.67e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 959         |
|    iterations           | 120         |
|    time_elapsed         | 1024        |
|    total_timesteps      | 983040      |
| train/                  |             |
|    approx_kl            | 0.027928742 |
|    clip_fraction        | 0.224       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.61       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00289     |
|    n_updates            | 582         |
|    policy_gradient_loss | 0.0129      |
|    std                  | 0.661       |
|    value_loss           | 2.67e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 964         |
|    iterations           | 121         |
|    time_elapsed         | 1027        |
|    total_timesteps      | 991232      |
| train/                  |             |
|    approx_kl            | 0.030255552 |
|    clip_fraction        | 0.238       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.295      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0075      |
|    n_updates            | 583         |
|    policy_gradient_loss | 0.0175      |
|    std                  | 0.661       |
|    value_loss           | 3.36e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 970         |
|    iterations           | 122         |
|    time_elapsed         | 1029        |
|    total_timesteps      | 999424      |
| train/                  |             |
|    approx_kl            | 0.031233441 |
|    clip_fraction        | 0.271       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.565      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00724     |
|    n_updates            | 584         |
|    policy_gradient_loss | 0.0173      |
|    std                  | 0.661       |
|    value_loss           | 2.27e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
Eval num_timesteps=1000000, episode_reward=-0.08 +/- 0.10
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.0755     |
| time/                   |             |
|    total_timesteps      | 1000000     |
| train/                  |             |
|    approx_kl            | 0.030597027 |
|    clip_fraction        | 0.294       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.3        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00243     |
|    n_updates            | 585         |
|    policy_gradient_loss | 0.0125      |
|    std                  | 0.661       |
|    value_loss           | 3.66e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 958     |
|    iterations      | 123     |
|    time_elapsed    | 1051    |
|    total_timesteps | 1007616 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 964         |
|    iterations           | 124         |
|    time_elapsed         | 1053        |
|    total_timesteps      | 1015808     |
| train/                  |             |
|    approx_kl            | 0.032906465 |
|    clip_fraction        | 0.25        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.21       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00556     |
|    n_updates            | 586         |
|    policy_gradient_loss | 0.0156      |
|    std                  | 0.661       |
|    value_loss           | 5.02e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 969         |
|    iterations           | 125         |
|    time_elapsed         | 1055        |
|    total_timesteps      | 1024000     |
| train/                  |             |
|    approx_kl            | 0.025046308 |
|    clip_fraction        | 0.244       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.242      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00352    |
|    n_updates            | 587         |
|    policy_gradient_loss | 0.0065      |
|    std                  | 0.661       |
|    value_loss           | 6.7e-05     |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.02
-----------------------------------------
| time/                   |             |
|    fps                  | 975         |
|    iterations           | 126         |
|    time_elapsed         | 1058        |
|    total_timesteps      | 1032192     |
| train/                  |             |
|    approx_kl            | 0.023078457 |
|    clip_fraction        | 0.224       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.323      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0013     |
|    n_updates            | 588         |
|    policy_gradient_loss | 0.00873     |
|    std                  | 0.661       |
|    value_loss           | 3.68e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
Eval num_timesteps=1040000, episode_reward=-0.12 +/- 0.10
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.122      |
| time/                   |             |
|    total_timesteps      | 1040000     |
| train/                  |             |
|    approx_kl            | 0.028791025 |
|    clip_fraction        | 0.261       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.363      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0184      |
|    n_updates            | 589         |
|    policy_gradient_loss | 0.0285      |
|    std                  | 0.661       |
|    value_loss           | 3.82e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 962     |
|    iterations      | 127     |
|    time_elapsed    | 1080    |
|    total_timesteps | 1040384 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 968         |
|    iterations           | 128         |
|    time_elapsed         | 1082        |
|    total_timesteps      | 1048576     |
| train/                  |             |
|    approx_kl            | 0.026858753 |
|    clip_fraction        | 0.231       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.317      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00161     |
|    n_updates            | 590         |
|    policy_gradient_loss | 0.0116      |
|    std                  | 0.661       |
|    value_loss           | 3.71e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 973         |
|    iterations           | 129         |
|    time_elapsed         | 1085        |
|    total_timesteps      | 1056768     |
| train/                  |             |
|    approx_kl            | 0.026215114 |
|    clip_fraction        | 0.229       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.139      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00952     |
|    n_updates            | 591         |
|    policy_gradient_loss | 0.0195      |
|    std                  | 0.661       |
|    value_loss           | 7.04e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 979         |
|    iterations           | 130         |
|    time_elapsed         | 1087        |
|    total_timesteps      | 1064960     |
| train/                  |             |
|    approx_kl            | 0.028681554 |
|    clip_fraction        | 0.238       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.363      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0118      |
|    n_updates            | 592         |
|    policy_gradient_loss | 0.0218      |
|    std                  | 0.661       |
|    value_loss           | 3.96e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 984         |
|    iterations           | 131         |
|    time_elapsed         | 1089        |
|    total_timesteps      | 1073152     |
| train/                  |             |
|    approx_kl            | 0.026386784 |
|    clip_fraction        | 0.226       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.182      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00128    |
|    n_updates            | 593         |
|    policy_gradient_loss | 0.00874     |
|    std                  | 0.661       |
|    value_loss           | 5.37e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
Eval num_timesteps=1080000, episode_reward=-0.05 +/- 0.08
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.0452     |
| time/                   |             |
|    total_timesteps      | 1080000     |
| train/                  |             |
|    approx_kl            | 0.029170197 |
|    clip_fraction        | 0.277       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.244      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00789     |
|    n_updates            | 594         |
|    policy_gradient_loss | 0.0179      |
|    std                  | 0.661       |
|    value_loss           | 4.52e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 972     |
|    iterations      | 132     |
|    time_elapsed    | 1111    |
|    total_timesteps | 1081344 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.02
-----------------------------------------
| time/                   |             |
|    fps                  | 977         |
|    iterations           | 133         |
|    time_elapsed         | 1114        |
|    total_timesteps      | 1089536     |
| train/                  |             |
|    approx_kl            | 0.023593921 |
|    clip_fraction        | 0.217       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.317      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00581     |
|    n_updates            | 595         |
|    policy_gradient_loss | 0.0158      |
|    std                  | 0.661       |
|    value_loss           | 3.61e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 983         |
|    iterations           | 134         |
|    time_elapsed         | 1116        |
|    total_timesteps      | 1097728     |
| train/                  |             |
|    approx_kl            | 0.029950432 |
|    clip_fraction        | 0.26        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.411      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0127      |
|    n_updates            | 596         |
|    policy_gradient_loss | 0.0228      |
|    std                  | 0.661       |
|    value_loss           | 3.27e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.02
-----------------------------------------
| time/                   |             |
|    fps                  | 988         |
|    iterations           | 135         |
|    time_elapsed         | 1118        |
|    total_timesteps      | 1105920     |
| train/                  |             |
|    approx_kl            | 0.024306534 |
|    clip_fraction        | 0.219       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.276      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00735    |
|    n_updates            | 597         |
|    policy_gradient_loss | 0.00268     |
|    std                  | 0.661       |
|    value_loss           | 3.84e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 993         |
|    iterations           | 136         |
|    time_elapsed         | 1121        |
|    total_timesteps      | 1114112     |
| train/                  |             |
|    approx_kl            | 0.029044293 |
|    clip_fraction        | 0.271       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.27       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00561    |
|    n_updates            | 598         |
|    policy_gradient_loss | 0.00442     |
|    std                  | 0.661       |
|    value_loss           | 3.81e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
Eval num_timesteps=1120000, episode_reward=-0.08 +/- 0.09
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.0843     |
| time/                   |             |
|    total_timesteps      | 1120000     |
| train/                  |             |
|    approx_kl            | 0.027845785 |
|    clip_fraction        | 0.234       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.366      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00272     |
|    n_updates            | 599         |
|    policy_gradient_loss | 0.0128      |
|    std                  | 0.661       |
|    value_loss           | 2.84e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 981     |
|    iterations      | 137     |
|    time_elapsed    | 1142    |
|    total_timesteps | 1122304 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 987         |
|    iterations           | 138         |
|    time_elapsed         | 1145        |
|    total_timesteps      | 1130496     |
| train/                  |             |
|    approx_kl            | 0.029276473 |
|    clip_fraction        | 0.252       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.439      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00472     |
|    n_updates            | 600         |
|    policy_gradient_loss | 0.0148      |
|    std                  | 0.661       |
|    value_loss           | 2.87e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 992         |
|    iterations           | 139         |
|    time_elapsed         | 1147        |
|    total_timesteps      | 1138688     |
| train/                  |             |
|    approx_kl            | 0.026384752 |
|    clip_fraction        | 0.233       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.364      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00731     |
|    n_updates            | 601         |
|    policy_gradient_loss | 0.0173      |
|    std                  | 0.661       |
|    value_loss           | 3.19e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 997         |
|    iterations           | 140         |
|    time_elapsed         | 1149        |
|    total_timesteps      | 1146880     |
| train/                  |             |
|    approx_kl            | 0.026787091 |
|    clip_fraction        | 0.234       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.467      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00333     |
|    n_updates            | 602         |
|    policy_gradient_loss | 0.0134      |
|    std                  | 0.661       |
|    value_loss           | 3.58e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 1002        |
|    iterations           | 141         |
|    time_elapsed         | 1152        |
|    total_timesteps      | 1155072     |
| train/                  |             |
|    approx_kl            | 0.025073947 |
|    clip_fraction        | 0.245       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.264      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0029      |
|    n_updates            | 603         |
|    policy_gradient_loss | 0.0129      |
|    std                  | 0.661       |
|    value_loss           | 3.99e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
Eval num_timesteps=1160000, episode_reward=-0.06 +/- 0.12
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.0595     |
| time/                   |             |
|    total_timesteps      | 1160000     |
| train/                  |             |
|    approx_kl            | 0.027552787 |
|    clip_fraction        | 0.246       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.211      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0035      |
|    n_updates            | 604         |
|    policy_gradient_loss | 0.0135      |
|    std                  | 0.661       |
|    value_loss           | 4.58e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 990     |
|    iterations      | 142     |
|    time_elapsed    | 1174    |
|    total_timesteps | 1163264 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 995         |
|    iterations           | 143         |
|    time_elapsed         | 1176        |
|    total_timesteps      | 1171456     |
| train/                  |             |
|    approx_kl            | 0.029272033 |
|    clip_fraction        | 0.239       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.43       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0139      |
|    n_updates            | 605         |
|    policy_gradient_loss | 0.0239      |
|    std                  | 0.661       |
|    value_loss           | 3.11e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 1000        |
|    iterations           | 144         |
|    time_elapsed         | 1179        |
|    total_timesteps      | 1179648     |
| train/                  |             |
|    approx_kl            | 0.029775247 |
|    clip_fraction        | 0.267       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.46       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0029     |
|    n_updates            | 606         |
|    policy_gradient_loss | 0.00713     |
|    std                  | 0.661       |
|    value_loss           | 2.86e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 1005        |
|    iterations           | 145         |
|    time_elapsed         | 1181        |
|    total_timesteps      | 1187840     |
| train/                  |             |
|    approx_kl            | 0.028701156 |
|    clip_fraction        | 0.262       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.182      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.000138    |
|    n_updates            | 607         |
|    policy_gradient_loss | 0.0102      |
|    std                  | 0.661       |
|    value_loss           | 6.63e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.02
-----------------------------------------
| time/                   |             |
|    fps                  | 1010        |
|    iterations           | 146         |
|    time_elapsed         | 1183        |
|    total_timesteps      | 1196032     |
| train/                  |             |
|    approx_kl            | 0.022748344 |
|    clip_fraction        | 0.233       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.207      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00529     |
|    n_updates            | 608         |
|    policy_gradient_loss | 0.0147      |
|    std                  | 0.661       |
|    value_loss           | 3.91e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
Eval num_timesteps=1200000, episode_reward=-0.10 +/- 0.11
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.104      |
| time/                   |             |
|    total_timesteps      | 1200000     |
| train/                  |             |
|    approx_kl            | 0.029355897 |
|    clip_fraction        | 0.238       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.156      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0139      |
|    n_updates            | 609         |
|    policy_gradient_loss | 0.0239      |
|    std                  | 0.661       |
|    value_loss           | 7.17e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 998     |
|    iterations      | 147     |
|    time_elapsed    | 1206    |
|    total_timesteps | 1204224 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 1003        |
|    iterations           | 148         |
|    time_elapsed         | 1208        |
|    total_timesteps      | 1212416     |
| train/                  |             |
|    approx_kl            | 0.026435409 |
|    clip_fraction        | 0.259       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.308      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00209     |
|    n_updates            | 610         |
|    policy_gradient_loss | 0.0121      |
|    std                  | 0.661       |
|    value_loss           | 4.04e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
----------------------------------------
| time/                   |            |
|    fps                  | 1008       |
|    iterations           | 149        |
|    time_elapsed         | 1210       |
|    total_timesteps      | 1220608    |
| train/                  |            |
|    approx_kl            | 0.02917654 |
|    clip_fraction        | 0.282      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.01      |
|    explained_variance   | -0.286     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.00828    |
|    n_updates            | 611        |
|    policy_gradient_loss | 0.0183     |
|    std                  | 0.661      |
|    value_loss           | 3.25e-05   |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 1012        |
|    iterations           | 150         |
|    time_elapsed         | 1213        |
|    total_timesteps      | 1228800     |
| train/                  |             |
|    approx_kl            | 0.026151922 |
|    clip_fraction        | 0.237       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.492      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00478     |
|    n_updates            | 612         |
|    policy_gradient_loss | 0.0148      |
|    std                  | 0.661       |
|    value_loss           | 2.9e-05     |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 1017        |
|    iterations           | 151         |
|    time_elapsed         | 1215        |
|    total_timesteps      | 1236992     |
| train/                  |             |
|    approx_kl            | 0.027410427 |
|    clip_fraction        | 0.259       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.501      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00751     |
|    n_updates            | 613         |
|    policy_gradient_loss | 0.0176      |
|    std                  | 0.661       |
|    value_loss           | 2.72e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
Eval num_timesteps=1240000, episode_reward=-0.14 +/- 0.19
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.137      |
| time/                   |             |
|    total_timesteps      | 1240000     |
| train/                  |             |
|    approx_kl            | 0.030495383 |
|    clip_fraction        | 0.263       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.223      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00345     |
|    n_updates            | 614         |
|    policy_gradient_loss | 0.0135      |
|    std                  | 0.661       |
|    value_loss           | 4.29e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 1006    |
|    iterations      | 152     |
|    time_elapsed    | 1236    |
|    total_timesteps | 1245184 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 1011        |
|    iterations           | 153         |
|    time_elapsed         | 1239        |
|    total_timesteps      | 1253376     |
| train/                  |             |
|    approx_kl            | 0.036665622 |
|    clip_fraction        | 0.289       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.33       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00262    |
|    n_updates            | 615         |
|    policy_gradient_loss | 0.00741     |
|    std                  | 0.661       |
|    value_loss           | 4.14e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 1016        |
|    iterations           | 154         |
|    time_elapsed         | 1241        |
|    total_timesteps      | 1261568     |
| train/                  |             |
|    approx_kl            | 0.030416753 |
|    clip_fraction        | 0.275       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.361      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00139     |
|    n_updates            | 616         |
|    policy_gradient_loss | 0.0114      |
|    std                  | 0.661       |
|    value_loss           | 3.43e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 1020        |
|    iterations           | 155         |
|    time_elapsed         | 1243        |
|    total_timesteps      | 1269760     |
| train/                  |             |
|    approx_kl            | 0.030300474 |
|    clip_fraction        | 0.28        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.252      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0163      |
|    n_updates            | 617         |
|    policy_gradient_loss | 0.0263      |
|    std                  | 0.661       |
|    value_loss           | 4.87e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 1025        |
|    iterations           | 156         |
|    time_elapsed         | 1246        |
|    total_timesteps      | 1277952     |
| train/                  |             |
|    approx_kl            | 0.026301578 |
|    clip_fraction        | 0.237       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.349      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00324     |
|    n_updates            | 618         |
|    policy_gradient_loss | 0.0133      |
|    std                  | 0.661       |
|    value_loss           | 3.78e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
Eval num_timesteps=1280000, episode_reward=-0.13 +/- 0.09
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.127      |
| time/                   |             |
|    total_timesteps      | 1280000     |
| train/                  |             |
|    approx_kl            | 0.025788434 |
|    clip_fraction        | 0.238       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.352      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00772    |
|    n_updates            | 619         |
|    policy_gradient_loss | 0.00232     |
|    std                  | 0.661       |
|    value_loss           | 3.34e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 1014    |
|    iterations      | 157     |
|    time_elapsed    | 1268    |
|    total_timesteps | 1286144 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
----------------------------------------
| time/                   |            |
|    fps                  | 1018       |
|    iterations           | 158        |
|    time_elapsed         | 1270       |
|    total_timesteps      | 1294336    |
| train/                  |            |
|    approx_kl            | 0.02907347 |
|    clip_fraction        | 0.257      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.01      |
|    explained_variance   | -0.329     |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00149   |
|    n_updates            | 620        |
|    policy_gradient_loss | 0.00854    |
|    std                  | 0.661      |
|    value_loss           | 3.84e-05   |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 1023        |
|    iterations           | 159         |
|    time_elapsed         | 1273        |
|    total_timesteps      | 1302528     |
| train/                  |             |
|    approx_kl            | 0.037854493 |
|    clip_fraction        | 0.279       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.172      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00585     |
|    n_updates            | 621         |
|    policy_gradient_loss | 0.0159      |
|    std                  | 0.661       |
|    value_loss           | 5.28e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
----------------------------------------
| time/                   |            |
|    fps                  | 1027       |
|    iterations           | 160        |
|    time_elapsed         | 1275       |
|    total_timesteps      | 1310720    |
| train/                  |            |
|    approx_kl            | 0.03151243 |
|    clip_fraction        | 0.258      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.01      |
|    explained_variance   | -0.167     |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00131   |
|    n_updates            | 622        |
|    policy_gradient_loss | 0.00871    |
|    std                  | 0.661      |
|    value_loss           | 6.7e-05    |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 1032        |
|    iterations           | 161         |
|    time_elapsed         | 1277        |
|    total_timesteps      | 1318912     |
| train/                  |             |
|    approx_kl            | 0.027666496 |
|    clip_fraction        | 0.244       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.387      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0041      |
|    n_updates            | 623         |
|    policy_gradient_loss | 0.0141      |
|    std                  | 0.661       |
|    value_loss           | 3.02e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
Eval num_timesteps=1320000, episode_reward=-0.15 +/- 0.08
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.153      |
| time/                   |             |
|    total_timesteps      | 1320000     |
| train/                  |             |
|    approx_kl            | 0.030723324 |
|    clip_fraction        | 0.249       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.411      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00814     |
|    n_updates            | 624         |
|    policy_gradient_loss | 0.0182      |
|    std                  | 0.661       |
|    value_loss           | 3.16e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 1021    |
|    iterations      | 162     |
|    time_elapsed    | 1299    |
|    total_timesteps | 1327104 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 1025        |
|    iterations           | 163         |
|    time_elapsed         | 1302        |
|    total_timesteps      | 1335296     |
| train/                  |             |
|    approx_kl            | 0.027831737 |
|    clip_fraction        | 0.256       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.204      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00285     |
|    n_updates            | 625         |
|    policy_gradient_loss | 0.0129      |
|    std                  | 0.661       |
|    value_loss           | 5.06e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 1029        |
|    iterations           | 164         |
|    time_elapsed         | 1304        |
|    total_timesteps      | 1343488     |
| train/                  |             |
|    approx_kl            | 0.027782302 |
|    clip_fraction        | 0.231       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.199      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00362     |
|    n_updates            | 626         |
|    policy_gradient_loss | 0.0137      |
|    std                  | 0.661       |
|    value_loss           | 4.51e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 1034        |
|    iterations           | 165         |
|    time_elapsed         | 1306        |
|    total_timesteps      | 1351680     |
| train/                  |             |
|    approx_kl            | 0.031128708 |
|    clip_fraction        | 0.277       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.41       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00393     |
|    n_updates            | 627         |
|    policy_gradient_loss | 0.014       |
|    std                  | 0.661       |
|    value_loss           | 3.46e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 1038        |
|    iterations           | 166         |
|    time_elapsed         | 1309        |
|    total_timesteps      | 1359872     |
| train/                  |             |
|    approx_kl            | 0.029298456 |
|    clip_fraction        | 0.261       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.242      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00601     |
|    n_updates            | 628         |
|    policy_gradient_loss | 0.016       |
|    std                  | 0.661       |
|    value_loss           | 5.61e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.02
Eval num_timesteps=1360000, episode_reward=-0.15 +/- 0.15
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.154      |
| time/                   |             |
|    total_timesteps      | 1360000     |
| train/                  |             |
|    approx_kl            | 0.024077004 |
|    clip_fraction        | 0.234       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.404      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00652    |
|    n_updates            | 629         |
|    policy_gradient_loss | 0.00351     |
|    std                  | 0.661       |
|    value_loss           | 3.12e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 1027    |
|    iterations      | 167     |
|    time_elapsed    | 1331    |
|    total_timesteps | 1368064 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 1032        |
|    iterations           | 168         |
|    time_elapsed         | 1333        |
|    total_timesteps      | 1376256     |
| train/                  |             |
|    approx_kl            | 0.029483672 |
|    clip_fraction        | 0.26        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.176      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00601    |
|    n_updates            | 630         |
|    policy_gradient_loss | 0.00401     |
|    std                  | 0.661       |
|    value_loss           | 5.88e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
----------------------------------------
| time/                   |            |
|    fps                  | 1036       |
|    iterations           | 169        |
|    time_elapsed         | 1335       |
|    total_timesteps      | 1384448    |
| train/                  |            |
|    approx_kl            | 0.03050157 |
|    clip_fraction        | 0.26       |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.01      |
|    explained_variance   | -0.285     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.00811    |
|    n_updates            | 631        |
|    policy_gradient_loss | 0.0181     |
|    std                  | 0.661      |
|    value_loss           | 4.25e-05   |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 1040        |
|    iterations           | 170         |
|    time_elapsed         | 1338        |
|    total_timesteps      | 1392640     |
| train/                  |             |
|    approx_kl            | 0.034105066 |
|    clip_fraction        | 0.251       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.379      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0102      |
|    n_updates            | 632         |
|    policy_gradient_loss | 0.0202      |
|    std                  | 0.661       |
|    value_loss           | 3.45e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
Eval num_timesteps=1400000, episode_reward=-0.08 +/- 0.08
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.0779     |
| time/                   |             |
|    total_timesteps      | 1400000     |
| train/                  |             |
|    approx_kl            | 0.028362483 |
|    clip_fraction        | 0.233       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.223      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0104      |
|    n_updates            | 633         |
|    policy_gradient_loss | 0.0204      |
|    std                  | 0.661       |
|    value_loss           | 5.03e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 1030    |
|    iterations      | 171     |
|    time_elapsed    | 1360    |
|    total_timesteps | 1400832 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 1034        |
|    iterations           | 172         |
|    time_elapsed         | 1362        |
|    total_timesteps      | 1409024     |
| train/                  |             |
|    approx_kl            | 0.031226344 |
|    clip_fraction        | 0.23        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.286      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00101     |
|    n_updates            | 634         |
|    policy_gradient_loss | 0.011       |
|    std                  | 0.661       |
|    value_loss           | 3.92e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 1038        |
|    iterations           | 173         |
|    time_elapsed         | 1364        |
|    total_timesteps      | 1417216     |
| train/                  |             |
|    approx_kl            | 0.028077733 |
|    clip_fraction        | 0.256       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.322      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00478    |
|    n_updates            | 635         |
|    policy_gradient_loss | 0.00525     |
|    std                  | 0.661       |
|    value_loss           | 3.56e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 1042        |
|    iterations           | 174         |
|    time_elapsed         | 1367        |
|    total_timesteps      | 1425408     |
| train/                  |             |
|    approx_kl            | 0.026548581 |
|    clip_fraction        | 0.256       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.267      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00234    |
|    n_updates            | 636         |
|    policy_gradient_loss | 0.00769     |
|    std                  | 0.661       |
|    value_loss           | 4.37e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 1046        |
|    iterations           | 175         |
|    time_elapsed         | 1369        |
|    total_timesteps      | 1433600     |
| train/                  |             |
|    approx_kl            | 0.029174116 |
|    clip_fraction        | 0.26        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.313      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0102      |
|    n_updates            | 637         |
|    policy_gradient_loss | 0.0202      |
|    std                  | 0.661       |
|    value_loss           | 4.46e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
Eval num_timesteps=1440000, episode_reward=-0.02 +/- 0.07
Episode length: 2340.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 2.34e+03   |
|    mean_reward          | -0.0191    |
| time/                   |            |
|    total_timesteps      | 1440000    |
| train/                  |            |
|    approx_kl            | 0.02566293 |
|    clip_fraction        | 0.25       |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.01      |
|    explained_variance   | -0.149     |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00107   |
|    n_updates            | 638        |
|    policy_gradient_loss | 0.00895    |
|    std                  | 0.661      |
|    value_loss           | 6.57e-05   |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 1036    |
|    iterations      | 176     |
|    time_elapsed    | 1391    |
|    total_timesteps | 1441792 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 1040        |
|    iterations           | 177         |
|    time_elapsed         | 1393        |
|    total_timesteps      | 1449984     |
| train/                  |             |
|    approx_kl            | 0.028505992 |
|    clip_fraction        | 0.254       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.333      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0248      |
|    n_updates            | 639         |
|    policy_gradient_loss | 0.0348      |
|    std                  | 0.661       |
|    value_loss           | 3.27e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 1044        |
|    iterations           | 178         |
|    time_elapsed         | 1395        |
|    total_timesteps      | 1458176     |
| train/                  |             |
|    approx_kl            | 0.030853124 |
|    clip_fraction        | 0.273       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.378      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0118      |
|    n_updates            | 640         |
|    policy_gradient_loss | 0.0218      |
|    std                  | 0.661       |
|    value_loss           | 3.46e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.02
-----------------------------------------
| time/                   |             |
|    fps                  | 1048        |
|    iterations           | 179         |
|    time_elapsed         | 1398        |
|    total_timesteps      | 1466368     |
| train/                  |             |
|    approx_kl            | 0.023378287 |
|    clip_fraction        | 0.211       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.467      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00372     |
|    n_updates            | 641         |
|    policy_gradient_loss | 0.0138      |
|    std                  | 0.661       |
|    value_loss           | 3.14e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 1052        |
|    iterations           | 180         |
|    time_elapsed         | 1400        |
|    total_timesteps      | 1474560     |
| train/                  |             |
|    approx_kl            | 0.031600215 |
|    clip_fraction        | 0.258       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.285      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00373    |
|    n_updates            | 642         |
|    policy_gradient_loss | 0.0063      |
|    std                  | 0.661       |
|    value_loss           | 3.96e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
Eval num_timesteps=1480000, episode_reward=-0.22 +/- 0.13
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.215      |
| time/                   |             |
|    total_timesteps      | 1480000     |
| train/                  |             |
|    approx_kl            | 0.028873794 |
|    clip_fraction        | 0.247       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.243      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00295    |
|    n_updates            | 643         |
|    policy_gradient_loss | 0.00708     |
|    std                  | 0.661       |
|    value_loss           | 4.27e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 1042    |
|    iterations      | 181     |
|    time_elapsed    | 1422    |
|    total_timesteps | 1482752 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 1046        |
|    iterations           | 182         |
|    time_elapsed         | 1424        |
|    total_timesteps      | 1490944     |
| train/                  |             |
|    approx_kl            | 0.031002872 |
|    clip_fraction        | 0.26        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.351      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00992     |
|    n_updates            | 644         |
|    policy_gradient_loss | 0.02        |
|    std                  | 0.661       |
|    value_loss           | 3.85e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
----------------------------------------
| time/                   |            |
|    fps                  | 1050       |
|    iterations           | 183        |
|    time_elapsed         | 1427       |
|    total_timesteps      | 1499136    |
| train/                  |            |
|    approx_kl            | 0.02878155 |
|    clip_fraction        | 0.254      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.01      |
|    explained_variance   | -0.175     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.00585    |
|    n_updates            | 645        |
|    policy_gradient_loss | 0.0159     |
|    std                  | 0.661      |
|    value_loss           | 9.62e-05   |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
----------------------------------------
| time/                   |            |
|    fps                  | 1054       |
|    iterations           | 184        |
|    time_elapsed         | 1429       |
|    total_timesteps      | 1507328    |
| train/                  |            |
|    approx_kl            | 0.02993612 |
|    clip_fraction        | 0.256      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.01      |
|    explained_variance   | -0.242     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0143     |
|    n_updates            | 646        |
|    policy_gradient_loss | 0.0243     |
|    std                  | 0.661      |
|    value_loss           | 4.71e-05   |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.02
-----------------------------------------
| time/                   |             |
|    fps                  | 1058        |
|    iterations           | 185         |
|    time_elapsed         | 1431        |
|    total_timesteps      | 1515520     |
| train/                  |             |
|    approx_kl            | 0.024414722 |
|    clip_fraction        | 0.243       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.488      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0103      |
|    n_updates            | 647         |
|    policy_gradient_loss | 0.0203      |
|    std                  | 0.661       |
|    value_loss           | 2.82e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
Eval num_timesteps=1520000, episode_reward=-0.11 +/- 0.09
Episode length: 2340.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 2.34e+03   |
|    mean_reward          | -0.107     |
| time/                   |            |
|    total_timesteps      | 1520000    |
| train/                  |            |
|    approx_kl            | 0.03646419 |
|    clip_fraction        | 0.264      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.01      |
|    explained_variance   | -0.433     |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00212   |
|    n_updates            | 648        |
|    policy_gradient_loss | 0.00792    |
|    std                  | 0.661      |
|    value_loss           | 3.02e-05   |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 1047    |
|    iterations      | 186     |
|    time_elapsed    | 1454    |
|    total_timesteps | 1523712 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 1051        |
|    iterations           | 187         |
|    time_elapsed         | 1457        |
|    total_timesteps      | 1531904     |
| train/                  |             |
|    approx_kl            | 0.028558366 |
|    clip_fraction        | 0.244       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.324      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.000931    |
|    n_updates            | 649         |
|    policy_gradient_loss | 0.011       |
|    std                  | 0.661       |
|    value_loss           | 3.03e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 1054        |
|    iterations           | 188         |
|    time_elapsed         | 1460        |
|    total_timesteps      | 1540096     |
| train/                  |             |
|    approx_kl            | 0.043741282 |
|    clip_fraction        | 0.258       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.437      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0181      |
|    n_updates            | 650         |
|    policy_gradient_loss | 0.0281      |
|    std                  | 0.661       |
|    value_loss           | 3.12e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 1057        |
|    iterations           | 189         |
|    time_elapsed         | 1464        |
|    total_timesteps      | 1548288     |
| train/                  |             |
|    approx_kl            | 0.026125794 |
|    clip_fraction        | 0.237       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.269      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.000471   |
|    n_updates            | 651         |
|    policy_gradient_loss | 0.00956     |
|    std                  | 0.661       |
|    value_loss           | 3.54e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 1060        |
|    iterations           | 190         |
|    time_elapsed         | 1467        |
|    total_timesteps      | 1556480     |
| train/                  |             |
|    approx_kl            | 0.026285652 |
|    clip_fraction        | 0.242       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.319      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00536     |
|    n_updates            | 652         |
|    policy_gradient_loss | 0.0154      |
|    std                  | 0.661       |
|    value_loss           | 3.6e-05     |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
Eval num_timesteps=1560000, episode_reward=-0.07 +/- 0.09
Episode length: 2340.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 2.34e+03   |
|    mean_reward          | -0.0683    |
| time/                   |            |
|    total_timesteps      | 1560000    |
| train/                  |            |
|    approx_kl            | 0.03326634 |
|    clip_fraction        | 0.248      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.01      |
|    explained_variance   | -0.319     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0121     |
|    n_updates            | 653        |
|    policy_gradient_loss | 0.0222     |
|    std                  | 0.661      |
|    value_loss           | 3.42e-05   |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 1045    |
|    iterations      | 191     |
|    time_elapsed    | 1496    |
|    total_timesteps | 1564672 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
---------------------------------------
| time/                   |           |
|    fps                  | 1048      |
|    iterations           | 192       |
|    time_elapsed         | 1500      |
|    total_timesteps      | 1572864   |
| train/                  |           |
|    approx_kl            | 0.0349917 |
|    clip_fraction        | 0.246     |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.01     |
|    explained_variance   | -0.141    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.00456   |
|    n_updates            | 654       |
|    policy_gradient_loss | 0.0146    |
|    std                  | 0.661     |
|    value_loss           | 5.79e-05  |
---------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 1051        |
|    iterations           | 193         |
|    time_elapsed         | 1504        |
|    total_timesteps      | 1581056     |
| train/                  |             |
|    approx_kl            | 0.029610138 |
|    clip_fraction        | 0.254       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.355      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00446     |
|    n_updates            | 655         |
|    policy_gradient_loss | 0.0145      |
|    std                  | 0.661       |
|    value_loss           | 3.58e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
----------------------------------------
| time/                   |            |
|    fps                  | 1054       |
|    iterations           | 194        |
|    time_elapsed         | 1507       |
|    total_timesteps      | 1589248    |
| train/                  |            |
|    approx_kl            | 0.03185785 |
|    clip_fraction        | 0.242      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.01      |
|    explained_variance   | -0.33      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0053     |
|    n_updates            | 656        |
|    policy_gradient_loss | 0.0153     |
|    std                  | 0.661      |
|    value_loss           | 3.37e-05   |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 1056        |
|    iterations           | 195         |
|    time_elapsed         | 1511        |
|    total_timesteps      | 1597440     |
| train/                  |             |
|    approx_kl            | 0.025187174 |
|    clip_fraction        | 0.23        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.167      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00518     |
|    n_updates            | 657         |
|    policy_gradient_loss | 0.0152      |
|    std                  | 0.661       |
|    value_loss           | 6.23e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
Eval num_timesteps=1600000, episode_reward=-0.12 +/- 0.12
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.124      |
| time/                   |             |
|    total_timesteps      | 1600000     |
| train/                  |             |
|    approx_kl            | 0.029128786 |
|    clip_fraction        | 0.237       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.418      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00648     |
|    n_updates            | 658         |
|    policy_gradient_loss | 0.0165      |
|    std                  | 0.661       |
|    value_loss           | 2.99e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 1043    |
|    iterations      | 196     |
|    time_elapsed    | 1539    |
|    total_timesteps | 1605632 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
----------------------------------------
| time/                   |            |
|    fps                  | 1046       |
|    iterations           | 197        |
|    time_elapsed         | 1542       |
|    total_timesteps      | 1613824    |
| train/                  |            |
|    approx_kl            | 0.03080676 |
|    clip_fraction        | 0.25       |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.01      |
|    explained_variance   | -0.164     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.00596    |
|    n_updates            | 659        |
|    policy_gradient_loss | 0.016      |
|    std                  | 0.661      |
|    value_loss           | 0.000105   |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
---------------------------------------
| time/                   |           |
|    fps                  | 1049      |
|    iterations           | 198       |
|    time_elapsed         | 1545      |
|    total_timesteps      | 1622016   |
| train/                  |           |
|    approx_kl            | 0.0361156 |
|    clip_fraction        | 0.27      |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.01     |
|    explained_variance   | -0.324    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.00789   |
|    n_updates            | 660       |
|    policy_gradient_loss | 0.0179    |
|    std                  | 0.661     |
|    value_loss           | 3.43e-05  |
---------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 1052        |
|    iterations           | 199         |
|    time_elapsed         | 1549        |
|    total_timesteps      | 1630208     |
| train/                  |             |
|    approx_kl            | 0.031567838 |
|    clip_fraction        | 0.261       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.283      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00164    |
|    n_updates            | 661         |
|    policy_gradient_loss | 0.00839     |
|    std                  | 0.661       |
|    value_loss           | 4e-05       |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
----------------------------------------
| time/                   |            |
|    fps                  | 1055       |
|    iterations           | 200        |
|    time_elapsed         | 1551       |
|    total_timesteps      | 1638400    |
| train/                  |            |
|    approx_kl            | 0.03253229 |
|    clip_fraction        | 0.249      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.01      |
|    explained_variance   | -0.421     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.00767    |
|    n_updates            | 662        |
|    policy_gradient_loss | 0.0177     |
|    std                  | 0.661      |
|    value_loss           | 3.33e-05   |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
Eval num_timesteps=1640000, episode_reward=-0.11 +/- 0.09
Episode length: 2340.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 2.34e+03   |
|    mean_reward          | -0.115     |
| time/                   |            |
|    total_timesteps      | 1640000    |
| train/                  |            |
|    approx_kl            | 0.03413645 |
|    clip_fraction        | 0.288      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.01      |
|    explained_variance   | -0.336     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.00492    |
|    n_updates            | 663        |
|    policy_gradient_loss | 0.015      |
|    std                  | 0.661      |
|    value_loss           | 3.63e-05   |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 1044    |
|    iterations      | 201     |
|    time_elapsed    | 1577    |
|    total_timesteps | 1646592 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 1047        |
|    iterations           | 202         |
|    time_elapsed         | 1580        |
|    total_timesteps      | 1654784     |
| train/                  |             |
|    approx_kl            | 0.030676434 |
|    clip_fraction        | 0.261       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.41       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.01        |
|    n_updates            | 664         |
|    policy_gradient_loss | 0.0201      |
|    std                  | 0.661       |
|    value_loss           | 2.66e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 1050        |
|    iterations           | 203         |
|    time_elapsed         | 1583        |
|    total_timesteps      | 1662976     |
| train/                  |             |
|    approx_kl            | 0.026376199 |
|    clip_fraction        | 0.232       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.408      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00219     |
|    n_updates            | 665         |
|    policy_gradient_loss | 0.0122      |
|    std                  | 0.661       |
|    value_loss           | 2.96e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 1053        |
|    iterations           | 204         |
|    time_elapsed         | 1586        |
|    total_timesteps      | 1671168     |
| train/                  |             |
|    approx_kl            | 0.026455551 |
|    clip_fraction        | 0.249       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.278      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00334     |
|    n_updates            | 666         |
|    policy_gradient_loss | 0.0134      |
|    std                  | 0.661       |
|    value_loss           | 4.32e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 1056        |
|    iterations           | 205         |
|    time_elapsed         | 1588        |
|    total_timesteps      | 1679360     |
| train/                  |             |
|    approx_kl            | 0.031627405 |
|    clip_fraction        | 0.256       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | -0.52       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00905     |
|    n_updates            | 667         |
|    policy_gradient_loss | 0.0191      |
|    std                  | 0.661       |
|    value_loss           | 2.97e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
Loading datasets...
[Dataset_Finance_MultiAsset] Global date splits: train_end=2024-07-26 14:20:00+00:00 val_end=2025-04-25 15:45:00+00:00 n_dates=96878 n_train=67814 n_val=14533 n_test=14531
[Dataset_Finance_MultiAsset] Global date splits: train_end=2024-07-26 14:20:00+00:00 val_end=2025-04-25 15:45:00+00:00 n_dates=96878 n_train=67814 n_val=14533 n_test=14531
Building environments...
Loading JEPA encoder...
/root/DrlPpoTransformer/.venv/lib/python3.11/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(
Loading JEPA weights from checkpoints/jepa_initial/best.pt
/root/DrlPpoTransformer/train_PPO_initial.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(checkpoint_path, map_location="cpu")
Using cuda device
Logging to logs/PPO_7
/root/DrlPpoTransformer/.venv/lib/python3.11/site-packages/stable_baselines3/common/callbacks.py:418: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.subproc_vec_env.SubprocVecEnv object at 0x7a0790fb4c90> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7a07f8ace710>
  warnings.warn("Training and eval env are not of the same type" f"{self.training_env} != {self.eval_env}")
-----------------------------
| time/              |      |
|    fps             | 2511 |
|    iterations      | 1    |
|    time_elapsed    | 3    |
|    total_timesteps | 8192 |
-----------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 2122        |
|    iterations           | 2           |
|    time_elapsed         | 7           |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.002706685 |
|    clip_fraction        | 0.00284     |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.42       |
|    explained_variance   | -7.7        |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0675     |
|    n_updates            | 4           |
|    policy_gradient_loss | -0.000707   |
|    std                  | 1           |
|    value_loss           | 0.0377      |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 2046         |
|    iterations           | 3            |
|    time_elapsed         | 12           |
|    total_timesteps      | 24576        |
| train/                  |              |
|    approx_kl            | 0.0007375305 |
|    clip_fraction        | 6.1e-05      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.42        |
|    explained_variance   | -7.46        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0661      |
|    n_updates            | 8            |
|    policy_gradient_loss | -0.000151    |
|    std                  | 1            |
|    value_loss           | 0.0267       |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 2001        |
|    iterations           | 4           |
|    time_elapsed         | 16          |
|    total_timesteps      | 32768       |
| train/                  |             |
|    approx_kl            | 0.002344436 |
|    clip_fraction        | 0.00165     |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.42       |
|    explained_variance   | -7.43       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0676     |
|    n_updates            | 12          |
|    policy_gradient_loss | -0.000496   |
|    std                  | 1           |
|    value_loss           | 0.0189      |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 1981        |
|    iterations           | 5           |
|    time_elapsed         | 20          |
|    total_timesteps      | 40960       |
| train/                  |             |
|    approx_kl            | 7.04136e-05 |
|    clip_fraction        | 0           |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.42       |
|    explained_variance   | -9.89       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0688     |
|    n_updates            | 16          |
|    policy_gradient_loss | -9.68e-05   |
|    std                  | 1           |
|    value_loss           | 0.0149      |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1972         |
|    iterations           | 6            |
|    time_elapsed         | 24           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 0.0014334609 |
|    clip_fraction        | 0.000183     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.42        |
|    explained_variance   | -9.9         |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0728      |
|    n_updates            | 20           |
|    policy_gradient_loss | -0.00033     |
|    std                  | 1.01         |
|    value_loss           | 0.0119       |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1990         |
|    iterations           | 7            |
|    time_elapsed         | 28           |
|    total_timesteps      | 57344        |
| train/                  |              |
|    approx_kl            | 0.0028683986 |
|    clip_fraction        | 0.00256      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.43        |
|    explained_variance   | -9.43        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0714      |
|    n_updates            | 24           |
|    policy_gradient_loss | -0.000509    |
|    std                  | 1.01         |
|    value_loss           | 0.00955      |
------------------------------------------
-------------------------------------------
| time/                   |               |
|    fps                  | 2007          |
|    iterations           | 8             |
|    time_elapsed         | 32            |
|    total_timesteps      | 65536         |
| train/                  |               |
|    approx_kl            | 0.00026386033 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.43         |
|    explained_variance   | -10.6         |
|    learning_rate        | 5e-05         |
|    loss                 | -0.0696       |
|    n_updates            | 28            |
|    policy_gradient_loss | -8.09e-05     |
|    std                  | 1.01          |
|    value_loss           | 0.0083        |
-------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 2020        |
|    iterations           | 9           |
|    time_elapsed         | 36          |
|    total_timesteps      | 73728       |
| train/                  |             |
|    approx_kl            | 0.000147739 |
|    clip_fraction        | 0           |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.43       |
|    explained_variance   | -11.7       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0703     |
|    n_updates            | 32          |
|    policy_gradient_loss | -7.32e-05   |
|    std                  | 1.01        |
|    value_loss           | 0.00701     |
-----------------------------------------
/root/DrlPpoTransformer/.venv/lib/python3.11/site-packages/stable_baselines3/common/evaluation.py:70: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.
  warnings.warn(
Eval num_timesteps=80000, episode_reward=-0.03 +/- 0.01
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | -0.0288      |
| time/                   |              |
|    total_timesteps      | 80000        |
| train/                  |              |
|    approx_kl            | 0.0006434859 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.43        |
|    explained_variance   | -7.88        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0679      |
|    n_updates            | 36           |
|    policy_gradient_loss | -0.000201    |
|    std                  | 1.01         |
|    value_loss           | 0.00612      |
------------------------------------------
New best mean reward!
------------------------------
| time/              |       |
|    fps             | 1280  |
|    iterations      | 10    |
|    time_elapsed    | 63    |
|    total_timesteps | 81920 |
------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1319         |
|    iterations           | 11           |
|    time_elapsed         | 68           |
|    total_timesteps      | 90112        |
| train/                  |              |
|    approx_kl            | 0.0020906376 |
|    clip_fraction        | 0.00125      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.43        |
|    explained_variance   | -9.55        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0717      |
|    n_updates            | 40           |
|    policy_gradient_loss | -0.000355    |
|    std                  | 1.01         |
|    value_loss           | 0.00555      |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 1352        |
|    iterations           | 12          |
|    time_elapsed         | 72          |
|    total_timesteps      | 98304       |
| train/                  |             |
|    approx_kl            | 0.004726121 |
|    clip_fraction        | 0.0182      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.43       |
|    explained_variance   | -7.98       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0673     |
|    n_updates            | 44          |
|    policy_gradient_loss | -0.00126    |
|    std                  | 1.01        |
|    value_loss           | 0.00497     |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1382         |
|    iterations           | 13           |
|    time_elapsed         | 77           |
|    total_timesteps      | 106496       |
| train/                  |              |
|    approx_kl            | 0.0008264504 |
|    clip_fraction        | 3.05e-05     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.43        |
|    explained_variance   | -7.59        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0699      |
|    n_updates            | 48           |
|    policy_gradient_loss | 2.36e-05     |
|    std                  | 1.01         |
|    value_loss           | 0.0044       |
------------------------------------------
-------------------------------------------
| time/                   |               |
|    fps                  | 1409          |
|    iterations           | 14            |
|    time_elapsed         | 81            |
|    total_timesteps      | 114688        |
| train/                  |               |
|    approx_kl            | 2.8508359e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.43         |
|    explained_variance   | -9.47         |
|    learning_rate        | 5e-05         |
|    loss                 | -0.0712       |
|    n_updates            | 52            |
|    policy_gradient_loss | -0.000102     |
|    std                  | 1.02          |
|    value_loss           | 0.00402       |
-------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1433         |
|    iterations           | 15           |
|    time_elapsed         | 85           |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 0.0028958207 |
|    clip_fraction        | 0.00339      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.43        |
|    explained_variance   | -9.15        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0711      |
|    n_updates            | 56           |
|    policy_gradient_loss | -0.000551    |
|    std                  | 1.02         |
|    value_loss           | 0.00372      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1455         |
|    iterations           | 16           |
|    time_elapsed         | 90           |
|    total_timesteps      | 131072       |
| train/                  |              |
|    approx_kl            | 0.0013526225 |
|    clip_fraction        | 0.000214     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.44        |
|    explained_variance   | -8.38        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0728      |
|    n_updates            | 60           |
|    policy_gradient_loss | -0.000241    |
|    std                  | 1.02         |
|    value_loss           | 0.00342      |
------------------------------------------
-------------------------------------------
| time/                   |               |
|    fps                  | 1474          |
|    iterations           | 17            |
|    time_elapsed         | 94            |
|    total_timesteps      | 139264        |
| train/                  |               |
|    approx_kl            | 0.00034865938 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.44         |
|    explained_variance   | -8.22         |
|    learning_rate        | 5e-05         |
|    loss                 | -0.071        |
|    n_updates            | 64            |
|    policy_gradient_loss | -9.2e-05      |
|    std                  | 1.02          |
|    value_loss           | 0.00322       |
-------------------------------------------
-------------------------------------------
| time/                   |               |
|    fps                  | 1490          |
|    iterations           | 18            |
|    time_elapsed         | 98            |
|    total_timesteps      | 147456        |
| train/                  |               |
|    approx_kl            | 0.00027724274 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.44         |
|    explained_variance   | -8.6          |
|    learning_rate        | 5e-05         |
|    loss                 | -0.0711       |
|    n_updates            | 68            |
|    policy_gradient_loss | -9.83e-05     |
|    std                  | 1.02          |
|    value_loss           | 0.00296       |
-------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1506         |
|    iterations           | 19           |
|    time_elapsed         | 103          |
|    total_timesteps      | 155648       |
| train/                  |              |
|    approx_kl            | 0.0011090417 |
|    clip_fraction        | 0.000183     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.44        |
|    explained_variance   | -7.81        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0703      |
|    n_updates            | 72           |
|    policy_gradient_loss | -0.00022     |
|    std                  | 1.02         |
|    value_loss           | 0.00288      |
------------------------------------------
/root/DrlPpoTransformer/.venv/lib/python3.11/site-packages/stable_baselines3/common/evaluation.py:70: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.
  warnings.warn(
Eval num_timesteps=160000, episode_reward=-0.04 +/- 0.04
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | -0.0399      |
| time/                   |              |
|    total_timesteps      | 160000       |
| train/                  |              |
|    approx_kl            | 0.0038214829 |
|    clip_fraction        | 0.0165       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.44        |
|    explained_variance   | -7.97        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0756      |
|    n_updates            | 76           |
|    policy_gradient_loss | -0.00101     |
|    std                  | 1.02         |
|    value_loss           | 0.00264      |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 1262   |
|    iterations      | 20     |
|    time_elapsed    | 129    |
|    total_timesteps | 163840 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1285         |
|    iterations           | 21           |
|    time_elapsed         | 133          |
|    total_timesteps      | 172032       |
| train/                  |              |
|    approx_kl            | 0.0042918073 |
|    clip_fraction        | 0.0102       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.44        |
|    explained_variance   | -8.91        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0704      |
|    n_updates            | 80           |
|    policy_gradient_loss | -0.000748    |
|    std                  | 1.02         |
|    value_loss           | 0.00245      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1312         |
|    iterations           | 22           |
|    time_elapsed         | 137          |
|    total_timesteps      | 180224       |
| train/                  |              |
|    approx_kl            | 0.0044417847 |
|    clip_fraction        | 0.0136       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.44        |
|    explained_variance   | -7.94        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0698      |
|    n_updates            | 84           |
|    policy_gradient_loss | -0.00106     |
|    std                  | 1.02         |
|    value_loss           | 0.0023       |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1338         |
|    iterations           | 23           |
|    time_elapsed         | 140          |
|    total_timesteps      | 188416       |
| train/                  |              |
|    approx_kl            | 0.0010672683 |
|    clip_fraction        | 9.16e-05     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.44        |
|    explained_variance   | -6.78        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0734      |
|    n_updates            | 88           |
|    policy_gradient_loss | 1.55e-05     |
|    std                  | 1.02         |
|    value_loss           | 0.00221      |
------------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 1362       |
|    iterations           | 24         |
|    time_elapsed         | 144        |
|    total_timesteps      | 196608     |
| train/                  |            |
|    approx_kl            | 0.00351631 |
|    clip_fraction        | 0.00635    |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.44      |
|    explained_variance   | -7.97      |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0704    |
|    n_updates            | 92         |
|    policy_gradient_loss | -0.000263  |
|    std                  | 1.02       |
|    value_loss           | 0.00206    |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 1384        |
|    iterations           | 25          |
|    time_elapsed         | 147         |
|    total_timesteps      | 204800      |
| train/                  |             |
|    approx_kl            | 0.004743427 |
|    clip_fraction        | 0.0292      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.44       |
|    explained_variance   | -6.98       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0712     |
|    n_updates            | 96          |
|    policy_gradient_loss | -0.00139    |
|    std                  | 1.02        |
|    value_loss           | 0.00196     |
-----------------------------------------
-------------------------------------------
| time/                   |               |
|    fps                  | 1407          |
|    iterations           | 26            |
|    time_elapsed         | 151           |
|    total_timesteps      | 212992        |
| train/                  |               |
|    approx_kl            | 0.00021580365 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.44         |
|    explained_variance   | -11.8         |
|    learning_rate        | 5e-05         |
|    loss                 | -0.0717       |
|    n_updates            | 100           |
|    policy_gradient_loss | -9.21e-06     |
|    std                  | 1.03          |
|    value_loss           | 0.00174       |
-------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 1428        |
|    iterations           | 27          |
|    time_elapsed         | 154         |
|    total_timesteps      | 221184      |
| train/                  |             |
|    approx_kl            | 0.001502694 |
|    clip_fraction        | 0.000427    |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.44       |
|    explained_variance   | -8.56       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0718     |
|    n_updates            | 104         |
|    policy_gradient_loss | -0.000196   |
|    std                  | 1.03        |
|    value_loss           | 0.0017      |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1449         |
|    iterations           | 28           |
|    time_elapsed         | 158          |
|    total_timesteps      | 229376       |
| train/                  |              |
|    approx_kl            | 0.0033912286 |
|    clip_fraction        | 0.0211       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.44        |
|    explained_variance   | -7.89        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0719      |
|    n_updates            | 108          |
|    policy_gradient_loss | -0.00182     |
|    std                  | 1.03         |
|    value_loss           | 0.00174      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1469         |
|    iterations           | 29           |
|    time_elapsed         | 161          |
|    total_timesteps      | 237568       |
| train/                  |              |
|    approx_kl            | 0.0014850837 |
|    clip_fraction        | 0.000244     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.45        |
|    explained_variance   | -8.36        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0712      |
|    n_updates            | 112          |
|    policy_gradient_loss | -0.00019     |
|    std                  | 1.03         |
|    value_loss           | 0.00158      |
------------------------------------------
Eval num_timesteps=240000, episode_reward=0.00 +/- 0.09
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | 0.00388      |
| time/                   |              |
|    total_timesteps      | 240000       |
| train/                  |              |
|    approx_kl            | 0.0011766991 |
|    clip_fraction        | 9.16e-05     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.45        |
|    explained_variance   | -9.34        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0745      |
|    n_updates            | 116          |
|    policy_gradient_loss | -8.32e-05    |
|    std                  | 1.03         |
|    value_loss           | 0.0015       |
------------------------------------------
New best mean reward!
-------------------------------
| time/              |        |
|    fps             | 1319   |
|    iterations      | 30     |
|    time_elapsed    | 186    |
|    total_timesteps | 245760 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1338         |
|    iterations           | 31           |
|    time_elapsed         | 189          |
|    total_timesteps      | 253952       |
| train/                  |              |
|    approx_kl            | 0.0046957163 |
|    clip_fraction        | 0.0144       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.45        |
|    explained_variance   | -9.41        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0691      |
|    n_updates            | 120          |
|    policy_gradient_loss | -0.000688    |
|    std                  | 1.03         |
|    value_loss           | 0.00148      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1356         |
|    iterations           | 32           |
|    time_elapsed         | 193          |
|    total_timesteps      | 262144       |
| train/                  |              |
|    approx_kl            | 0.0010100582 |
|    clip_fraction        | 3.05e-05     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.45        |
|    explained_variance   | -8.47        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0748      |
|    n_updates            | 124          |
|    policy_gradient_loss | -1.52e-05    |
|    std                  | 1.03         |
|    value_loss           | 0.00141      |
------------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 1373       |
|    iterations           | 33         |
|    time_elapsed         | 196        |
|    total_timesteps      | 270336     |
| train/                  |            |
|    approx_kl            | 0.00275177 |
|    clip_fraction        | 0.0211     |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.45      |
|    explained_variance   | -8.57      |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0711    |
|    n_updates            | 128        |
|    policy_gradient_loss | -0.00169   |
|    std                  | 1.03       |
|    value_loss           | 0.00136    |
----------------------------------------
-------------------------------------------
| time/                   |               |
|    fps                  | 1390          |
|    iterations           | 34            |
|    time_elapsed         | 200           |
|    total_timesteps      | 278528        |
| train/                  |               |
|    approx_kl            | 0.00032827776 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.45         |
|    explained_variance   | -10.5         |
|    learning_rate        | 5e-05         |
|    loss                 | -0.0713       |
|    n_updates            | 132           |
|    policy_gradient_loss | -5.51e-05     |
|    std                  | 1.03          |
|    value_loss           | 0.00123       |
-------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 1406        |
|    iterations           | 35          |
|    time_elapsed         | 203         |
|    total_timesteps      | 286720      |
| train/                  |             |
|    approx_kl            | 0.002732911 |
|    clip_fraction        | 0.00714     |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.45       |
|    explained_variance   | -8.08       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0731     |
|    n_updates            | 136         |
|    policy_gradient_loss | -0.000466   |
|    std                  | 1.03        |
|    value_loss           | 0.00127     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 1422        |
|    iterations           | 36          |
|    time_elapsed         | 207         |
|    total_timesteps      | 294912      |
| train/                  |             |
|    approx_kl            | 0.003247389 |
|    clip_fraction        | 0.00992     |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.45       |
|    explained_variance   | -10.4       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0732     |
|    n_updates            | 140         |
|    policy_gradient_loss | -0.000461   |
|    std                  | 1.03        |
|    value_loss           | 0.00119     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 1438        |
|    iterations           | 37          |
|    time_elapsed         | 210         |
|    total_timesteps      | 303104      |
| train/                  |             |
|    approx_kl            | 0.003246728 |
|    clip_fraction        | 0.0043      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.45       |
|    explained_variance   | -7.02       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0712     |
|    n_updates            | 144         |
|    policy_gradient_loss | -0.000167   |
|    std                  | 1.03        |
|    value_loss           | 0.00118     |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1453         |
|    iterations           | 38           |
|    time_elapsed         | 214          |
|    total_timesteps      | 311296       |
| train/                  |              |
|    approx_kl            | 0.0036455437 |
|    clip_fraction        | 0.0225       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.45        |
|    explained_variance   | -8.25        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.076       |
|    n_updates            | 148          |
|    policy_gradient_loss | -0.00114     |
|    std                  | 1.03         |
|    value_loss           | 0.00108      |
------------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 1467       |
|    iterations           | 39         |
|    time_elapsed         | 217        |
|    total_timesteps      | 319488     |
| train/                  |            |
|    approx_kl            | 0.00503741 |
|    clip_fraction        | 0.0139     |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.45      |
|    explained_variance   | -8.26      |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0768    |
|    n_updates            | 152        |
|    policy_gradient_loss | -0.000929  |
|    std                  | 1.03       |
|    value_loss           | 0.00106    |
----------------------------------------
Eval num_timesteps=320000, episode_reward=-0.03 +/- 0.09
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | -0.0307      |
| time/                   |              |
|    total_timesteps      | 320000       |
| train/                  |              |
|    approx_kl            | 0.0035395531 |
|    clip_fraction        | 0.00552      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.45        |
|    explained_variance   | -7.78        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0767      |
|    n_updates            | 156          |
|    policy_gradient_loss | -0.000567    |
|    std                  | 1.03         |
|    value_loss           | 0.00102      |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 1352   |
|    iterations      | 40     |
|    time_elapsed    | 242    |
|    total_timesteps | 327680 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1367         |
|    iterations           | 41           |
|    time_elapsed         | 245          |
|    total_timesteps      | 335872       |
| train/                  |              |
|    approx_kl            | 0.0025417474 |
|    clip_fraction        | 0.0184       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.45        |
|    explained_variance   | -10.5        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0759      |
|    n_updates            | 160          |
|    policy_gradient_loss | -0.00152     |
|    std                  | 1.04         |
|    value_loss           | 0.000935     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 1382        |
|    iterations           | 42          |
|    time_elapsed         | 248         |
|    total_timesteps      | 344064      |
| train/                  |             |
|    approx_kl            | 0.002798565 |
|    clip_fraction        | 0.0285      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.45       |
|    explained_variance   | -8.13       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0739     |
|    n_updates            | 164         |
|    policy_gradient_loss | -0.00182    |
|    std                  | 1.04        |
|    value_loss           | 0.000921    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1396         |
|    iterations           | 43           |
|    time_elapsed         | 252          |
|    total_timesteps      | 352256       |
| train/                  |              |
|    approx_kl            | 0.0026196418 |
|    clip_fraction        | 0.00235      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.46        |
|    explained_variance   | -7.04        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0744      |
|    n_updates            | 168          |
|    policy_gradient_loss | -0.000236    |
|    std                  | 1.04         |
|    value_loss           | 0.000923     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1410         |
|    iterations           | 44           |
|    time_elapsed         | 255          |
|    total_timesteps      | 360448       |
| train/                  |              |
|    approx_kl            | 0.0015357024 |
|    clip_fraction        | 0.000977     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.46        |
|    explained_variance   | -12.1        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.074       |
|    n_updates            | 172          |
|    policy_gradient_loss | -0.000135    |
|    std                  | 1.04         |
|    value_loss           | 0.000871     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 1424        |
|    iterations           | 45          |
|    time_elapsed         | 258         |
|    total_timesteps      | 368640      |
| train/                  |             |
|    approx_kl            | 0.003742929 |
|    clip_fraction        | 0.0062      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.46       |
|    explained_variance   | -8.49       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0661     |
|    n_updates            | 176         |
|    policy_gradient_loss | -0.000415   |
|    std                  | 1.04        |
|    value_loss           | 0.000879    |
-----------------------------------------
-------------------------------------------
| time/                   |               |
|    fps                  | 1437          |
|    iterations           | 46            |
|    time_elapsed         | 262           |
|    total_timesteps      | 376832        |
| train/                  |               |
|    approx_kl            | 3.9721526e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.46         |
|    explained_variance   | -7.07         |
|    learning_rate        | 5e-05         |
|    loss                 | -0.0732       |
|    n_updates            | 180           |
|    policy_gradient_loss | -1.5e-05      |
|    std                  | 1.04          |
|    value_loss           | 0.000833      |
-------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 1450        |
|    iterations           | 47          |
|    time_elapsed         | 265         |
|    total_timesteps      | 385024      |
| train/                  |             |
|    approx_kl            | 0.002475489 |
|    clip_fraction        | 0.00214     |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.46       |
|    explained_variance   | -8.33       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0723     |
|    n_updates            | 184         |
|    policy_gradient_loss | -0.000238   |
|    std                  | 1.04        |
|    value_loss           | 0.000819    |
-----------------------------------------
-------------------------------------------
| time/                   |               |
|    fps                  | 1462          |
|    iterations           | 48            |
|    time_elapsed         | 268           |
|    total_timesteps      | 393216        |
| train/                  |               |
|    approx_kl            | 0.00033969185 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.46         |
|    explained_variance   | -11           |
|    learning_rate        | 5e-05         |
|    loss                 | -0.0747       |
|    n_updates            | 188           |
|    policy_gradient_loss | -0.000102     |
|    std                  | 1.04          |
|    value_loss           | 0.00077       |
-------------------------------------------
Eval num_timesteps=400000, episode_reward=0.01 +/- 0.06
Episode length: 2340.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 2.34e+03  |
|    mean_reward          | 0.0052    |
| time/                   |           |
|    total_timesteps      | 400000    |
| train/                  |           |
|    approx_kl            | 0.0041589 |
|    clip_fraction        | 0.00983   |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.46     |
|    explained_variance   | -11.1     |
|    learning_rate        | 5e-05     |
|    loss                 | -0.0732   |
|    n_updates            | 192       |
|    policy_gradient_loss | -0.000279 |
|    std                  | 1.04      |
|    value_loss           | 0.000755  |
---------------------------------------
New best mean reward!
-------------------------------
| time/              |        |
|    fps             | 1360   |
|    iterations      | 49     |
|    time_elapsed    | 295    |
|    total_timesteps | 401408 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 1368        |
|    iterations           | 50          |
|    time_elapsed         | 299         |
|    total_timesteps      | 409600      |
| train/                  |             |
|    approx_kl            | 0.001836411 |
|    clip_fraction        | 0.0011      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.46       |
|    explained_variance   | -10.2       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0737     |
|    n_updates            | 196         |
|    policy_gradient_loss | -0.000239   |
|    std                  | 1.04        |
|    value_loss           | 0.000726    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 1376        |
|    iterations           | 51          |
|    time_elapsed         | 303         |
|    total_timesteps      | 417792      |
| train/                  |             |
|    approx_kl            | 0.004138799 |
|    clip_fraction        | 0.0083      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.46       |
|    explained_variance   | -8.78       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0747     |
|    n_updates            | 200         |
|    policy_gradient_loss | -0.000646   |
|    std                  | 1.05        |
|    value_loss           | 0.000713    |
-----------------------------------------
-------------------------------------------
| time/                   |               |
|    fps                  | 1383          |
|    iterations           | 52            |
|    time_elapsed         | 307           |
|    total_timesteps      | 425984        |
| train/                  |               |
|    approx_kl            | 0.00047387765 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.46         |
|    explained_variance   | -9.74         |
|    learning_rate        | 5e-05         |
|    loss                 | -0.0741       |
|    n_updates            | 204           |
|    policy_gradient_loss | -9.73e-05     |
|    std                  | 1.05          |
|    value_loss           | 0.000678      |
-------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1391         |
|    iterations           | 53           |
|    time_elapsed         | 312          |
|    total_timesteps      | 434176       |
| train/                  |              |
|    approx_kl            | 0.0012286836 |
|    clip_fraction        | 0.00342      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.46        |
|    explained_variance   | -8.1         |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0714      |
|    n_updates            | 208          |
|    policy_gradient_loss | -0.000186    |
|    std                  | 1.05         |
|    value_loss           | 0.000707     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1398         |
|    iterations           | 54           |
|    time_elapsed         | 316          |
|    total_timesteps      | 442368       |
| train/                  |              |
|    approx_kl            | 0.0034107799 |
|    clip_fraction        | 0.00449      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.46        |
|    explained_variance   | -8.87        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0798      |
|    n_updates            | 212          |
|    policy_gradient_loss | -0.000613    |
|    std                  | 1.05         |
|    value_loss           | 0.000663     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 1405        |
|    iterations           | 55          |
|    time_elapsed         | 320         |
|    total_timesteps      | 450560      |
| train/                  |             |
|    approx_kl            | 0.003386978 |
|    clip_fraction        | 0.00531     |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.47       |
|    explained_variance   | -8.63       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0751     |
|    n_updates            | 216         |
|    policy_gradient_loss | -0.000151   |
|    std                  | 1.05        |
|    value_loss           | 0.000638    |
-----------------------------------------
-------------------------------------------
| time/                   |               |
|    fps                  | 1411          |
|    iterations           | 56            |
|    time_elapsed         | 324           |
|    total_timesteps      | 458752        |
| train/                  |               |
|    approx_kl            | 4.1318395e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.47         |
|    explained_variance   | -7.25         |
|    learning_rate        | 5e-05         |
|    loss                 | -0.0735       |
|    n_updates            | 220           |
|    policy_gradient_loss | 3.41e-05      |
|    std                  | 1.05          |
|    value_loss           | 0.000639      |
-------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1418         |
|    iterations           | 57           |
|    time_elapsed         | 329          |
|    total_timesteps      | 466944       |
| train/                  |              |
|    approx_kl            | 0.0003775177 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.47        |
|    explained_variance   | -7.9         |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0728      |
|    n_updates            | 224          |
|    policy_gradient_loss | -9.71e-05    |
|    std                  | 1.05         |
|    value_loss           | 0.00059      |
------------------------------------------
-------------------------------------------
| time/                   |               |
|    fps                  | 1424          |
|    iterations           | 58            |
|    time_elapsed         | 333           |
|    total_timesteps      | 475136        |
| train/                  |               |
|    approx_kl            | 0.00031719828 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.47         |
|    explained_variance   | -5.07         |
|    learning_rate        | 5e-05         |
|    loss                 | -0.073        |
|    n_updates            | 228           |
|    policy_gradient_loss | -5.18e-05     |
|    std                  | 1.05          |
|    value_loss           | 0.000631      |
-------------------------------------------
Eval num_timesteps=480000, episode_reward=0.05 +/- 0.08
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | 0.0462       |
| time/                   |              |
|    total_timesteps      | 480000       |
| train/                  |              |
|    approx_kl            | 0.0028418037 |
|    clip_fraction        | 0.00296      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.47        |
|    explained_variance   | -8.36        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0739      |
|    n_updates            | 232          |
|    policy_gradient_loss | -0.000366    |
|    std                  | 1.05         |
|    value_loss           | 0.000607     |
------------------------------------------
New best mean reward!
-------------------------------
| time/              |        |
|    fps             | 1339   |
|    iterations      | 59     |
|    time_elapsed    | 360    |
|    total_timesteps | 483328 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1345         |
|    iterations           | 60           |
|    time_elapsed         | 365          |
|    total_timesteps      | 491520       |
| train/                  |              |
|    approx_kl            | 0.0039490433 |
|    clip_fraction        | 0.0097       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.47        |
|    explained_variance   | -10.8        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0776      |
|    n_updates            | 236          |
|    policy_gradient_loss | -0.000499    |
|    std                  | 1.05         |
|    value_loss           | 0.000567     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1352         |
|    iterations           | 61           |
|    time_elapsed         | 369          |
|    total_timesteps      | 499712       |
| train/                  |              |
|    approx_kl            | 0.0033317218 |
|    clip_fraction        | 0.0113       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.47        |
|    explained_variance   | -9.39        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0746      |
|    n_updates            | 240          |
|    policy_gradient_loss | -0.000663    |
|    std                  | 1.06         |
|    value_loss           | 0.000544     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1358         |
|    iterations           | 62           |
|    time_elapsed         | 373          |
|    total_timesteps      | 507904       |
| train/                  |              |
|    approx_kl            | 0.0001589495 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.47        |
|    explained_variance   | -6.91        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0742      |
|    n_updates            | 244          |
|    policy_gradient_loss | 4.33e-06     |
|    std                  | 1.06         |
|    value_loss           | 0.000533     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1365         |
|    iterations           | 63           |
|    time_elapsed         | 377          |
|    total_timesteps      | 516096       |
| train/                  |              |
|    approx_kl            | 0.0032547684 |
|    clip_fraction        | 0.00516      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.47        |
|    explained_variance   | -4.92        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0696      |
|    n_updates            | 248          |
|    policy_gradient_loss | -0.000373    |
|    std                  | 1.06         |
|    value_loss           | 0.000568     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1371         |
|    iterations           | 64           |
|    time_elapsed         | 382          |
|    total_timesteps      | 524288       |
| train/                  |              |
|    approx_kl            | 0.0008145275 |
|    clip_fraction        | 3.05e-05     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.47        |
|    explained_variance   | -6.43        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0723      |
|    n_updates            | 252          |
|    policy_gradient_loss | -9.07e-05    |
|    std                  | 1.06         |
|    value_loss           | 0.000543     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1377         |
|    iterations           | 65           |
|    time_elapsed         | 386          |
|    total_timesteps      | 532480       |
| train/                  |              |
|    approx_kl            | 0.0041445284 |
|    clip_fraction        | 0.0139       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.48        |
|    explained_variance   | -8.57        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0728      |
|    n_updates            | 256          |
|    policy_gradient_loss | -0.000549    |
|    std                  | 1.06         |
|    value_loss           | 0.000489     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 1383        |
|    iterations           | 66          |
|    time_elapsed         | 390         |
|    total_timesteps      | 540672      |
| train/                  |             |
|    approx_kl            | 7.44603e-05 |
|    clip_fraction        | 0           |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.48       |
|    explained_variance   | -11         |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0737     |
|    n_updates            | 260         |
|    policy_gradient_loss | 8.03e-05    |
|    std                  | 1.06        |
|    value_loss           | 0.000505    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 1389        |
|    iterations           | 67          |
|    time_elapsed         | 394         |
|    total_timesteps      | 548864      |
| train/                  |             |
|    approx_kl            | 0.003617586 |
|    clip_fraction        | 0.00568     |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.48       |
|    explained_variance   | -7.4        |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0717     |
|    n_updates            | 264         |
|    policy_gradient_loss | -0.000553   |
|    std                  | 1.06        |
|    value_loss           | 0.000487    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 1395        |
|    iterations           | 68          |
|    time_elapsed         | 399         |
|    total_timesteps      | 557056      |
| train/                  |             |
|    approx_kl            | 0.004155377 |
|    clip_fraction        | 0.00784     |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.48       |
|    explained_variance   | -4.69       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0764     |
|    n_updates            | 268         |
|    policy_gradient_loss | -0.000617   |
|    std                  | 1.06        |
|    value_loss           | 0.000484    |
-----------------------------------------
Eval num_timesteps=560000, episode_reward=0.03 +/- 0.09
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | 0.0291       |
| time/                   |              |
|    total_timesteps      | 560000       |
| train/                  |              |
|    approx_kl            | 0.0010674519 |
|    clip_fraction        | 6.1e-05      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.48        |
|    explained_variance   | -5.99        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0753      |
|    n_updates            | 272          |
|    policy_gradient_loss | -8.67e-05    |
|    std                  | 1.06         |
|    value_loss           | 0.000458     |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 1325   |
|    iterations      | 69     |
|    time_elapsed    | 426    |
|    total_timesteps | 565248 |
-------------------------------
-------------------------------------------
| time/                   |               |
|    fps                  | 1331          |
|    iterations           | 70            |
|    time_elapsed         | 430           |
|    total_timesteps      | 573440        |
| train/                  |               |
|    approx_kl            | 0.00010136447 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.48         |
|    explained_variance   | -6.71         |
|    learning_rate        | 5e-05         |
|    loss                 | -0.0742       |
|    n_updates            | 276           |
|    policy_gradient_loss | 4.67e-06      |
|    std                  | 1.06          |
|    value_loss           | 0.000445      |
-------------------------------------------
-------------------------------------------
| time/                   |               |
|    fps                  | 1337          |
|    iterations           | 71            |
|    time_elapsed         | 434           |
|    total_timesteps      | 581632        |
| train/                  |               |
|    approx_kl            | 0.00038893856 |
|    clip_fraction        | 3.05e-05      |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.48         |
|    explained_variance   | -7.91         |
|    learning_rate        | 5e-05         |
|    loss                 | -0.0746       |
|    n_updates            | 280           |
|    policy_gradient_loss | -7.97e-05     |
|    std                  | 1.07          |
|    value_loss           | 0.000443      |
-------------------------------------------
-------------------------------------------
| time/                   |               |
|    fps                  | 1343          |
|    iterations           | 72            |
|    time_elapsed         | 439           |
|    total_timesteps      | 589824        |
| train/                  |               |
|    approx_kl            | 0.00016569815 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.48         |
|    explained_variance   | -7.3          |
|    learning_rate        | 5e-05         |
|    loss                 | -0.0744       |
|    n_updates            | 284           |
|    policy_gradient_loss | 1.86e-05      |
|    std                  | 1.07          |
|    value_loss           | 0.000429      |
-------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1349         |
|    iterations           | 73           |
|    time_elapsed         | 443          |
|    total_timesteps      | 598016       |
| train/                  |              |
|    approx_kl            | 0.0036669576 |
|    clip_fraction        | 0.0143       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.48        |
|    explained_variance   | -7.13        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0755      |
|    n_updates            | 288          |
|    policy_gradient_loss | -0.000835    |
|    std                  | 1.07         |
|    value_loss           | 0.00042      |
------------------------------------------
-------------------------------------------
| time/                   |               |
|    fps                  | 1354          |
|    iterations           | 74            |
|    time_elapsed         | 447           |
|    total_timesteps      | 606208        |
| train/                  |               |
|    approx_kl            | 4.9364164e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.49         |
|    explained_variance   | -6.29         |
|    learning_rate        | 5e-05         |
|    loss                 | -0.0745       |
|    n_updates            | 292           |
|    policy_gradient_loss | -1.18e-05     |
|    std                  | 1.07          |
|    value_loss           | 0.000423      |
-------------------------------------------
--------------------------------------------
| time/                   |                |
|    fps                  | 1359           |
|    iterations           | 75             |
|    time_elapsed         | 451            |
|    total_timesteps      | 614400         |
| train/                  |                |
|    approx_kl            | 0.000119390286 |
|    clip_fraction        | 0              |
|    clip_range           | 0.2            |
|    entropy_loss         | -1.49          |
|    explained_variance   | -7.93          |
|    learning_rate        | 5e-05          |
|    loss                 | -0.0741        |
|    n_updates            | 296            |
|    policy_gradient_loss | -1.26e-05      |
|    std                  | 1.07           |
|    value_loss           | 0.00039        |
--------------------------------------------
-------------------------------------------
| time/                   |               |
|    fps                  | 1365          |
|    iterations           | 76            |
|    time_elapsed         | 456           |
|    total_timesteps      | 622592        |
| train/                  |               |
|    approx_kl            | 0.00019538298 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.49         |
|    explained_variance   | -8.48         |
|    learning_rate        | 5e-05         |
|    loss                 | -0.0747       |
|    n_updates            | 300           |
|    policy_gradient_loss | 4.95e-05      |
|    std                  | 1.07          |
|    value_loss           | 0.000377      |
-------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1370         |
|    iterations           | 77           |
|    time_elapsed         | 460          |
|    total_timesteps      | 630784       |
| train/                  |              |
|    approx_kl            | 0.0023341028 |
|    clip_fraction        | 0.00156      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.49        |
|    explained_variance   | -6.71        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.075       |
|    n_updates            | 304          |
|    policy_gradient_loss | -0.000266    |
|    std                  | 1.07         |
|    value_loss           | 0.000364     |
------------------------------------------
-------------------------------------------
| time/                   |               |
|    fps                  | 1375          |
|    iterations           | 78            |
|    time_elapsed         | 464           |
|    total_timesteps      | 638976        |
| train/                  |               |
|    approx_kl            | 4.3014334e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.49         |
|    explained_variance   | -7.35         |
|    learning_rate        | 5e-05         |
|    loss                 | -0.0746       |
|    n_updates            | 308           |
|    policy_gradient_loss | -2.68e-06     |
|    std                  | 1.08          |
|    value_loss           | 0.000364      |
-------------------------------------------
Eval num_timesteps=640000, episode_reward=0.02 +/- 0.07
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | 0.0238      |
| time/                   |             |
|    total_timesteps      | 640000      |
| train/                  |             |
|    approx_kl            | 0.001598706 |
|    clip_fraction        | 0.000336    |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.49       |
|    explained_variance   | -5.63       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0785     |
|    n_updates            | 312         |
|    policy_gradient_loss | -0.000106   |
|    std                  | 1.08        |
|    value_loss           | 0.000375    |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 1314   |
|    iterations      | 79     |
|    time_elapsed    | 492    |
|    total_timesteps | 647168 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1318         |
|    iterations           | 80           |
|    time_elapsed         | 497          |
|    total_timesteps      | 655360       |
| train/                  |              |
|    approx_kl            | 0.0038201131 |
|    clip_fraction        | 0.00827      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.49        |
|    explained_variance   | -7.64        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.076       |
|    n_updates            | 316          |
|    policy_gradient_loss | -0.000383    |
|    std                  | 1.08         |
|    value_loss           | 0.00036      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1322         |
|    iterations           | 81           |
|    time_elapsed         | 501          |
|    total_timesteps      | 663552       |
| train/                  |              |
|    approx_kl            | 0.0039022504 |
|    clip_fraction        | 0.00717      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.49        |
|    explained_variance   | -5.92        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0775      |
|    n_updates            | 320          |
|    policy_gradient_loss | -0.000473    |
|    std                  | 1.08         |
|    value_loss           | 0.000358     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 1326        |
|    iterations           | 82          |
|    time_elapsed         | 506         |
|    total_timesteps      | 671744      |
| train/                  |             |
|    approx_kl            | 0.002594853 |
|    clip_fraction        | 0.00204     |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.5        |
|    explained_variance   | -8.68       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0753     |
|    n_updates            | 324         |
|    policy_gradient_loss | -0.000364   |
|    std                  | 1.08        |
|    value_loss           | 0.000326    |
-----------------------------------------
-------------------------------------------
| time/                   |               |
|    fps                  | 1330          |
|    iterations           | 83            |
|    time_elapsed         | 510           |
|    total_timesteps      | 679936        |
| train/                  |               |
|    approx_kl            | 5.8772734e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.5          |
|    explained_variance   | -6.13         |
|    learning_rate        | 5e-05         |
|    loss                 | -0.0751       |
|    n_updates            | 328           |
|    policy_gradient_loss | 5.53e-05      |
|    std                  | 1.08          |
|    value_loss           | 0.000326      |
-------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1334         |
|    iterations           | 84           |
|    time_elapsed         | 515          |
|    total_timesteps      | 688128       |
| train/                  |              |
|    approx_kl            | 0.0025912244 |
|    clip_fraction        | 0.00208      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.5         |
|    explained_variance   | -6.35        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0768      |
|    n_updates            | 332          |
|    policy_gradient_loss | -0.000248    |
|    std                  | 1.08         |
|    value_loss           | 0.000332     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 1338        |
|    iterations           | 85          |
|    time_elapsed         | 520         |
|    total_timesteps      | 696320      |
| train/                  |             |
|    approx_kl            | 0.002096327 |
|    clip_fraction        | 0.0011      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.5        |
|    explained_variance   | -9.1        |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0768     |
|    n_updates            | 336         |
|    policy_gradient_loss | -0.000304   |
|    std                  | 1.08        |
|    value_loss           | 0.000304    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1342         |
|    iterations           | 86           |
|    time_elapsed         | 524          |
|    total_timesteps      | 704512       |
| train/                  |              |
|    approx_kl            | 0.0030330978 |
|    clip_fraction        | 0.0162       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.5         |
|    explained_variance   | -6.24        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0745      |
|    n_updates            | 340          |
|    policy_gradient_loss | -0.00126     |
|    std                  | 1.08         |
|    value_loss           | 0.000312     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1346         |
|    iterations           | 87           |
|    time_elapsed         | 529          |
|    total_timesteps      | 712704       |
| train/                  |              |
|    approx_kl            | 0.0028913291 |
|    clip_fraction        | 0.00293      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.5         |
|    explained_variance   | -6.64        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0787      |
|    n_updates            | 344          |
|    policy_gradient_loss | -0.00025     |
|    std                  | 1.09         |
|    value_loss           | 0.000307     |
------------------------------------------
Eval num_timesteps=720000, episode_reward=-0.04 +/- 0.08
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | -0.0419      |
| time/                   |              |
|    total_timesteps      | 720000       |
| train/                  |              |
|    approx_kl            | 0.0039784396 |
|    clip_fraction        | 0.00858      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.5         |
|    explained_variance   | -8.78        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0747      |
|    n_updates            | 348          |
|    policy_gradient_loss | -0.000486    |
|    std                  | 1.09         |
|    value_loss           | 0.000297     |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 1295   |
|    iterations      | 88     |
|    time_elapsed    | 556    |
|    total_timesteps | 720896 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1299         |
|    iterations           | 89           |
|    time_elapsed         | 560          |
|    total_timesteps      | 729088       |
| train/                  |              |
|    approx_kl            | 0.0024299985 |
|    clip_fraction        | 0.00143      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.5         |
|    explained_variance   | -2.73        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0767      |
|    n_updates            | 352          |
|    policy_gradient_loss | -0.000225    |
|    std                  | 1.09         |
|    value_loss           | 0.000365     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1303         |
|    iterations           | 90           |
|    time_elapsed         | 565          |
|    total_timesteps      | 737280       |
| train/                  |              |
|    approx_kl            | 0.0019316345 |
|    clip_fraction        | 0.000763     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.5         |
|    explained_variance   | -3.06        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0745      |
|    n_updates            | 356          |
|    policy_gradient_loss | -0.000197    |
|    std                  | 1.09         |
|    value_loss           | 0.000349     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1307         |
|    iterations           | 91           |
|    time_elapsed         | 570          |
|    total_timesteps      | 745472       |
| train/                  |              |
|    approx_kl            | 3.090482e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.51        |
|    explained_variance   | -5.33        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.075       |
|    n_updates            | 360          |
|    policy_gradient_loss | 3.31e-05     |
|    std                  | 1.09         |
|    value_loss           | 0.000314     |
------------------------------------------
-------------------------------------------
| time/                   |               |
|    fps                  | 1311          |
|    iterations           | 92            |
|    time_elapsed         | 574           |
|    total_timesteps      | 753664        |
| train/                  |               |
|    approx_kl            | 2.5596943e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.51         |
|    explained_variance   | -6.4          |
|    learning_rate        | 5e-05         |
|    loss                 | -0.0755       |
|    n_updates            | 364           |
|    policy_gradient_loss | 8.89e-06      |
|    std                  | 1.09          |
|    value_loss           | 0.000295      |
-------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1314         |
|    iterations           | 93           |
|    time_elapsed         | 579          |
|    total_timesteps      | 761856       |
| train/                  |              |
|    approx_kl            | 0.0021528937 |
|    clip_fraction        | 0.00143      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.51        |
|    explained_variance   | -7.48        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0762      |
|    n_updates            | 368          |
|    policy_gradient_loss | -9.24e-05    |
|    std                  | 1.09         |
|    value_loss           | 0.000275     |
------------------------------------------
-------------------------------------------
| time/                   |               |
|    fps                  | 1318          |
|    iterations           | 94            |
|    time_elapsed         | 584           |
|    total_timesteps      | 770048        |
| train/                  |               |
|    approx_kl            | 0.00047362107 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.51         |
|    explained_variance   | -7.01         |
|    learning_rate        | 5e-05         |
|    loss                 | -0.0748       |
|    n_updates            | 372           |
|    policy_gradient_loss | 5.7e-05       |
|    std                  | 1.1           |
|    value_loss           | 0.000267      |
-------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1322         |
|    iterations           | 95           |
|    time_elapsed         | 588          |
|    total_timesteps      | 778240       |
| train/                  |              |
|    approx_kl            | 0.0012496455 |
|    clip_fraction        | 9.16e-05     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.51        |
|    explained_variance   | -5.57        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0757      |
|    n_updates            | 376          |
|    policy_gradient_loss | -1.05e-05    |
|    std                  | 1.1          |
|    value_loss           | 0.000273     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 1325        |
|    iterations           | 96          |
|    time_elapsed         | 593         |
|    total_timesteps      | 786432      |
| train/                  |             |
|    approx_kl            | 0.001734768 |
|    clip_fraction        | 0.000458    |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.51       |
|    explained_variance   | -6.91       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0781     |
|    n_updates            | 380         |
|    policy_gradient_loss | -0.000161   |
|    std                  | 1.1         |
|    value_loss           | 0.000264    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1330         |
|    iterations           | 97           |
|    time_elapsed         | 597          |
|    total_timesteps      | 794624       |
| train/                  |              |
|    approx_kl            | 0.0031870306 |
|    clip_fraction        | 0.00995      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.51        |
|    explained_variance   | -5.88        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0752      |
|    n_updates            | 384          |
|    policy_gradient_loss | -0.000322    |
|    std                  | 1.1          |
|    value_loss           | 0.000254     |
------------------------------------------
Eval num_timesteps=800000, episode_reward=0.01 +/- 0.12
Episode length: 2340.00 +/- 0.00
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 2.34e+03      |
|    mean_reward          | 0.0096        |
| time/                   |               |
|    total_timesteps      | 800000        |
| train/                  |               |
|    approx_kl            | 0.00017579901 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.52         |
|    explained_variance   | -6.46         |
|    learning_rate        | 5e-05         |
|    loss                 | -0.0759       |
|    n_updates            | 388           |
|    policy_gradient_loss | 3.64e-05      |
|    std                  | 1.1           |
|    value_loss           | 0.000264      |
-------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 1285   |
|    iterations      | 98     |
|    time_elapsed    | 624    |
|    total_timesteps | 802816 |
-------------------------------
-------------------------------------------
| time/                   |               |
|    fps                  | 1290          |
|    iterations           | 99            |
|    time_elapsed         | 628           |
|    total_timesteps      | 811008        |
| train/                  |               |
|    approx_kl            | 2.3695196e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.52         |
|    explained_variance   | -4.4          |
|    learning_rate        | 5e-05         |
|    loss                 | -0.0756       |
|    n_updates            | 392           |
|    policy_gradient_loss | -3.53e-05     |
|    std                  | 1.1           |
|    value_loss           | 0.000279      |
-------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1294         |
|    iterations           | 100          |
|    time_elapsed         | 632          |
|    total_timesteps      | 819200       |
| train/                  |              |
|    approx_kl            | 0.0035428593 |
|    clip_fraction        | 0.00546      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.52        |
|    explained_variance   | -3.26        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0744      |
|    n_updates            | 396          |
|    policy_gradient_loss | -0.000301    |
|    std                  | 1.1          |
|    value_loss           | 0.000276     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1298         |
|    iterations           | 101          |
|    time_elapsed         | 637          |
|    total_timesteps      | 827392       |
| train/                  |              |
|    approx_kl            | 0.0030719535 |
|    clip_fraction        | 0.00381      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.52        |
|    explained_variance   | -6.13        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0825      |
|    n_updates            | 400          |
|    policy_gradient_loss | -0.000387    |
|    std                  | 1.11         |
|    value_loss           | 0.000261     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1302         |
|    iterations           | 102          |
|    time_elapsed         | 641          |
|    total_timesteps      | 835584       |
| train/                  |              |
|    approx_kl            | 0.0015860725 |
|    clip_fraction        | 0.000305     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.52        |
|    explained_variance   | -5.58        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0771      |
|    n_updates            | 404          |
|    policy_gradient_loss | -5.17e-05    |
|    std                  | 1.11         |
|    value_loss           | 0.00024      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1306         |
|    iterations           | 103          |
|    time_elapsed         | 645          |
|    total_timesteps      | 843776       |
| train/                  |              |
|    approx_kl            | 0.0030400972 |
|    clip_fraction        | 0.0107       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.52        |
|    explained_variance   | -7.38        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0798      |
|    n_updates            | 408          |
|    policy_gradient_loss | -0.00104     |
|    std                  | 1.11         |
|    value_loss           | 0.000225     |
------------------------------------------
-------------------------------------------
| time/                   |               |
|    fps                  | 1310          |
|    iterations           | 104           |
|    time_elapsed         | 649           |
|    total_timesteps      | 851968        |
| train/                  |               |
|    approx_kl            | 3.5101868e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.52         |
|    explained_variance   | -6.98         |
|    learning_rate        | 5e-05         |
|    loss                 | -0.0761       |
|    n_updates            | 412           |
|    policy_gradient_loss | 3.94e-05      |
|    std                  | 1.11          |
|    value_loss           | 0.00021       |
-------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1314         |
|    iterations           | 105          |
|    time_elapsed         | 654          |
|    total_timesteps      | 860160       |
| train/                  |              |
|    approx_kl            | 0.0032280749 |
|    clip_fraction        | 0.00412      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.52        |
|    explained_variance   | -7.32        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.077       |
|    n_updates            | 416          |
|    policy_gradient_loss | -0.000287    |
|    std                  | 1.11         |
|    value_loss           | 0.000224     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1318         |
|    iterations           | 106          |
|    time_elapsed         | 658          |
|    total_timesteps      | 868352       |
| train/                  |              |
|    approx_kl            | 0.0016131208 |
|    clip_fraction        | 0.000153     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.52        |
|    explained_variance   | -5.63        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0733      |
|    n_updates            | 420          |
|    policy_gradient_loss | -8.87e-05    |
|    std                  | 1.11         |
|    value_loss           | 0.000223     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 1322        |
|    iterations           | 107         |
|    time_elapsed         | 662         |
|    total_timesteps      | 876544      |
| train/                  |             |
|    approx_kl            | 0.001218001 |
|    clip_fraction        | 0.000183    |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.53       |
|    explained_variance   | -5.46       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0746     |
|    n_updates            | 424         |
|    policy_gradient_loss | -0.000285   |
|    std                  | 1.11        |
|    value_loss           | 0.000213    |
-----------------------------------------
Eval num_timesteps=880000, episode_reward=-0.04 +/- 0.09
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | -0.0365      |
| time/                   |              |
|    total_timesteps      | 880000       |
| train/                  |              |
|    approx_kl            | 3.250013e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.53        |
|    explained_variance   | -6.8         |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0765      |
|    n_updates            | 428          |
|    policy_gradient_loss | 7.57e-05     |
|    std                  | 1.12         |
|    value_loss           | 0.000209     |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 1283   |
|    iterations      | 108    |
|    time_elapsed    | 689    |
|    total_timesteps | 884736 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1287         |
|    iterations           | 109          |
|    time_elapsed         | 693          |
|    total_timesteps      | 892928       |
| train/                  |              |
|    approx_kl            | 0.0035530713 |
|    clip_fraction        | 0.0105       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.53        |
|    explained_variance   | -6.89        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0775      |
|    n_updates            | 432          |
|    policy_gradient_loss | -0.000883    |
|    std                  | 1.12         |
|    value_loss           | 0.000207     |
------------------------------------------
-------------------------------------------
| time/                   |               |
|    fps                  | 1291          |
|    iterations           | 110           |
|    time_elapsed         | 697           |
|    total_timesteps      | 901120        |
| train/                  |               |
|    approx_kl            | 8.4837295e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.53         |
|    explained_variance   | -4.99         |
|    learning_rate        | 5e-05         |
|    loss                 | -0.0762       |
|    n_updates            | 436           |
|    policy_gradient_loss | 7.79e-06      |
|    std                  | 1.12          |
|    value_loss           | 0.000216      |
-------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1295         |
|    iterations           | 111          |
|    time_elapsed         | 702          |
|    total_timesteps      | 909312       |
| train/                  |              |
|    approx_kl            | 0.0023351389 |
|    clip_fraction        | 0.00162      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.53        |
|    explained_variance   | -8.3         |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0796      |
|    n_updates            | 440          |
|    policy_gradient_loss | -0.000249    |
|    std                  | 1.12         |
|    value_loss           | 0.000188     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1298         |
|    iterations           | 112          |
|    time_elapsed         | 706          |
|    total_timesteps      | 917504       |
| train/                  |              |
|    approx_kl            | 0.0041518463 |
|    clip_fraction        | 0.011        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.53        |
|    explained_variance   | -3.5         |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0768      |
|    n_updates            | 444          |
|    policy_gradient_loss | -0.000828    |
|    std                  | 1.12         |
|    value_loss           | 0.000217     |
------------------------------------------
-------------------------------------------
| time/                   |               |
|    fps                  | 1302          |
|    iterations           | 113           |
|    time_elapsed         | 710           |
|    total_timesteps      | 925696        |
| train/                  |               |
|    approx_kl            | 0.00013427107 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.53         |
|    explained_variance   | -2.99         |
|    learning_rate        | 5e-05         |
|    loss                 | -0.0772       |
|    n_updates            | 448           |
|    policy_gradient_loss | 2.17e-05      |
|    std                  | 1.12          |
|    value_loss           | 0.00022       |
-------------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 1306       |
|    iterations           | 114        |
|    time_elapsed         | 714        |
|    total_timesteps      | 933888     |
| train/                  |            |
|    approx_kl            | 0.00300048 |
|    clip_fraction        | 0.0128     |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.53      |
|    explained_variance   | -5.13      |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0799    |
|    n_updates            | 452        |
|    policy_gradient_loss | -0.000949  |
|    std                  | 1.12       |
|    value_loss           | 0.000203   |
----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1309         |
|    iterations           | 115          |
|    time_elapsed         | 719          |
|    total_timesteps      | 942080       |
| train/                  |              |
|    approx_kl            | 0.0020609666 |
|    clip_fraction        | 0.000885     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.53        |
|    explained_variance   | -4.49        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0749      |
|    n_updates            | 456          |
|    policy_gradient_loss | -0.000173    |
|    std                  | 1.12         |
|    value_loss           | 0.000197     |
------------------------------------------
-------------------------------------------
| time/                   |               |
|    fps                  | 1313          |
|    iterations           | 116           |
|    time_elapsed         | 723           |
|    total_timesteps      | 950272        |
| train/                  |               |
|    approx_kl            | 0.00023992197 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.54         |
|    explained_variance   | -4.95         |
|    learning_rate        | 5e-05         |
|    loss                 | -0.0781       |
|    n_updates            | 460           |
|    policy_gradient_loss | -4.82e-05     |
|    std                  | 1.12          |
|    value_loss           | 0.000196      |
-------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1317         |
|    iterations           | 117          |
|    time_elapsed         | 727          |
|    total_timesteps      | 958464       |
| train/                  |              |
|    approx_kl            | 0.0029649106 |
|    clip_fraction        | 0.00342      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.54        |
|    explained_variance   | -4.42        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0742      |
|    n_updates            | 464          |
|    policy_gradient_loss | -0.000335    |
|    std                  | 1.13         |
|    value_loss           | 0.000184     |
------------------------------------------
Eval num_timesteps=960000, episode_reward=-0.01 +/- 0.12
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | -0.015       |
| time/                   |              |
|    total_timesteps      | 960000       |
| train/                  |              |
|    approx_kl            | 0.0035664274 |
|    clip_fraction        | 0.00635      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.54        |
|    explained_variance   | -3.32        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0766      |
|    n_updates            | 468          |
|    policy_gradient_loss | -0.000484    |
|    std                  | 1.13         |
|    value_loss           | 0.000194     |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 1281   |
|    iterations      | 118    |
|    time_elapsed    | 754    |
|    total_timesteps | 966656 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1285         |
|    iterations           | 119          |
|    time_elapsed         | 758          |
|    total_timesteps      | 974848       |
| train/                  |              |
|    approx_kl            | 0.0031806885 |
|    clip_fraction        | 0.00354      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.54        |
|    explained_variance   | -3.13        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0796      |
|    n_updates            | 472          |
|    policy_gradient_loss | -0.000391    |
|    std                  | 1.13         |
|    value_loss           | 0.000208     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1290         |
|    iterations           | 120          |
|    time_elapsed         | 761          |
|    total_timesteps      | 983040       |
| train/                  |              |
|    approx_kl            | 0.0006332303 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.54        |
|    explained_variance   | -4.27        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0759      |
|    n_updates            | 476          |
|    policy_gradient_loss | -1.56e-05    |
|    std                  | 1.13         |
|    value_loss           | 0.00018      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1294         |
|    iterations           | 121          |
|    time_elapsed         | 765          |
|    total_timesteps      | 991232       |
| train/                  |              |
|    approx_kl            | 0.0042536687 |
|    clip_fraction        | 0.0225       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.54        |
|    explained_variance   | -2.41        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0792      |
|    n_updates            | 480          |
|    policy_gradient_loss | -0.00139     |
|    std                  | 1.13         |
|    value_loss           | 0.000203     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1297         |
|    iterations           | 122          |
|    time_elapsed         | 770          |
|    total_timesteps      | 999424       |
| train/                  |              |
|    approx_kl            | 0.0012605765 |
|    clip_fraction        | 0.000397     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.54        |
|    explained_variance   | -2.55        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0774      |
|    n_updates            | 484          |
|    policy_gradient_loss | -0.000177    |
|    std                  | 1.13         |
|    value_loss           | 0.000202     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1301         |
|    iterations           | 123          |
|    time_elapsed         | 774          |
|    total_timesteps      | 1007616      |
| train/                  |              |
|    approx_kl            | 0.0041353237 |
|    clip_fraction        | 0.00827      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.54        |
|    explained_variance   | -5.76        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0753      |
|    n_updates            | 488          |
|    policy_gradient_loss | -0.000382    |
|    std                  | 1.13         |
|    value_loss           | 0.000163     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 1305        |
|    iterations           | 124         |
|    time_elapsed         | 777         |
|    total_timesteps      | 1015808     |
| train/                  |             |
|    approx_kl            | 0.005061485 |
|    clip_fraction        | 0.0152      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.55       |
|    explained_variance   | -2.32       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0791     |
|    n_updates            | 492         |
|    policy_gradient_loss | -0.000887   |
|    std                  | 1.14        |
|    value_loss           | 0.000198    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 1309        |
|    iterations           | 125         |
|    time_elapsed         | 781         |
|    total_timesteps      | 1024000     |
| train/                  |             |
|    approx_kl            | 0.002245936 |
|    clip_fraction        | 0.00137     |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.55       |
|    explained_variance   | -3.41       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0811     |
|    n_updates            | 496         |
|    policy_gradient_loss | -0.000229   |
|    std                  | 1.14        |
|    value_loss           | 0.00018     |
-----------------------------------------
-------------------------------------------
| time/                   |               |
|    fps                  | 1313          |
|    iterations           | 126           |
|    time_elapsed         | 785           |
|    total_timesteps      | 1032192       |
| train/                  |               |
|    approx_kl            | 0.00023156372 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.55         |
|    explained_variance   | -4.63         |
|    learning_rate        | 5e-05         |
|    loss                 | -0.0781       |
|    n_updates            | 500           |
|    policy_gradient_loss | -1.49e-05     |
|    std                  | 1.14          |
|    value_loss           | 0.00017       |
-------------------------------------------
Eval num_timesteps=1040000, episode_reward=0.01 +/- 0.06
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | 0.00898      |
| time/                   |              |
|    total_timesteps      | 1040000      |
| train/                  |              |
|    approx_kl            | 0.0014983735 |
|    clip_fraction        | 0.000305     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.55        |
|    explained_variance   | -4.49        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0792      |
|    n_updates            | 504          |
|    policy_gradient_loss | -0.00019     |
|    std                  | 1.14         |
|    value_loss           | 0.000164     |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 1281    |
|    iterations      | 127     |
|    time_elapsed    | 811     |
|    total_timesteps | 1040384 |
--------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1285         |
|    iterations           | 128          |
|    time_elapsed         | 815          |
|    total_timesteps      | 1048576      |
| train/                  |              |
|    approx_kl            | 0.0015530082 |
|    clip_fraction        | 0.000519     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.55        |
|    explained_variance   | -4.4         |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0801      |
|    n_updates            | 508          |
|    policy_gradient_loss | -8.09e-05    |
|    std                  | 1.14         |
|    value_loss           | 0.000158     |
------------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 1289       |
|    iterations           | 129        |
|    time_elapsed         | 819        |
|    total_timesteps      | 1056768    |
| train/                  |            |
|    approx_kl            | 0.00352365 |
|    clip_fraction        | 0.0127     |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.55      |
|    explained_variance   | -4.68      |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0774    |
|    n_updates            | 512        |
|    policy_gradient_loss | -0.000654  |
|    std                  | 1.14       |
|    value_loss           | 0.000154   |
----------------------------------------
-------------------------------------------
| time/                   |               |
|    fps                  | 1292          |
|    iterations           | 130           |
|    time_elapsed         | 823           |
|    total_timesteps      | 1064960       |
| train/                  |               |
|    approx_kl            | 0.00013781589 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.55         |
|    explained_variance   | -6.05         |
|    learning_rate        | 5e-05         |
|    loss                 | -0.0776       |
|    n_updates            | 516           |
|    policy_gradient_loss | 5.5e-05       |
|    std                  | 1.14          |
|    value_loss           | 0.000144      |
-------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1296         |
|    iterations           | 131          |
|    time_elapsed         | 827          |
|    total_timesteps      | 1073152      |
| train/                  |              |
|    approx_kl            | 0.0001886743 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.55        |
|    explained_variance   | -3.79        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0768      |
|    n_updates            | 520          |
|    policy_gradient_loss | 3.01e-05     |
|    std                  | 1.14         |
|    value_loss           | 0.00016      |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 1300        |
|    iterations           | 132         |
|    time_elapsed         | 831         |
|    total_timesteps      | 1081344     |
| train/                  |             |
|    approx_kl            | 0.003487123 |
|    clip_fraction        | 0.005       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.55       |
|    explained_variance   | -4.37       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0822     |
|    n_updates            | 524         |
|    policy_gradient_loss | -0.000513   |
|    std                  | 1.14        |
|    value_loss           | 0.000154    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1304         |
|    iterations           | 133          |
|    time_elapsed         | 835          |
|    total_timesteps      | 1089536      |
| train/                  |              |
|    approx_kl            | 0.0023336518 |
|    clip_fraction        | 0.00128      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.55        |
|    explained_variance   | -4.12        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0807      |
|    n_updates            | 528          |
|    policy_gradient_loss | -0.000408    |
|    std                  | 1.15         |
|    value_loss           | 0.000149     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1308         |
|    iterations           | 134          |
|    time_elapsed         | 839          |
|    total_timesteps      | 1097728      |
| train/                  |              |
|    approx_kl            | 0.0042211674 |
|    clip_fraction        | 0.0111       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.56        |
|    explained_variance   | -3.97        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0753      |
|    n_updates            | 532          |
|    policy_gradient_loss | -0.00103     |
|    std                  | 1.15         |
|    value_loss           | 0.000143     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1311         |
|    iterations           | 135          |
|    time_elapsed         | 842          |
|    total_timesteps      | 1105920      |
| train/                  |              |
|    approx_kl            | 0.0010491827 |
|    clip_fraction        | 9.16e-05     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.56        |
|    explained_variance   | -2.68        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0763      |
|    n_updates            | 536          |
|    policy_gradient_loss | -0.000115    |
|    std                  | 1.15         |
|    value_loss           | 0.000169     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 1315        |
|    iterations           | 136         |
|    time_elapsed         | 846         |
|    total_timesteps      | 1114112     |
| train/                  |             |
|    approx_kl            | 0.003642806 |
|    clip_fraction        | 0.00565     |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.56       |
|    explained_variance   | -3.28       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0835     |
|    n_updates            | 540         |
|    policy_gradient_loss | -0.000807   |
|    std                  | 1.15        |
|    value_loss           | 0.000154    |
-----------------------------------------
Eval num_timesteps=1120000, episode_reward=0.02 +/- 0.08
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | 0.0238       |
| time/                   |              |
|    total_timesteps      | 1120000      |
| train/                  |              |
|    approx_kl            | 0.0030326345 |
|    clip_fraction        | 0.0223       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.56        |
|    explained_variance   | -3.07        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0785      |
|    n_updates            | 544          |
|    policy_gradient_loss | -0.00137     |
|    std                  | 1.15         |
|    value_loss           | 0.000159     |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 1286    |
|    iterations      | 137     |
|    time_elapsed    | 872     |
|    total_timesteps | 1122304 |
--------------------------------
-------------------------------------------
| time/                   |               |
|    fps                  | 1290          |
|    iterations           | 138           |
|    time_elapsed         | 875           |
|    total_timesteps      | 1130496       |
| train/                  |               |
|    approx_kl            | 0.00070435647 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.56         |
|    explained_variance   | -2.2          |
|    learning_rate        | 5e-05         |
|    loss                 | -0.0803       |
|    n_updates            | 548           |
|    policy_gradient_loss | -3.15e-05     |
|    std                  | 1.15          |
|    value_loss           | 0.000163      |
-------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1295         |
|    iterations           | 139          |
|    time_elapsed         | 879          |
|    total_timesteps      | 1138688      |
| train/                  |              |
|    approx_kl            | 0.0003804992 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.56        |
|    explained_variance   | -3.17        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0768      |
|    n_updates            | 552          |
|    policy_gradient_loss | 0.000114     |
|    std                  | 1.15         |
|    value_loss           | 0.000146     |
------------------------------------------
--------------------------------------------
| time/                   |                |
|    fps                  | 1299           |
|    iterations           | 140            |
|    time_elapsed         | 882            |
|    total_timesteps      | 1146880        |
| train/                  |                |
|    approx_kl            | 0.000121784775 |
|    clip_fraction        | 0              |
|    clip_range           | 0.2            |
|    entropy_loss         | -1.56          |
|    explained_variance   | -4.64          |
|    learning_rate        | 5e-05          |
|    loss                 | -0.0784        |
|    n_updates            | 556            |
|    policy_gradient_loss | 8.69e-06       |
|    std                  | 1.15           |
|    value_loss           | 0.00013        |
--------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1303         |
|    iterations           | 141          |
|    time_elapsed         | 886          |
|    total_timesteps      | 1155072      |
| train/                  |              |
|    approx_kl            | 0.0032479172 |
|    clip_fraction        | 0.00375      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.56        |
|    explained_variance   | -2.02        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0773      |
|    n_updates            | 560          |
|    policy_gradient_loss | -0.000575    |
|    std                  | 1.16         |
|    value_loss           | 0.000161     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1307         |
|    iterations           | 142          |
|    time_elapsed         | 889          |
|    total_timesteps      | 1163264      |
| train/                  |              |
|    approx_kl            | 0.0007953294 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.56        |
|    explained_variance   | -2.14        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0799      |
|    n_updates            | 564          |
|    policy_gradient_loss | -0.000284    |
|    std                  | 1.16         |
|    value_loss           | 0.000157     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1311         |
|    iterations           | 143          |
|    time_elapsed         | 892          |
|    total_timesteps      | 1171456      |
| train/                  |              |
|    approx_kl            | 2.307781e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.56        |
|    explained_variance   | -3.77        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0787      |
|    n_updates            | 568          |
|    policy_gradient_loss | 1.43e-05     |
|    std                  | 1.16         |
|    value_loss           | 0.000133     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1316         |
|    iterations           | 144          |
|    time_elapsed         | 896          |
|    total_timesteps      | 1179648      |
| train/                  |              |
|    approx_kl            | 0.0008204254 |
|    clip_fraction        | 3.05e-05     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.57        |
|    explained_variance   | -4.91        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0792      |
|    n_updates            | 572          |
|    policy_gradient_loss | -0.000109    |
|    std                  | 1.16         |
|    value_loss           | 0.000122     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1320         |
|    iterations           | 145          |
|    time_elapsed         | 899          |
|    total_timesteps      | 1187840      |
| train/                  |              |
|    approx_kl            | 0.0036397201 |
|    clip_fraction        | 0.0127       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.57        |
|    explained_variance   | -5.74        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0842      |
|    n_updates            | 576          |
|    policy_gradient_loss | -0.000811    |
|    std                  | 1.16         |
|    value_loss           | 0.000115     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 1324        |
|    iterations           | 146         |
|    time_elapsed         | 903         |
|    total_timesteps      | 1196032     |
| train/                  |             |
|    approx_kl            | 0.004482578 |
|    clip_fraction        | 0.0126      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.57       |
|    explained_variance   | -6.73       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0825     |
|    n_updates            | 580         |
|    policy_gradient_loss | -0.000805   |
|    std                  | 1.16        |
|    value_loss           | 0.000114    |
-----------------------------------------
Eval num_timesteps=1200000, episode_reward=0.04 +/- 0.09
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | 0.0429       |
| time/                   |              |
|    total_timesteps      | 1200000      |
| train/                  |              |
|    approx_kl            | 0.0005241035 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.57        |
|    explained_variance   | -3.87        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.078       |
|    n_updates            | 584          |
|    policy_gradient_loss | -6.94e-05    |
|    std                  | 1.16         |
|    value_loss           | 0.00012      |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 1298    |
|    iterations      | 147     |
|    time_elapsed    | 927     |
|    total_timesteps | 1204224 |
--------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1301         |
|    iterations           | 148          |
|    time_elapsed         | 931          |
|    total_timesteps      | 1212416      |
| train/                  |              |
|    approx_kl            | 0.0015158395 |
|    clip_fraction        | 0.000214     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.57        |
|    explained_variance   | -5.01        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0781      |
|    n_updates            | 588          |
|    policy_gradient_loss | -0.000123    |
|    std                  | 1.16         |
|    value_loss           | 0.000123     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1305         |
|    iterations           | 149          |
|    time_elapsed         | 934          |
|    total_timesteps      | 1220608      |
| train/                  |              |
|    approx_kl            | 0.0024889268 |
|    clip_fraction        | 0.0018       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.57        |
|    explained_variance   | -4.28        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0779      |
|    n_updates            | 592          |
|    policy_gradient_loss | -0.000326    |
|    std                  | 1.17         |
|    value_loss           | 0.000119     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1309         |
|    iterations           | 150          |
|    time_elapsed         | 938          |
|    total_timesteps      | 1228800      |
| train/                  |              |
|    approx_kl            | 0.0014100797 |
|    clip_fraction        | 0.000275     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.57        |
|    explained_variance   | -3.88        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0795      |
|    n_updates            | 596          |
|    policy_gradient_loss | -9.04e-05    |
|    std                  | 1.17         |
|    value_loss           | 0.000116     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1313         |
|    iterations           | 151          |
|    time_elapsed         | 941          |
|    total_timesteps      | 1236992      |
| train/                  |              |
|    approx_kl            | 0.0007031758 |
|    clip_fraction        | 6.1e-05      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.57        |
|    explained_variance   | -1.87        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0787      |
|    n_updates            | 600          |
|    policy_gradient_loss | 3.37e-05     |
|    std                  | 1.17         |
|    value_loss           | 0.000142     |
------------------------------------------
-------------------------------------------
| time/                   |               |
|    fps                  | 1317          |
|    iterations           | 152           |
|    time_elapsed         | 945           |
|    total_timesteps      | 1245184       |
| train/                  |               |
|    approx_kl            | 0.00013231464 |
|    clip_fraction        | 3.05e-05      |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.58         |
|    explained_variance   | -3.52         |
|    learning_rate        | 5e-05         |
|    loss                 | -0.0795       |
|    n_updates            | 604           |
|    policy_gradient_loss | -0.0001       |
|    std                  | 1.17          |
|    value_loss           | 0.000113      |
-------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1321         |
|    iterations           | 153          |
|    time_elapsed         | 948          |
|    total_timesteps      | 1253376      |
| train/                  |              |
|    approx_kl            | 8.198839e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.58        |
|    explained_variance   | -2.29        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0794      |
|    n_updates            | 608          |
|    policy_gradient_loss | 4.76e-05     |
|    std                  | 1.17         |
|    value_loss           | 0.000128     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1325         |
|    iterations           | 154          |
|    time_elapsed         | 951          |
|    total_timesteps      | 1261568      |
| train/                  |              |
|    approx_kl            | 0.0031838035 |
|    clip_fraction        | 0.00433      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.58        |
|    explained_variance   | -1.51        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0814      |
|    n_updates            | 612          |
|    policy_gradient_loss | -0.000469    |
|    std                  | 1.17         |
|    value_loss           | 0.000143     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1329         |
|    iterations           | 155          |
|    time_elapsed         | 955          |
|    total_timesteps      | 1269760      |
| train/                  |              |
|    approx_kl            | 0.0006723451 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.58        |
|    explained_variance   | -3.19        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0806      |
|    n_updates            | 616          |
|    policy_gradient_loss | -0.000208    |
|    std                  | 1.18         |
|    value_loss           | 0.000115     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 1332        |
|    iterations           | 156         |
|    time_elapsed         | 958         |
|    total_timesteps      | 1277952     |
| train/                  |             |
|    approx_kl            | 0.001188351 |
|    clip_fraction        | 0.000153    |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.58       |
|    explained_variance   | -1.77       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0759     |
|    n_updates            | 620         |
|    policy_gradient_loss | 2.29e-05    |
|    std                  | 1.18        |
|    value_loss           | 0.000131    |
-----------------------------------------
Eval num_timesteps=1280000, episode_reward=-0.00 +/- 0.06
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | -0.00245     |
| time/                   |              |
|    total_timesteps      | 1280000      |
| train/                  |              |
|    approx_kl            | 0.0019474492 |
|    clip_fraction        | 0.00122      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.58        |
|    explained_variance   | -2.91        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0762      |
|    n_updates            | 624          |
|    policy_gradient_loss | -0.00016     |
|    std                  | 1.18         |
|    value_loss           | 0.000119     |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 1308    |
|    iterations      | 157     |
|    time_elapsed    | 983     |
|    total_timesteps | 1286144 |
--------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1311         |
|    iterations           | 158          |
|    time_elapsed         | 987          |
|    total_timesteps      | 1294336      |
| train/                  |              |
|    approx_kl            | 0.0031836336 |
|    clip_fraction        | 0.024        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.58        |
|    explained_variance   | -3.15        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.085       |
|    n_updates            | 628          |
|    policy_gradient_loss | -0.00143     |
|    std                  | 1.18         |
|    value_loss           | 0.000116     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 1314        |
|    iterations           | 159         |
|    time_elapsed         | 990         |
|    total_timesteps      | 1302528     |
| train/                  |             |
|    approx_kl            | 0.004242494 |
|    clip_fraction        | 0.0142      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.58       |
|    explained_variance   | -4.73       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.079      |
|    n_updates            | 632         |
|    policy_gradient_loss | -0.000803   |
|    std                  | 1.18        |
|    value_loss           | 0.000102    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1317         |
|    iterations           | 160          |
|    time_elapsed         | 994          |
|    total_timesteps      | 1310720      |
| train/                  |              |
|    approx_kl            | 0.0011914251 |
|    clip_fraction        | 0.000153     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.59        |
|    explained_variance   | -1.65        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0801      |
|    n_updates            | 636          |
|    policy_gradient_loss | -7.94e-05    |
|    std                  | 1.18         |
|    value_loss           | 0.000127     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 1320        |
|    iterations           | 161         |
|    time_elapsed         | 998         |
|    total_timesteps      | 1318912     |
| train/                  |             |
|    approx_kl            | 0.003833163 |
|    clip_fraction        | 0.0115      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.59       |
|    explained_variance   | -3.38       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0827     |
|    n_updates            | 640         |
|    policy_gradient_loss | -0.000745   |
|    std                  | 1.18        |
|    value_loss           | 0.000103    |
-----------------------------------------
-------------------------------------------
| time/                   |               |
|    fps                  | 1324          |
|    iterations           | 162           |
|    time_elapsed         | 1002          |
|    total_timesteps      | 1327104       |
| train/                  |               |
|    approx_kl            | 0.00097202056 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.59         |
|    explained_variance   | -3.94         |
|    learning_rate        | 5e-05         |
|    loss                 | -0.0813       |
|    n_updates            | 644           |
|    policy_gradient_loss | -9.18e-05     |
|    std                  | 1.19          |
|    value_loss           | 0.000103      |
-------------------------------------------
-------------------------------------------
| time/                   |               |
|    fps                  | 1327          |
|    iterations           | 163           |
|    time_elapsed         | 1006          |
|    total_timesteps      | 1335296       |
| train/                  |               |
|    approx_kl            | 1.5045989e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.59         |
|    explained_variance   | -2.09         |
|    learning_rate        | 5e-05         |
|    loss                 | -0.0794       |
|    n_updates            | 648           |
|    policy_gradient_loss | 4.49e-06      |
|    std                  | 1.19          |
|    value_loss           | 0.000113      |
-------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1330         |
|    iterations           | 164          |
|    time_elapsed         | 1010         |
|    total_timesteps      | 1343488      |
| train/                  |              |
|    approx_kl            | 0.0045938473 |
|    clip_fraction        | 0.0146       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.59        |
|    explained_variance   | -3.21        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0742      |
|    n_updates            | 652          |
|    policy_gradient_loss | -0.000897    |
|    std                  | 1.19         |
|    value_loss           | 0.000106     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1333         |
|    iterations           | 165          |
|    time_elapsed         | 1013         |
|    total_timesteps      | 1351680      |
| train/                  |              |
|    approx_kl            | 0.0025452073 |
|    clip_fraction        | 0.00204      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.59        |
|    explained_variance   | -2.39        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0774      |
|    n_updates            | 656          |
|    policy_gradient_loss | -0.000299    |
|    std                  | 1.19         |
|    value_loss           | 0.000106     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1336         |
|    iterations           | 166          |
|    time_elapsed         | 1017         |
|    total_timesteps      | 1359872      |
| train/                  |              |
|    approx_kl            | 0.0044088406 |
|    clip_fraction        | 0.0111       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.59        |
|    explained_variance   | -2.8         |
|    learning_rate        | 5e-05        |
|    loss                 | -0.078       |
|    n_updates            | 660          |
|    policy_gradient_loss | -0.000564    |
|    std                  | 1.19         |
|    value_loss           | 9.86e-05     |
------------------------------------------
Eval num_timesteps=1360000, episode_reward=0.03 +/- 0.05
Episode length: 2340.00 +/- 0.00
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 2.34e+03      |
|    mean_reward          | 0.0286        |
| time/                   |               |
|    total_timesteps      | 1360000       |
| train/                  |               |
|    approx_kl            | 0.00034682182 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.59         |
|    explained_variance   | -2.6          |
|    learning_rate        | 5e-05         |
|    loss                 | -0.0796       |
|    n_updates            | 664           |
|    policy_gradient_loss | -1.52e-05     |
|    std                  | 1.19          |
|    value_loss           | 0.000104      |
-------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 1311    |
|    iterations      | 167     |
|    time_elapsed    | 1043    |
|    total_timesteps | 1368064 |
--------------------------------
-------------------------------------------
| time/                   |               |
|    fps                  | 1314          |
|    iterations           | 168           |
|    time_elapsed         | 1046          |
|    total_timesteps      | 1376256       |
| train/                  |               |
|    approx_kl            | 0.00069965655 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.59         |
|    explained_variance   | -1.94         |
|    learning_rate        | 5e-05         |
|    loss                 | -0.0787       |
|    n_updates            | 668           |
|    policy_gradient_loss | -0.00011      |
|    std                  | 1.19          |
|    value_loss           | 0.000118      |
-------------------------------------------
-------------------------------------------
| time/                   |               |
|    fps                  | 1317          |
|    iterations           | 169           |
|    time_elapsed         | 1050          |
|    total_timesteps      | 1384448       |
| train/                  |               |
|    approx_kl            | 3.2572156e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.6          |
|    explained_variance   | -2.37         |
|    learning_rate        | 5e-05         |
|    loss                 | -0.0799       |
|    n_updates            | 672           |
|    policy_gradient_loss | -1.14e-05     |
|    std                  | 1.19          |
|    value_loss           | 0.000103      |
-------------------------------------------
-------------------------------------------
| time/                   |               |
|    fps                  | 1320          |
|    iterations           | 170           |
|    time_elapsed         | 1054          |
|    total_timesteps      | 1392640       |
| train/                  |               |
|    approx_kl            | 0.00026693026 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.6          |
|    explained_variance   | -1.87         |
|    learning_rate        | 5e-05         |
|    loss                 | -0.0804       |
|    n_updates            | 676           |
|    policy_gradient_loss | -7.13e-05     |
|    std                  | 1.2           |
|    value_loss           | 0.000103      |
-------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 1322        |
|    iterations           | 171         |
|    time_elapsed         | 1059        |
|    total_timesteps      | 1400832     |
| train/                  |             |
|    approx_kl            | 0.003141569 |
|    clip_fraction        | 0.00385     |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.6        |
|    explained_variance   | -1.76       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0781     |
|    n_updates            | 680         |
|    policy_gradient_loss | -0.000278   |
|    std                  | 1.2         |
|    value_loss           | 0.000108    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1324         |
|    iterations           | 172          |
|    time_elapsed         | 1063         |
|    total_timesteps      | 1409024      |
| train/                  |              |
|    approx_kl            | 0.0016482277 |
|    clip_fraction        | 0.000488     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.6         |
|    explained_variance   | -1.74        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0849      |
|    n_updates            | 684          |
|    policy_gradient_loss | -0.000257    |
|    std                  | 1.2          |
|    value_loss           | 0.000109     |
------------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 1327       |
|    iterations           | 173        |
|    time_elapsed         | 1067       |
|    total_timesteps      | 1417216    |
| train/                  |            |
|    approx_kl            | 0.00403993 |
|    clip_fraction        | 0.00751    |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.6       |
|    explained_variance   | -1.75      |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0787    |
|    n_updates            | 688        |
|    policy_gradient_loss | -0.000579  |
|    std                  | 1.2        |
|    value_loss           | 0.000101   |
----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1329         |
|    iterations           | 174          |
|    time_elapsed         | 1072         |
|    total_timesteps      | 1425408      |
| train/                  |              |
|    approx_kl            | 0.0008532251 |
|    clip_fraction        | 3.05e-05     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.6         |
|    explained_variance   | -2.98        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0811      |
|    n_updates            | 692          |
|    policy_gradient_loss | -0.00019     |
|    std                  | 1.2          |
|    value_loss           | 8.96e-05     |
------------------------------------------
-------------------------------------------
| time/                   |               |
|    fps                  | 1331          |
|    iterations           | 175           |
|    time_elapsed         | 1076          |
|    total_timesteps      | 1433600       |
| train/                  |               |
|    approx_kl            | 0.00019451788 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.6          |
|    explained_variance   | -3.68         |
|    learning_rate        | 5e-05         |
|    loss                 | -0.0797       |
|    n_updates            | 696           |
|    policy_gradient_loss | 0.000147      |
|    std                  | 1.2           |
|    value_loss           | 8.73e-05      |
-------------------------------------------
Eval num_timesteps=1440000, episode_reward=0.06 +/- 0.05
Episode length: 2340.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 2.34e+03   |
|    mean_reward          | 0.0575     |
| time/                   |            |
|    total_timesteps      | 1440000    |
| train/                  |            |
|    approx_kl            | 0.00328369 |
|    clip_fraction        | 0.00726    |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.6       |
|    explained_variance   | -2.48      |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0828    |
|    n_updates            | 700        |
|    policy_gradient_loss | -0.000347  |
|    std                  | 1.2        |
|    value_loss           | 9.3e-05    |
----------------------------------------
New best mean reward!
--------------------------------
| time/              |         |
|    fps             | 1307    |
|    iterations      | 176     |
|    time_elapsed    | 1102    |
|    total_timesteps | 1441792 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 1309        |
|    iterations           | 177         |
|    time_elapsed         | 1107        |
|    total_timesteps      | 1449984     |
| train/                  |             |
|    approx_kl            | 6.82861e-06 |
|    clip_fraction        | 0           |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.61       |
|    explained_variance   | -2.04       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0802     |
|    n_updates            | 704         |
|    policy_gradient_loss | 1.03e-05    |
|    std                  | 1.21        |
|    value_loss           | 9.76e-05    |
-----------------------------------------
-------------------------------------------
| time/                   |               |
|    fps                  | 1311          |
|    iterations           | 178           |
|    time_elapsed         | 1111          |
|    total_timesteps      | 1458176       |
| train/                  |               |
|    approx_kl            | 4.9011527e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.61         |
|    explained_variance   | -0.828        |
|    learning_rate        | 5e-05         |
|    loss                 | -0.0803       |
|    n_updates            | 708           |
|    policy_gradient_loss | 1.52e-05      |
|    std                  | 1.21          |
|    value_loss           | 0.000137      |
-------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1313         |
|    iterations           | 179          |
|    time_elapsed         | 1116         |
|    total_timesteps      | 1466368      |
| train/                  |              |
|    approx_kl            | 0.0038513436 |
|    clip_fraction        | 0.00632      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.61        |
|    explained_variance   | -2.4         |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0867      |
|    n_updates            | 712          |
|    policy_gradient_loss | -0.00027     |
|    std                  | 1.21         |
|    value_loss           | 8.71e-05     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 1315        |
|    iterations           | 180         |
|    time_elapsed         | 1120        |
|    total_timesteps      | 1474560     |
| train/                  |             |
|    approx_kl            | 0.001960115 |
|    clip_fraction        | 0.000946    |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.61       |
|    explained_variance   | -0.743      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0829     |
|    n_updates            | 716         |
|    policy_gradient_loss | -0.000408   |
|    std                  | 1.21        |
|    value_loss           | 0.000138    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 1317        |
|    iterations           | 181         |
|    time_elapsed         | 1125        |
|    total_timesteps      | 1482752     |
| train/                  |             |
|    approx_kl            | 0.001672663 |
|    clip_fraction        | 0.000397    |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.61       |
|    explained_variance   | -1.29       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0818     |
|    n_updates            | 720         |
|    policy_gradient_loss | -5.35e-05   |
|    std                  | 1.21        |
|    value_loss           | 0.000107    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1319         |
|    iterations           | 182          |
|    time_elapsed         | 1129         |
|    total_timesteps      | 1490944      |
| train/                  |              |
|    approx_kl            | 0.0031207032 |
|    clip_fraction        | 0.0138       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.61        |
|    explained_variance   | -1.66        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0834      |
|    n_updates            | 724          |
|    policy_gradient_loss | -0.000892    |
|    std                  | 1.21         |
|    value_loss           | 9.58e-05     |
------------------------------------------
-------------------------------------------
| time/                   |               |
|    fps                  | 1321          |
|    iterations           | 183           |
|    time_elapsed         | 1134          |
|    total_timesteps      | 1499136       |
| train/                  |               |
|    approx_kl            | 0.00022818128 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.61         |
|    explained_variance   | -1.87         |
|    learning_rate        | 5e-05         |
|    loss                 | -0.0807       |
|    n_updates            | 728           |
|    policy_gradient_loss | -4.21e-05     |
|    std                  | 1.21          |
|    value_loss           | 8.93e-05      |
-------------------------------------------
--------------------------------------------
| time/                   |                |
|    fps                  | 1323           |
|    iterations           | 184            |
|    time_elapsed         | 1138           |
|    total_timesteps      | 1507328        |
| train/                  |                |
|    approx_kl            | 0.000120862926 |
|    clip_fraction        | 0              |
|    clip_range           | 0.2            |
|    entropy_loss         | -1.61          |
|    explained_variance   | -1.89          |
|    learning_rate        | 5e-05          |
|    loss                 | -0.0807        |
|    n_updates            | 732            |
|    policy_gradient_loss | 3.87e-05       |
|    std                  | 1.21           |
|    value_loss           | 8.45e-05       |
--------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1325         |
|    iterations           | 185          |
|    time_elapsed         | 1143         |
|    total_timesteps      | 1515520      |
| train/                  |              |
|    approx_kl            | 0.0019515613 |
|    clip_fraction        | 0.000824     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.61        |
|    explained_variance   | -3.07        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0837      |
|    n_updates            | 736          |
|    policy_gradient_loss | -0.000287    |
|    std                  | 1.22         |
|    value_loss           | 7.22e-05     |
------------------------------------------
Eval num_timesteps=1520000, episode_reward=0.02 +/- 0.06
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | 0.0162       |
| time/                   |              |
|    total_timesteps      | 1520000      |
| train/                  |              |
|    approx_kl            | 0.0007800148 |
|    clip_fraction        | 0.000153     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.62        |
|    explained_variance   | -1.44        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0815      |
|    n_updates            | 740          |
|    policy_gradient_loss | 0.000133     |
|    std                  | 1.22         |
|    value_loss           | 0.000104     |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 1300    |
|    iterations      | 186     |
|    time_elapsed    | 1171    |
|    total_timesteps | 1523712 |
--------------------------------
-------------------------------------------
| time/                   |               |
|    fps                  | 1302          |
|    iterations           | 187           |
|    time_elapsed         | 1175          |
|    total_timesteps      | 1531904       |
| train/                  |               |
|    approx_kl            | 0.00031782244 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.62         |
|    explained_variance   | -2.19         |
|    learning_rate        | 5e-05         |
|    loss                 | -0.0793       |
|    n_updates            | 744           |
|    policy_gradient_loss | -6.41e-05     |
|    std                  | 1.22          |
|    value_loss           | 7.76e-05      |
-------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 1304        |
|    iterations           | 188         |
|    time_elapsed         | 1180        |
|    total_timesteps      | 1540096     |
| train/                  |             |
|    approx_kl            | 0.000810539 |
|    clip_fraction        | 0           |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.62       |
|    explained_variance   | -1.6        |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0823     |
|    n_updates            | 748         |
|    policy_gradient_loss | -0.000147   |
|    std                  | 1.22        |
|    value_loss           | 8.83e-05    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1306         |
|    iterations           | 189          |
|    time_elapsed         | 1184         |
|    total_timesteps      | 1548288      |
| train/                  |              |
|    approx_kl            | 0.0003239108 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.62        |
|    explained_variance   | -1.82        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0815      |
|    n_updates            | 752          |
|    policy_gradient_loss | -1.64e-05    |
|    std                  | 1.22         |
|    value_loss           | 8.44e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1309         |
|    iterations           | 190          |
|    time_elapsed         | 1188         |
|    total_timesteps      | 1556480      |
| train/                  |              |
|    approx_kl            | 6.741442e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.62        |
|    explained_variance   | -1.21        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0807      |
|    n_updates            | 756          |
|    policy_gradient_loss | 1.76e-05     |
|    std                  | 1.22         |
|    value_loss           | 9.77e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1311         |
|    iterations           | 191          |
|    time_elapsed         | 1192         |
|    total_timesteps      | 1564672      |
| train/                  |              |
|    approx_kl            | 0.0038837339 |
|    clip_fraction        | 0.00671      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.62        |
|    explained_variance   | -1.68        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0789      |
|    n_updates            | 760          |
|    policy_gradient_loss | -0.000496    |
|    std                  | 1.23         |
|    value_loss           | 8.25e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1314         |
|    iterations           | 192          |
|    time_elapsed         | 1196         |
|    total_timesteps      | 1572864      |
| train/                  |              |
|    approx_kl            | 0.0008522128 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.62        |
|    explained_variance   | -1.55        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0809      |
|    n_updates            | 764          |
|    policy_gradient_loss | 3.09e-05     |
|    std                  | 1.23         |
|    value_loss           | 7.96e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1316         |
|    iterations           | 193          |
|    time_elapsed         | 1200         |
|    total_timesteps      | 1581056      |
| train/                  |              |
|    approx_kl            | 0.0011368596 |
|    clip_fraction        | 6.1e-05      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.62        |
|    explained_variance   | -1.96        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0819      |
|    n_updates            | 768          |
|    policy_gradient_loss | -0.000155    |
|    std                  | 1.23         |
|    value_loss           | 8.12e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1318         |
|    iterations           | 194          |
|    time_elapsed         | 1204         |
|    total_timesteps      | 1589248      |
| train/                  |              |
|    approx_kl            | 0.0003614932 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.63        |
|    explained_variance   | -1.84        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0818      |
|    n_updates            | 772          |
|    policy_gradient_loss | -7.87e-05    |
|    std                  | 1.23         |
|    value_loss           | 7.88e-05     |
------------------------------------------
-------------------------------------------
| time/                   |               |
|    fps                  | 1321          |
|    iterations           | 195           |
|    time_elapsed         | 1208          |
|    total_timesteps      | 1597440       |
| train/                  |               |
|    approx_kl            | 0.00013132166 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.63         |
|    explained_variance   | -2.62         |
|    learning_rate        | 5e-05         |
|    loss                 | -0.0813       |
|    n_updates            | 776           |
|    policy_gradient_loss | 0.000119      |
|    std                  | 1.23          |
|    value_loss           | 7.34e-05      |
-------------------------------------------
Eval num_timesteps=1600000, episode_reward=-0.05 +/- 0.09
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | -0.049       |
| time/                   |              |
|    total_timesteps      | 1600000      |
| train/                  |              |
|    approx_kl            | 0.0036093413 |
|    clip_fraction        | 0.0104       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.63        |
|    explained_variance   | -3.25        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0808      |
|    n_updates            | 780          |
|    policy_gradient_loss | -0.000731    |
|    std                  | 1.23         |
|    value_loss           | 6.77e-05     |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 1300    |
|    iterations      | 196     |
|    time_elapsed    | 1234    |
|    total_timesteps | 1605632 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 1302      |
|    iterations           | 197       |
|    time_elapsed         | 1238      |
|    total_timesteps      | 1613824   |
| train/                  |           |
|    approx_kl            | 0.0035087 |
|    clip_fraction        | 0.00558   |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.63     |
|    explained_variance   | -3.17     |
|    learning_rate        | 5e-05     |
|    loss                 | -0.0859   |
|    n_updates            | 784       |
|    policy_gradient_loss | -0.000466 |
|    std                  | 1.24      |
|    value_loss           | 6.47e-05  |
---------------------------------------
-------------------------------------------
| time/                   |               |
|    fps                  | 1305          |
|    iterations           | 198           |
|    time_elapsed         | 1242          |
|    total_timesteps      | 1622016       |
| train/                  |               |
|    approx_kl            | 4.0313957e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.63         |
|    explained_variance   | -1.98         |
|    learning_rate        | 5e-05         |
|    loss                 | -0.0817       |
|    n_updates            | 788           |
|    policy_gradient_loss | 8.31e-06      |
|    std                  | 1.24          |
|    value_loss           | 7.51e-05      |
-------------------------------------------
-------------------------------------------
| time/                   |               |
|    fps                  | 1307          |
|    iterations           | 199           |
|    time_elapsed         | 1246          |
|    total_timesteps      | 1630208       |
| train/                  |               |
|    approx_kl            | 2.4423069e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.63         |
|    explained_variance   | -1.06         |
|    learning_rate        | 5e-05         |
|    loss                 | -0.0819       |
|    n_updates            | 792           |
|    policy_gradient_loss | 3.75e-05      |
|    std                  | 1.24          |
|    value_loss           | 9.34e-05      |
-------------------------------------------
-------------------------------------------
| time/                   |               |
|    fps                  | 1309          |
|    iterations           | 200           |
|    time_elapsed         | 1250          |
|    total_timesteps      | 1638400       |
| train/                  |               |
|    approx_kl            | 8.1011785e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.63         |
|    explained_variance   | -1.76         |
|    learning_rate        | 5e-05         |
|    loss                 | -0.0818       |
|    n_updates            | 796           |
|    policy_gradient_loss | 2.9e-05       |
|    std                  | 1.24          |
|    value_loss           | 7.31e-05      |
-------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1312         |
|    iterations           | 201          |
|    time_elapsed         | 1254         |
|    total_timesteps      | 1646592      |
| train/                  |              |
|    approx_kl            | 0.0041701323 |
|    clip_fraction        | 0.0203       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.63        |
|    explained_variance   | -2.17        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0829      |
|    n_updates            | 800          |
|    policy_gradient_loss | -0.00119     |
|    std                  | 1.24         |
|    value_loss           | 6.63e-05     |
------------------------------------------
-------------------------------------------
| time/                   |               |
|    fps                  | 1314          |
|    iterations           | 202           |
|    time_elapsed         | 1258          |
|    total_timesteps      | 1654784       |
| train/                  |               |
|    approx_kl            | 0.00017124499 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.64         |
|    explained_variance   | -2.09         |
|    learning_rate        | 5e-05         |
|    loss                 | -0.0818       |
|    n_updates            | 804           |
|    policy_gradient_loss | -0.000134     |
|    std                  | 1.24          |
|    value_loss           | 7.56e-05      |
-------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1316         |
|    iterations           | 203          |
|    time_elapsed         | 1263         |
|    total_timesteps      | 1662976      |
| train/                  |              |
|    approx_kl            | 5.859096e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.64        |
|    explained_variance   | -1.05        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0812      |
|    n_updates            | 808          |
|    policy_gradient_loss | 5.04e-05     |
|    std                  | 1.24         |
|    value_loss           | 8.95e-05     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 1318        |
|    iterations           | 204         |
|    time_elapsed         | 1267        |
|    total_timesteps      | 1671168     |
| train/                  |             |
|    approx_kl            | 0.002448148 |
|    clip_fraction        | 0.00223     |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.64       |
|    explained_variance   | -1.39       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0834     |
|    n_updates            | 812         |
|    policy_gradient_loss | -0.000261   |
|    std                  | 1.25        |
|    value_loss           | 7.6e-05     |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1321         |
|    iterations           | 205          |
|    time_elapsed         | 1271         |
|    total_timesteps      | 1679360      |
| train/                  |              |
|    approx_kl            | 0.0002961564 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.64        |
|    explained_variance   | -0.831       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0819      |
|    n_updates            | 816          |
|    policy_gradient_loss | -3.82e-06    |
|    std                  | 1.25         |
|    value_loss           | 9.79e-05     |
------------------------------------------
Eval num_timesteps=1680000, episode_reward=-0.01 +/- 0.08
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | -0.0118      |
| time/                   |              |
|    total_timesteps      | 1680000      |
| train/                  |              |
|    approx_kl            | 0.0034843632 |
|    clip_fraction        | 0.0141       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.64        |
|    explained_variance   | -0.675       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0825      |
|    n_updates            | 820          |
|    policy_gradient_loss | -0.000619    |
|    std                  | 1.25         |
|    value_loss           | 0.000109     |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 1300    |
|    iterations      | 206     |
|    time_elapsed    | 1297    |
|    total_timesteps | 1687552 |
--------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1303         |
|    iterations           | 207          |
|    time_elapsed         | 1300         |
|    total_timesteps      | 1695744      |
| train/                  |              |
|    approx_kl            | 0.0039301384 |
|    clip_fraction        | 0.0164       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.64        |
|    explained_variance   | -1.01        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0785      |
|    n_updates            | 824          |
|    policy_gradient_loss | -0.000782    |
|    std                  | 1.25         |
|    value_loss           | 8.51e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1306         |
|    iterations           | 208          |
|    time_elapsed         | 1304         |
|    total_timesteps      | 1703936      |
| train/                  |              |
|    approx_kl            | 0.0018029447 |
|    clip_fraction        | 0.000702     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.64        |
|    explained_variance   | -1.85        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0834      |
|    n_updates            | 828          |
|    policy_gradient_loss | -0.000158    |
|    std                  | 1.25         |
|    value_loss           | 6.96e-05     |
------------------------------------------
-------------------------------------------
| time/                   |               |
|    fps                  | 1309          |
|    iterations           | 209           |
|    time_elapsed         | 1307          |
|    total_timesteps      | 1712128       |
| train/                  |               |
|    approx_kl            | 0.00035733447 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.64         |
|    explained_variance   | -1.4          |
|    learning_rate        | 5e-05         |
|    loss                 | -0.0821       |
|    n_updates            | 832           |
|    policy_gradient_loss | -3.35e-05     |
|    std                  | 1.25          |
|    value_loss           | 8.08e-05      |
-------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1312         |
|    iterations           | 210          |
|    time_elapsed         | 1310         |
|    total_timesteps      | 1720320      |
| train/                  |              |
|    approx_kl            | 0.0009706105 |
|    clip_fraction        | 6.1e-05      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.64        |
|    explained_variance   | -2.23        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0832      |
|    n_updates            | 836          |
|    policy_gradient_loss | -7.01e-05    |
|    std                  | 1.25         |
|    value_loss           | 6.01e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1315         |
|    iterations           | 211          |
|    time_elapsed         | 1313         |
|    total_timesteps      | 1728512      |
| train/                  |              |
|    approx_kl            | 0.0021797912 |
|    clip_fraction        | 0.00195      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.65        |
|    explained_variance   | -1.52        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.083       |
|    n_updates            | 840          |
|    policy_gradient_loss | -0.000363    |
|    std                  | 1.26         |
|    value_loss           | 7.01e-05     |
------------------------------------------
-------------------------------------------
| time/                   |               |
|    fps                  | 1318          |
|    iterations           | 212           |
|    time_elapsed         | 1317          |
|    total_timesteps      | 1736704       |
| train/                  |               |
|    approx_kl            | 0.00056807755 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.65         |
|    explained_variance   | -0.804        |
|    learning_rate        | 5e-05         |
|    loss                 | -0.0836       |
|    n_updates            | 844           |
|    policy_gradient_loss | -3.8e-05      |
|    std                  | 1.26          |
|    value_loss           | 9.46e-05      |
-------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1321         |
|    iterations           | 213          |
|    time_elapsed         | 1320         |
|    total_timesteps      | 1744896      |
| train/                  |              |
|    approx_kl            | 0.0033695654 |
|    clip_fraction        | 0.00522      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.65        |
|    explained_variance   | -1.09        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0833      |
|    n_updates            | 848          |
|    policy_gradient_loss | -0.000403    |
|    std                  | 1.26         |
|    value_loss           | 8.59e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1324         |
|    iterations           | 214          |
|    time_elapsed         | 1323         |
|    total_timesteps      | 1753088      |
| train/                  |              |
|    approx_kl            | 8.592226e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.65        |
|    explained_variance   | -1.67        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0813      |
|    n_updates            | 852          |
|    policy_gradient_loss | 3.22e-05     |
|    std                  | 1.26         |
|    value_loss           | 6.78e-05     |
------------------------------------------
Eval num_timesteps=1760000, episode_reward=0.01 +/- 0.09
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | 0.0138       |
| time/                   |              |
|    total_timesteps      | 1760000      |
| train/                  |              |
|    approx_kl            | 0.0014065797 |
|    clip_fraction        | 0.000336     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.65        |
|    explained_variance   | -1.83        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0834      |
|    n_updates            | 856          |
|    policy_gradient_loss | -9.29e-05    |
|    std                  | 1.26         |
|    value_loss           | 6.06e-05     |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 1303    |
|    iterations      | 215     |
|    time_elapsed    | 1350    |
|    total_timesteps | 1761280 |
--------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1305         |
|    iterations           | 216          |
|    time_elapsed         | 1355         |
|    total_timesteps      | 1769472      |
| train/                  |              |
|    approx_kl            | 0.0019056046 |
|    clip_fraction        | 0.00104      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.65        |
|    explained_variance   | -1.14        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0854      |
|    n_updates            | 860          |
|    policy_gradient_loss | -0.000287    |
|    std                  | 1.26         |
|    value_loss           | 7.77e-05     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 1307        |
|    iterations           | 217         |
|    time_elapsed         | 1359        |
|    total_timesteps      | 1777664     |
| train/                  |             |
|    approx_kl            | 0.004403499 |
|    clip_fraction        | 0.0139      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.65       |
|    explained_variance   | -0.96       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0876     |
|    n_updates            | 864         |
|    policy_gradient_loss | -0.000736   |
|    std                  | 1.26        |
|    value_loss           | 7.85e-05    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1309         |
|    iterations           | 218          |
|    time_elapsed         | 1363         |
|    total_timesteps      | 1785856      |
| train/                  |              |
|    approx_kl            | 0.0035619256 |
|    clip_fraction        | 0.0146       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.65        |
|    explained_variance   | -1.29        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0832      |
|    n_updates            | 868          |
|    policy_gradient_loss | -0.000961    |
|    std                  | 1.27         |
|    value_loss           | 6.88e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1311         |
|    iterations           | 219          |
|    time_elapsed         | 1368         |
|    total_timesteps      | 1794048      |
| train/                  |              |
|    approx_kl            | 0.0042184703 |
|    clip_fraction        | 0.0223       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.65        |
|    explained_variance   | -0.802       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0831      |
|    n_updates            | 872          |
|    policy_gradient_loss | -0.00158     |
|    std                  | 1.27         |
|    value_loss           | 0.000103     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1312         |
|    iterations           | 220          |
|    time_elapsed         | 1372         |
|    total_timesteps      | 1802240      |
| train/                  |              |
|    approx_kl            | 0.0049700863 |
|    clip_fraction        | 0.0145       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.66        |
|    explained_variance   | -1.43        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0766      |
|    n_updates            | 876          |
|    policy_gradient_loss | -0.000925    |
|    std                  | 1.27         |
|    value_loss           | 7.11e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1314         |
|    iterations           | 221          |
|    time_elapsed         | 1377         |
|    total_timesteps      | 1810432      |
| train/                  |              |
|    approx_kl            | 0.0011265446 |
|    clip_fraction        | 0.000122     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.66        |
|    explained_variance   | -1.28        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0845      |
|    n_updates            | 880          |
|    policy_gradient_loss | -3.84e-05    |
|    std                  | 1.27         |
|    value_loss           | 6.94e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1316         |
|    iterations           | 222          |
|    time_elapsed         | 1381         |
|    total_timesteps      | 1818624      |
| train/                  |              |
|    approx_kl            | 0.0032219724 |
|    clip_fraction        | 0.0138       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.66        |
|    explained_variance   | -1.42        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0849      |
|    n_updates            | 884          |
|    policy_gradient_loss | -0.00103     |
|    std                  | 1.27         |
|    value_loss           | 6.27e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1318         |
|    iterations           | 223          |
|    time_elapsed         | 1385         |
|    total_timesteps      | 1826816      |
| train/                  |              |
|    approx_kl            | 0.0027498119 |
|    clip_fraction        | 0.00482      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.66        |
|    explained_variance   | -1.85        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0832      |
|    n_updates            | 888          |
|    policy_gradient_loss | -0.00023     |
|    std                  | 1.27         |
|    value_loss           | 5.95e-05     |
------------------------------------------
-------------------------------------------
| time/                   |               |
|    fps                  | 1319          |
|    iterations           | 224           |
|    time_elapsed         | 1390          |
|    total_timesteps      | 1835008       |
| train/                  |               |
|    approx_kl            | 0.00048045735 |
|    clip_fraction        | 6.1e-05       |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.66         |
|    explained_variance   | -1.26         |
|    learning_rate        | 5e-05         |
|    loss                 | -0.0804       |
|    n_updates            | 892           |
|    policy_gradient_loss | -4.39e-05     |
|    std                  | 1.27          |
|    value_loss           | 6.4e-05       |
-------------------------------------------
Eval num_timesteps=1840000, episode_reward=0.02 +/- 0.06
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | 0.0247       |
| time/                   |              |
|    total_timesteps      | 1840000      |
| train/                  |              |
|    approx_kl            | 0.0031232992 |
|    clip_fraction        | 0.00882      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.66        |
|    explained_variance   | -2.01        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0831      |
|    n_updates            | 896          |
|    policy_gradient_loss | -0.000763    |
|    std                  | 1.27         |
|    value_loss           | 5.6e-05      |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 1299    |
|    iterations      | 225     |
|    time_elapsed    | 1418    |
|    total_timesteps | 1843200 |
--------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1300         |
|    iterations           | 226          |
|    time_elapsed         | 1423         |
|    total_timesteps      | 1851392      |
| train/                  |              |
|    approx_kl            | 0.0038136854 |
|    clip_fraction        | 0.0236       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.66        |
|    explained_variance   | -1.47        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0813      |
|    n_updates            | 900          |
|    policy_gradient_loss | -0.00172     |
|    std                  | 1.27         |
|    value_loss           | 6.21e-05     |
------------------------------------------
-------------------------------------------
| time/                   |               |
|    fps                  | 1301          |
|    iterations           | 227           |
|    time_elapsed         | 1429          |
|    total_timesteps      | 1859584       |
| train/                  |               |
|    approx_kl            | 0.00037013873 |
|    clip_fraction        | 3.05e-05      |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.66         |
|    explained_variance   | -1.43         |
|    learning_rate        | 5e-05         |
|    loss                 | -0.0837       |
|    n_updates            | 904           |
|    policy_gradient_loss | -0.000138     |
|    std                  | 1.28          |
|    value_loss           | 6.04e-05      |
-------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1301         |
|    iterations           | 228          |
|    time_elapsed         | 1434         |
|    total_timesteps      | 1867776      |
| train/                  |              |
|    approx_kl            | 0.0017546677 |
|    clip_fraction        | 0.00119      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.66        |
|    explained_variance   | -1.8         |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0825      |
|    n_updates            | 908          |
|    policy_gradient_loss | -4.23e-05    |
|    std                  | 1.28         |
|    value_loss           | 5.51e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1302         |
|    iterations           | 229          |
|    time_elapsed         | 1439         |
|    total_timesteps      | 1875968      |
| train/                  |              |
|    approx_kl            | 0.0028262464 |
|    clip_fraction        | 0.0162       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.66        |
|    explained_variance   | -1.03        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.086       |
|    n_updates            | 912          |
|    policy_gradient_loss | -0.000888    |
|    std                  | 1.28         |
|    value_loss           | 6.49e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1304         |
|    iterations           | 230          |
|    time_elapsed         | 1444         |
|    total_timesteps      | 1884160      |
| train/                  |              |
|    approx_kl            | 0.0006555582 |
|    clip_fraction        | 0.000122     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.66        |
|    explained_variance   | -1.49        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0826      |
|    n_updates            | 916          |
|    policy_gradient_loss | -6.85e-05    |
|    std                  | 1.28         |
|    value_loss           | 5.68e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1306         |
|    iterations           | 231          |
|    time_elapsed         | 1448         |
|    total_timesteps      | 1892352      |
| train/                  |              |
|    approx_kl            | 0.0025098475 |
|    clip_fraction        | 0.0032       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.67        |
|    explained_variance   | -0.902       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0867      |
|    n_updates            | 920          |
|    policy_gradient_loss | -0.000376    |
|    std                  | 1.28         |
|    value_loss           | 6.61e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1307         |
|    iterations           | 232          |
|    time_elapsed         | 1453         |
|    total_timesteps      | 1900544      |
| train/                  |              |
|    approx_kl            | 0.0041000494 |
|    clip_fraction        | 0.00851      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.67        |
|    explained_variance   | -0.845       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0834      |
|    n_updates            | 924          |
|    policy_gradient_loss | -0.000221    |
|    std                  | 1.28         |
|    value_loss           | 7.35e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1309         |
|    iterations           | 233          |
|    time_elapsed         | 1457         |
|    total_timesteps      | 1908736      |
| train/                  |              |
|    approx_kl            | 0.0015428088 |
|    clip_fraction        | 0.0106       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.67        |
|    explained_variance   | -1.46        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0849      |
|    n_updates            | 928          |
|    policy_gradient_loss | -0.000863    |
|    std                  | 1.28         |
|    value_loss           | 5.91e-05     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 1311        |
|    iterations           | 234         |
|    time_elapsed         | 1461        |
|    total_timesteps      | 1916928     |
| train/                  |             |
|    approx_kl            | 0.002901431 |
|    clip_fraction        | 0.0062      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.67       |
|    explained_variance   | -1.97       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0823     |
|    n_updates            | 932         |
|    policy_gradient_loss | -0.000289   |
|    std                  | 1.28        |
|    value_loss           | 4.98e-05    |
-----------------------------------------
Eval num_timesteps=1920000, episode_reward=-0.02 +/- 0.06
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | -0.022       |
| time/                   |              |
|    total_timesteps      | 1920000      |
| train/                  |              |
|    approx_kl            | 0.0030133289 |
|    clip_fraction        | 0.00562      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.67        |
|    explained_variance   | -1.65        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0861      |
|    n_updates            | 936          |
|    policy_gradient_loss | -0.000393    |
|    std                  | 1.29         |
|    value_loss           | 5.52e-05     |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 1292    |
|    iterations      | 235     |
|    time_elapsed    | 1489    |
|    total_timesteps | 1925120 |
--------------------------------
--------------------------------------------
| time/                   |                |
|    fps                  | 1293           |
|    iterations           | 236            |
|    time_elapsed         | 1494           |
|    total_timesteps      | 1933312        |
| train/                  |                |
|    approx_kl            | 0.000117387295 |
|    clip_fraction        | 0              |
|    clip_range           | 0.2            |
|    entropy_loss         | -1.67          |
|    explained_variance   | -0.883         |
|    learning_rate        | 5e-05          |
|    loss                 | -0.0838        |
|    n_updates            | 940            |
|    policy_gradient_loss | 3.54e-05       |
|    std                  | 1.29           |
|    value_loss           | 6.98e-05       |
--------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1294         |
|    iterations           | 237          |
|    time_elapsed         | 1499         |
|    total_timesteps      | 1941504      |
| train/                  |              |
|    approx_kl            | 0.0039058386 |
|    clip_fraction        | 0.019        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.67        |
|    explained_variance   | -1.1         |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0807      |
|    n_updates            | 944          |
|    policy_gradient_loss | -0.000891    |
|    std                  | 1.29         |
|    value_loss           | 5.94e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1295         |
|    iterations           | 238          |
|    time_elapsed         | 1504         |
|    total_timesteps      | 1949696      |
| train/                  |              |
|    approx_kl            | 0.0020549868 |
|    clip_fraction        | 0.00125      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.67        |
|    explained_variance   | -0.845       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0859      |
|    n_updates            | 948          |
|    policy_gradient_loss | -0.000223    |
|    std                  | 1.29         |
|    value_loss           | 7.13e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1296         |
|    iterations           | 239          |
|    time_elapsed         | 1509         |
|    total_timesteps      | 1957888      |
| train/                  |              |
|    approx_kl            | 0.0032644467 |
|    clip_fraction        | 0.00482      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.67        |
|    explained_variance   | -0.686       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0835      |
|    n_updates            | 952          |
|    policy_gradient_loss | -0.000335    |
|    std                  | 1.29         |
|    value_loss           | 7.95e-05     |
------------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 1297       |
|    iterations           | 240        |
|    time_elapsed         | 1514       |
|    total_timesteps      | 1966080    |
| train/                  |            |
|    approx_kl            | 0.00250638 |
|    clip_fraction        | 0.00223    |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.68      |
|    explained_variance   | -0.995     |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0849    |
|    n_updates            | 956        |
|    policy_gradient_loss | -0.000125  |
|    std                  | 1.29       |
|    value_loss           | 6.41e-05   |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 1298       |
|    iterations           | 241        |
|    time_elapsed         | 1519       |
|    total_timesteps      | 1974272    |
| train/                  |            |
|    approx_kl            | 0.00358684 |
|    clip_fraction        | 0.00751    |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.68      |
|    explained_variance   | -1.4       |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0838    |
|    n_updates            | 960        |
|    policy_gradient_loss | -0.000507  |
|    std                  | 1.29       |
|    value_loss           | 5.07e-05   |
----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1300         |
|    iterations           | 242          |
|    time_elapsed         | 1524         |
|    total_timesteps      | 1982464      |
| train/                  |              |
|    approx_kl            | 0.0003832518 |
|    clip_fraction        | 3.05e-05     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.68        |
|    explained_variance   | -0.655       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0842      |
|    n_updates            | 964          |
|    policy_gradient_loss | 9.14e-05     |
|    std                  | 1.3          |
|    value_loss           | 7.5e-05      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1301         |
|    iterations           | 243          |
|    time_elapsed         | 1529         |
|    total_timesteps      | 1990656      |
| train/                  |              |
|    approx_kl            | 0.0016688879 |
|    clip_fraction        | 0.000946     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.68        |
|    explained_variance   | -1.27        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0852      |
|    n_updates            | 968          |
|    policy_gradient_loss | -0.000115    |
|    std                  | 1.3          |
|    value_loss           | 5.41e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1302         |
|    iterations           | 244          |
|    time_elapsed         | 1535         |
|    total_timesteps      | 1998848      |
| train/                  |              |
|    approx_kl            | 0.0033468413 |
|    clip_fraction        | 0.00488      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.68        |
|    explained_variance   | -1.19        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0847      |
|    n_updates            | 972          |
|    policy_gradient_loss | -0.000536    |
|    std                  | 1.3          |
|    value_loss           | 5.39e-05     |
------------------------------------------
Eval num_timesteps=2000000, episode_reward=0.00 +/- 0.06
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | 0.0039       |
| time/                   |              |
|    total_timesteps      | 2000000      |
| train/                  |              |
|    approx_kl            | 0.0037577013 |
|    clip_fraction        | 0.00909      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.68        |
|    explained_variance   | -0.981       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0816      |
|    n_updates            | 976          |
|    policy_gradient_loss | -0.000528    |
|    std                  | 1.3          |
|    value_loss           | 6.1e-05      |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 1283    |
|    iterations      | 245     |
|    time_elapsed    | 1563    |
|    total_timesteps | 2007040 |
--------------------------------
Loading datasets...
[Dataset_Finance_MultiAsset] Global date splits: train_end=2024-07-26 14:20:00+00:00 val_end=2025-04-25 15:45:00+00:00 n_dates=96878 n_train=67814 n_val=14533 n_test=14531
[Dataset_Finance_MultiAsset] Global date splits: train_end=2024-07-26 14:20:00+00:00 val_end=2025-04-25 15:45:00+00:00 n_dates=96878 n_train=67814 n_val=14533 n_test=14531
Building environments...
Loading JEPA encoder...
/root/DrlPpoTransformer/.venv/lib/python3.11/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(
Loading JEPA weights from checkpoints/jepa_initial/best.pt
/root/DrlPpoTransformer/train_PPO_initial.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(checkpoint_path, map_location="cpu")
Using cuda device
Logging to logs/PPO_8
/root/DrlPpoTransformer/.venv/lib/python3.11/site-packages/stable_baselines3/common/callbacks.py:418: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.subproc_vec_env.SubprocVecEnv object at 0x76d24d6c7310> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x76d2567b3050>
  warnings.warn("Training and eval env are not of the same type" f"{self.training_env} != {self.eval_env}")
-----------------------------
| time/              |      |
|    fps             | 3046 |
|    iterations      | 1    |
|    time_elapsed    | 2    |
|    total_timesteps | 8192 |
-----------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 2192        |
|    iterations           | 2           |
|    time_elapsed         | 7           |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.002561255 |
|    clip_fraction        | 0.00145     |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.42       |
|    explained_variance   | -6.39       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0183     |
|    n_updates            | 8           |
|    policy_gradient_loss | -0.0005     |
|    std                  | 1           |
|    value_loss           | 0.0426      |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 2031         |
|    iterations           | 3            |
|    time_elapsed         | 12           |
|    total_timesteps      | 24576        |
| train/                  |              |
|    approx_kl            | 0.0012607682 |
|    clip_fraction        | 6.1e-05      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.42        |
|    explained_variance   | -4.4         |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0231      |
|    n_updates            | 16           |
|    policy_gradient_loss | -0.000172    |
|    std                  | 1            |
|    value_loss           | 0.0172       |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1918         |
|    iterations           | 4            |
|    time_elapsed         | 17           |
|    total_timesteps      | 32768        |
| train/                  |              |
|    approx_kl            | 0.0022076913 |
|    clip_fraction        | 0.00121      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.42        |
|    explained_variance   | -5.87        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0232      |
|    n_updates            | 24           |
|    policy_gradient_loss | -0.00032     |
|    std                  | 1            |
|    value_loss           | 0.0106       |
------------------------------------------
/root/DrlPpoTransformer/.venv/lib/python3.11/site-packages/stable_baselines3/common/evaluation.py:70: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.
  warnings.warn(
Eval num_timesteps=40000, episode_reward=-0.03 +/- 0.04
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | -0.0256      |
| time/                   |              |
|    total_timesteps      | 40000        |
| train/                  |              |
|    approx_kl            | 0.0027902636 |
|    clip_fraction        | 0.00305      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.42        |
|    explained_variance   | -5.65        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0272      |
|    n_updates            | 32           |
|    policy_gradient_loss | -0.000386    |
|    std                  | 1.01         |
|    value_loss           | 0.00729      |
------------------------------------------
New best mean reward!
------------------------------
| time/              |       |
|    fps             | 887   |
|    iterations      | 5     |
|    time_elapsed    | 46    |
|    total_timesteps | 40960 |
------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 946          |
|    iterations           | 6            |
|    time_elapsed         | 51           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 0.0024066088 |
|    clip_fraction        | 0.00749      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.43        |
|    explained_variance   | -5.44        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0255      |
|    n_updates            | 40           |
|    policy_gradient_loss | -0.000758    |
|    std                  | 1.01         |
|    value_loss           | 0.00549      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1004         |
|    iterations           | 7            |
|    time_elapsed         | 57           |
|    total_timesteps      | 57344        |
| train/                  |              |
|    approx_kl            | 0.0019362235 |
|    clip_fraction        | 0.00282      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.43        |
|    explained_variance   | -8.51        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0266      |
|    n_updates            | 48           |
|    policy_gradient_loss | -0.000468    |
|    std                  | 1.01         |
|    value_loss           | 0.00461      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1059         |
|    iterations           | 8            |
|    time_elapsed         | 61           |
|    total_timesteps      | 65536        |
| train/                  |              |
|    approx_kl            | 0.0022146637 |
|    clip_fraction        | 0.00102      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.43        |
|    explained_variance   | -9.13        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0288      |
|    n_updates            | 56           |
|    policy_gradient_loss | -0.00041     |
|    std                  | 1.01         |
|    value_loss           | 0.00395      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 1107         |
|    iterations           | 9            |
|    time_elapsed         | 66           |
|    total_timesteps      | 73728        |
| train/                  |              |
|    approx_kl            | 0.0019268866 |
|    clip_fraction        | 0.00204      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.43        |
|    explained_variance   | -10.9        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0279      |
|    n_updates            | 64           |
|    policy_gradient_loss | -0.0005      |
|    std                  | 1.01         |
|    value_loss           | 0.00319      |
------------------------------------------
/root/DrlPpoTransformer/.venv/lib/python3.11/site-packages/stable_baselines3/common/evaluation.py:70: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.
  warnings.warn(
Eval num_timesteps=80000, episode_reward=-0.05 +/- 0.03
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.046      |
| time/                   |             |
|    total_timesteps      | 80000       |
| train/                  |             |
|    approx_kl            | 7.39159e-05 |
|    clip_fraction        | 0           |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.43       |
|    explained_variance   | -12.9       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0278     |
|    n_updates            | 72          |
|    policy_gradient_loss | -3.82e-05   |
|    std                  | 1.01        |
|    value_loss           | 0.00281     |
-----------------------------------------
------------------------------
| time/              |       |
|    fps             | 872   |
|    iterations      | 10    |
|    time_elapsed    | 93    |
|    total_timesteps | 81920 |
------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 905          |
|    iterations           | 11           |
|    time_elapsed         | 99           |
|    total_timesteps      | 90112        |
| train/                  |              |
|    approx_kl            | 0.0023998073 |
|    clip_fraction        | 0.00876      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.43        |
|    explained_variance   | -16.8        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.028       |
|    n_updates            | 80           |
|    policy_gradient_loss | -0.0012      |
|    std                  | 1.01         |
|    value_loss           | 0.00252      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 934          |
|    iterations           | 12           |
|    time_elapsed         | 105          |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 0.0021617457 |
|    clip_fraction        | 0.00575      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.43        |
|    explained_variance   | -13.2        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0283      |
|    n_updates            | 88           |
|    policy_gradient_loss | -0.000742    |
|    std                  | 1.01         |
|    value_loss           | 0.00217      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 960          |
|    iterations           | 13           |
|    time_elapsed         | 110          |
|    total_timesteps      | 106496       |
| train/                  |              |
|    approx_kl            | 0.0024965657 |
|    clip_fraction        | 0.00494      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.43        |
|    explained_variance   | -9.37        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0296      |
|    n_updates            | 96           |
|    policy_gradient_loss | -0.000428    |
|    std                  | 1.02         |
|    value_loss           | 0.00196      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 983          |
|    iterations           | 14           |
|    time_elapsed         | 116          |
|    total_timesteps      | 114688       |
| train/                  |              |
|    approx_kl            | 0.0011349313 |
|    clip_fraction        | 0.00633      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.44        |
|    explained_variance   | -10.9        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.028       |
|    n_updates            | 104          |
|    policy_gradient_loss | -0.000702    |
|    std                  | 1.02         |
|    value_loss           | 0.00183      |
------------------------------------------
Eval num_timesteps=120000, episode_reward=-0.10 +/- 0.02
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | -0.102       |
| time/                   |              |
|    total_timesteps      | 120000       |
| train/                  |              |
|    approx_kl            | 0.0014243382 |
|    clip_fraction        | 0.000839     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.43        |
|    explained_variance   | -12.2        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0294      |
|    n_updates            | 112          |
|    policy_gradient_loss | -0.000426    |
|    std                  | 1.02         |
|    value_loss           | 0.0016       |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 845    |
|    iterations      | 15     |
|    time_elapsed    | 145    |
|    total_timesteps | 122880 |
-------------------------------
-------------------------------------------
| time/                   |               |
|    fps                  | 867           |
|    iterations           | 16            |
|    time_elapsed         | 151           |
|    total_timesteps      | 131072        |
| train/                  |               |
|    approx_kl            | 0.00050937076 |
|    clip_fraction        | 6.1e-05       |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.43         |
|    explained_variance   | -11.2         |
|    learning_rate        | 5e-05         |
|    loss                 | -0.0272       |
|    n_updates            | 120           |
|    policy_gradient_loss | -0.000364     |
|    std                  | 1.02          |
|    value_loss           | 0.00153       |
-------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 891          |
|    iterations           | 17           |
|    time_elapsed         | 156          |
|    total_timesteps      | 139264       |
| train/                  |              |
|    approx_kl            | 0.0017480502 |
|    clip_fraction        | 0.00117      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.43        |
|    explained_variance   | -10.5        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0315      |
|    n_updates            | 128          |
|    policy_gradient_loss | -0.000447    |
|    std                  | 1.02         |
|    value_loss           | 0.00136      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 915          |
|    iterations           | 18           |
|    time_elapsed         | 161          |
|    total_timesteps      | 147456       |
| train/                  |              |
|    approx_kl            | 0.0025893457 |
|    clip_fraction        | 0.0116       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.43        |
|    explained_variance   | -15.8        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0261      |
|    n_updates            | 136          |
|    policy_gradient_loss | -0.00107     |
|    std                  | 1.01         |
|    value_loss           | 0.00122      |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 937         |
|    iterations           | 19          |
|    time_elapsed         | 166         |
|    total_timesteps      | 155648      |
| train/                  |             |
|    approx_kl            | 0.002418774 |
|    clip_fraction        | 0.00621     |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.43       |
|    explained_variance   | -9.73       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0288     |
|    n_updates            | 144         |
|    policy_gradient_loss | -0.000927   |
|    std                  | 1.01        |
|    value_loss           | 0.00114     |
-----------------------------------------
Eval num_timesteps=160000, episode_reward=-0.16 +/- 0.05
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | -0.163       |
| time/                   |              |
|    total_timesteps      | 160000       |
| train/                  |              |
|    approx_kl            | 0.0021668773 |
|    clip_fraction        | 0.0106       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.43        |
|    explained_variance   | -9.8         |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0313      |
|    n_updates            | 152          |
|    policy_gradient_loss | -0.00119     |
|    std                  | 1.01         |
|    value_loss           | 0.00108      |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 853    |
|    iterations      | 20     |
|    time_elapsed    | 192    |
|    total_timesteps | 163840 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 874          |
|    iterations           | 21           |
|    time_elapsed         | 196          |
|    total_timesteps      | 172032       |
| train/                  |              |
|    approx_kl            | 0.0007503489 |
|    clip_fraction        | 0.000412     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.43        |
|    explained_variance   | -9.39        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.029       |
|    n_updates            | 160          |
|    policy_gradient_loss | -0.000502    |
|    std                  | 1.01         |
|    value_loss           | 0.000984     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 894          |
|    iterations           | 22           |
|    time_elapsed         | 201          |
|    total_timesteps      | 180224       |
| train/                  |              |
|    approx_kl            | 0.0032894511 |
|    clip_fraction        | 0.0211       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.43        |
|    explained_variance   | -7.79        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0277      |
|    n_updates            | 168          |
|    policy_gradient_loss | -0.00156     |
|    std                  | 1.01         |
|    value_loss           | 0.00092      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 913          |
|    iterations           | 23           |
|    time_elapsed         | 206          |
|    total_timesteps      | 188416       |
| train/                  |              |
|    approx_kl            | 0.0012840785 |
|    clip_fraction        | 0.00339      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.43        |
|    explained_variance   | -8.35        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0318      |
|    n_updates            | 176          |
|    policy_gradient_loss | -0.000999    |
|    std                  | 1.01         |
|    value_loss           | 0.000862     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 933          |
|    iterations           | 24           |
|    time_elapsed         | 210          |
|    total_timesteps      | 196608       |
| train/                  |              |
|    approx_kl            | 0.0011906656 |
|    clip_fraction        | 0.00432      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.43        |
|    explained_variance   | -7.63        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0296      |
|    n_updates            | 184          |
|    policy_gradient_loss | -0.00095     |
|    std                  | 1.02         |
|    value_loss           | 0.000824     |
------------------------------------------
Eval num_timesteps=200000, episode_reward=-0.18 +/- 0.05
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | -0.178       |
| time/                   |              |
|    total_timesteps      | 200000       |
| train/                  |              |
|    approx_kl            | 0.0013673508 |
|    clip_fraction        | 0.00465      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.44        |
|    explained_variance   | -6           |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0293      |
|    n_updates            | 192          |
|    policy_gradient_loss | -0.000872    |
|    std                  | 1.02         |
|    value_loss           | 0.000818     |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 857    |
|    iterations      | 25     |
|    time_elapsed    | 238    |
|    total_timesteps | 204800 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 873         |
|    iterations           | 26          |
|    time_elapsed         | 243         |
|    total_timesteps      | 212992      |
| train/                  |             |
|    approx_kl            | 0.002451588 |
|    clip_fraction        | 0.0197      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.44       |
|    explained_variance   | -13.2       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0314     |
|    n_updates            | 200         |
|    policy_gradient_loss | -0.00233    |
|    std                  | 1.02        |
|    value_loss           | 0.000676    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 887          |
|    iterations           | 27           |
|    time_elapsed         | 249          |
|    total_timesteps      | 221184       |
| train/                  |              |
|    approx_kl            | 0.0012678835 |
|    clip_fraction        | 0.00494      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.43        |
|    explained_variance   | -8.09        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0311      |
|    n_updates            | 208          |
|    policy_gradient_loss | -0.00123     |
|    std                  | 1.02         |
|    value_loss           | 0.000692     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 903          |
|    iterations           | 28           |
|    time_elapsed         | 253          |
|    total_timesteps      | 229376       |
| train/                  |              |
|    approx_kl            | 0.0027757955 |
|    clip_fraction        | 0.0201       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.43        |
|    explained_variance   | -8.45        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.03        |
|    n_updates            | 216          |
|    policy_gradient_loss | -0.00173     |
|    std                  | 1.02         |
|    value_loss           | 0.000656     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 914         |
|    iterations           | 29          |
|    time_elapsed         | 259         |
|    total_timesteps      | 237568      |
| train/                  |             |
|    approx_kl            | 0.001715959 |
|    clip_fraction        | 0.0161      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.43       |
|    explained_variance   | -6.78       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.032      |
|    n_updates            | 224         |
|    policy_gradient_loss | -0.00138    |
|    std                  | 1.02        |
|    value_loss           | 0.000587    |
-----------------------------------------
Eval num_timesteps=240000, episode_reward=-0.29 +/- 0.05
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | -0.291       |
| time/                   |              |
|    total_timesteps      | 240000       |
| train/                  |              |
|    approx_kl            | 0.0038299102 |
|    clip_fraction        | 0.0294       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.43        |
|    explained_variance   | -6.08        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0309      |
|    n_updates            | 232          |
|    policy_gradient_loss | -0.0021      |
|    std                  | 1.02         |
|    value_loss           | 0.000581     |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 853    |
|    iterations      | 30     |
|    time_elapsed    | 287    |
|    total_timesteps | 245760 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 868          |
|    iterations           | 31           |
|    time_elapsed         | 292          |
|    total_timesteps      | 253952       |
| train/                  |              |
|    approx_kl            | 0.0011573716 |
|    clip_fraction        | 0.00534      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.44        |
|    explained_variance   | -5.75        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0313      |
|    n_updates            | 240          |
|    policy_gradient_loss | -0.000897    |
|    std                  | 1.02         |
|    value_loss           | 0.000525     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 883          |
|    iterations           | 32           |
|    time_elapsed         | 296          |
|    total_timesteps      | 262144       |
| train/                  |              |
|    approx_kl            | 0.0021018342 |
|    clip_fraction        | 0.0196       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.44        |
|    explained_variance   | -6.47        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.03        |
|    n_updates            | 248          |
|    policy_gradient_loss | -0.00123     |
|    std                  | 1.02         |
|    value_loss           | 0.000476     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 895          |
|    iterations           | 33           |
|    time_elapsed         | 301          |
|    total_timesteps      | 270336       |
| train/                  |              |
|    approx_kl            | 0.0032272781 |
|    clip_fraction        | 0.0243       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.44        |
|    explained_variance   | -6.65        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0323      |
|    n_updates            | 256          |
|    policy_gradient_loss | -0.00175     |
|    std                  | 1.02         |
|    value_loss           | 0.000475     |
------------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 907        |
|    iterations           | 34         |
|    time_elapsed         | 307        |
|    total_timesteps      | 278528     |
| train/                  |            |
|    approx_kl            | 0.00219707 |
|    clip_fraction        | 0.0131     |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.44      |
|    explained_variance   | -10.2      |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0272    |
|    n_updates            | 264        |
|    policy_gradient_loss | -0.00174   |
|    std                  | 1.02       |
|    value_loss           | 0.000428   |
----------------------------------------
Eval num_timesteps=280000, episode_reward=-0.23 +/- 0.06
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.234      |
| time/                   |             |
|    total_timesteps      | 280000      |
| train/                  |             |
|    approx_kl            | 0.003200416 |
|    clip_fraction        | 0.0189      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.44       |
|    explained_variance   | -5.04       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0273     |
|    n_updates            | 272         |
|    policy_gradient_loss | -0.00156    |
|    std                  | 1.02        |
|    value_loss           | 0.000439    |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 852    |
|    iterations      | 35     |
|    time_elapsed    | 336    |
|    total_timesteps | 286720 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 861         |
|    iterations           | 36          |
|    time_elapsed         | 342         |
|    total_timesteps      | 294912      |
| train/                  |             |
|    approx_kl            | 0.002246855 |
|    clip_fraction        | 0.0137      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.44       |
|    explained_variance   | -3.61       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0306     |
|    n_updates            | 280         |
|    policy_gradient_loss | -0.00131    |
|    std                  | 1.02        |
|    value_loss           | 0.000447    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 869         |
|    iterations           | 37          |
|    time_elapsed         | 348         |
|    total_timesteps      | 303104      |
| train/                  |             |
|    approx_kl            | 0.002712599 |
|    clip_fraction        | 0.0202      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.43       |
|    explained_variance   | -4.33       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0336     |
|    n_updates            | 288         |
|    policy_gradient_loss | -0.00115    |
|    std                  | 1.01        |
|    value_loss           | 0.000372    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 877          |
|    iterations           | 38           |
|    time_elapsed         | 354          |
|    total_timesteps      | 311296       |
| train/                  |              |
|    approx_kl            | 0.0028983026 |
|    clip_fraction        | 0.0192       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.43        |
|    explained_variance   | -5.37        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0302      |
|    n_updates            | 296          |
|    policy_gradient_loss | -0.000865    |
|    std                  | 1.01         |
|    value_loss           | 0.000353     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 885          |
|    iterations           | 39           |
|    time_elapsed         | 360          |
|    total_timesteps      | 319488       |
| train/                  |              |
|    approx_kl            | 0.0020799937 |
|    clip_fraction        | 0.0196       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.43        |
|    explained_variance   | -5.27        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0313      |
|    n_updates            | 304          |
|    policy_gradient_loss | -0.00108     |
|    std                  | 1.01         |
|    value_loss           | 0.000355     |
------------------------------------------
Eval num_timesteps=320000, episode_reward=-0.33 +/- 0.05
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | -0.332       |
| time/                   |              |
|    total_timesteps      | 320000       |
| train/                  |              |
|    approx_kl            | 0.0030626457 |
|    clip_fraction        | 0.0231       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.43        |
|    explained_variance   | -5.06        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0259      |
|    n_updates            | 312          |
|    policy_gradient_loss | -0.000798    |
|    std                  | 1.01         |
|    value_loss           | 0.000324     |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 837    |
|    iterations      | 40     |
|    time_elapsed    | 391    |
|    total_timesteps | 327680 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 845         |
|    iterations           | 41          |
|    time_elapsed         | 397         |
|    total_timesteps      | 335872      |
| train/                  |             |
|    approx_kl            | 0.002946535 |
|    clip_fraction        | 0.031       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.43       |
|    explained_variance   | -4.29       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0309     |
|    n_updates            | 320         |
|    policy_gradient_loss | -0.00158    |
|    std                  | 1.01        |
|    value_loss           | 0.000324    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 852          |
|    iterations           | 42           |
|    time_elapsed         | 403          |
|    total_timesteps      | 344064       |
| train/                  |              |
|    approx_kl            | 0.0028920951 |
|    clip_fraction        | 0.0258       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.43        |
|    explained_variance   | -4.77        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0299      |
|    n_updates            | 328          |
|    policy_gradient_loss | -0.000878    |
|    std                  | 1.01         |
|    value_loss           | 0.000296     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 859          |
|    iterations           | 43           |
|    time_elapsed         | 409          |
|    total_timesteps      | 352256       |
| train/                  |              |
|    approx_kl            | 0.0041739726 |
|    clip_fraction        | 0.0358       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.43        |
|    explained_variance   | -4.39        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0291      |
|    n_updates            | 336          |
|    policy_gradient_loss | -0.000928    |
|    std                  | 1.01         |
|    value_loss           | 0.000297     |
------------------------------------------
Eval num_timesteps=360000, episode_reward=-0.37 +/- 0.03
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | -0.372       |
| time/                   |              |
|    total_timesteps      | 360000       |
| train/                  |              |
|    approx_kl            | 0.0038406877 |
|    clip_fraction        | 0.0379       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.43        |
|    explained_variance   | -3.93        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0321      |
|    n_updates            | 344          |
|    policy_gradient_loss | -0.000682    |
|    std                  | 1.01         |
|    value_loss           | 0.000298     |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 818    |
|    iterations      | 44     |
|    time_elapsed    | 440    |
|    total_timesteps | 360448 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 825          |
|    iterations           | 45           |
|    time_elapsed         | 446          |
|    total_timesteps      | 368640       |
| train/                  |              |
|    approx_kl            | 0.0039633834 |
|    clip_fraction        | 0.0429       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.43        |
|    explained_variance   | -4.23        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0294      |
|    n_updates            | 352          |
|    policy_gradient_loss | -0.00108     |
|    std                  | 1.01         |
|    value_loss           | 0.000281     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 832          |
|    iterations           | 46           |
|    time_elapsed         | 452          |
|    total_timesteps      | 376832       |
| train/                  |              |
|    approx_kl            | 0.0037801543 |
|    clip_fraction        | 0.0373       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.43        |
|    explained_variance   | -4           |
|    learning_rate        | 5e-05        |
|    loss                 | -0.035       |
|    n_updates            | 360          |
|    policy_gradient_loss | -0.000792    |
|    std                  | 1.01         |
|    value_loss           | 0.000254     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 839         |
|    iterations           | 47          |
|    time_elapsed         | 458         |
|    total_timesteps      | 385024      |
| train/                  |             |
|    approx_kl            | 0.004080518 |
|    clip_fraction        | 0.0466      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.43       |
|    explained_variance   | -4.67       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0298     |
|    n_updates            | 368         |
|    policy_gradient_loss | -0.000495   |
|    std                  | 1.01        |
|    value_loss           | 0.000249    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 845          |
|    iterations           | 48           |
|    time_elapsed         | 465          |
|    total_timesteps      | 393216       |
| train/                  |              |
|    approx_kl            | 0.0048494777 |
|    clip_fraction        | 0.0535       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.43        |
|    explained_variance   | -3.77        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.03        |
|    n_updates            | 376          |
|    policy_gradient_loss | -0.00167     |
|    std                  | 1.01         |
|    value_loss           | 0.000235     |
------------------------------------------
Eval num_timesteps=400000, episode_reward=-0.51 +/- 0.04
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | -0.509       |
| time/                   |              |
|    total_timesteps      | 400000       |
| train/                  |              |
|    approx_kl            | 0.0068901973 |
|    clip_fraction        | 0.0649       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.42        |
|    explained_variance   | -3.41        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0301      |
|    n_updates            | 384          |
|    policy_gradient_loss | -0.00117     |
|    std                  | 1            |
|    value_loss           | 0.000238     |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 811    |
|    iterations      | 49     |
|    time_elapsed    | 494    |
|    total_timesteps | 401408 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 820         |
|    iterations           | 50          |
|    time_elapsed         | 498         |
|    total_timesteps      | 409600      |
| train/                  |             |
|    approx_kl            | 0.004666145 |
|    clip_fraction        | 0.0619      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.42       |
|    explained_variance   | -4.89       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0338     |
|    n_updates            | 392         |
|    policy_gradient_loss | 0.000131    |
|    std                  | 1           |
|    value_loss           | 0.000224    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 830         |
|    iterations           | 51          |
|    time_elapsed         | 503         |
|    total_timesteps      | 417792      |
| train/                  |             |
|    approx_kl            | 0.004371957 |
|    clip_fraction        | 0.055       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.42       |
|    explained_variance   | -3.4        |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0321     |
|    n_updates            | 400         |
|    policy_gradient_loss | 4.55e-05    |
|    std                  | 1           |
|    value_loss           | 0.000227    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 838          |
|    iterations           | 52           |
|    time_elapsed         | 507          |
|    total_timesteps      | 425984       |
| train/                  |              |
|    approx_kl            | 0.0048441375 |
|    clip_fraction        | 0.0671       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.42        |
|    explained_variance   | -3.86        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0226      |
|    n_updates            | 408          |
|    policy_gradient_loss | 0.000499     |
|    std                  | 1            |
|    value_loss           | 0.000229     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 847          |
|    iterations           | 53           |
|    time_elapsed         | 512          |
|    total_timesteps      | 434176       |
| train/                  |              |
|    approx_kl            | 0.0069180876 |
|    clip_fraction        | 0.0715       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.42        |
|    explained_variance   | -2.82        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0314      |
|    n_updates            | 416          |
|    policy_gradient_loss | -0.000585    |
|    std                  | 1            |
|    value_loss           | 0.00023      |
------------------------------------------
Eval num_timesteps=440000, episode_reward=-0.56 +/- 0.07
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | -0.558       |
| time/                   |              |
|    total_timesteps      | 440000       |
| train/                  |              |
|    approx_kl            | 0.0056714406 |
|    clip_fraction        | 0.074        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.42        |
|    explained_variance   | -2.57        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0299      |
|    n_updates            | 424          |
|    policy_gradient_loss | 0.000568     |
|    std                  | 1            |
|    value_loss           | 0.000209     |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 823    |
|    iterations      | 54     |
|    time_elapsed    | 537    |
|    total_timesteps | 442368 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 830         |
|    iterations           | 55          |
|    time_elapsed         | 542         |
|    total_timesteps      | 450560      |
| train/                  |             |
|    approx_kl            | 0.006181769 |
|    clip_fraction        | 0.0726      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.42       |
|    explained_variance   | -4.14       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0343     |
|    n_updates            | 432         |
|    policy_gradient_loss | 0.00122     |
|    std                  | 1           |
|    value_loss           | 0.000192    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 836          |
|    iterations           | 56           |
|    time_elapsed         | 548          |
|    total_timesteps      | 458752       |
| train/                  |              |
|    approx_kl            | 0.0065442207 |
|    clip_fraction        | 0.0741       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.42        |
|    explained_variance   | -2.75        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0298      |
|    n_updates            | 440          |
|    policy_gradient_loss | 0.0013       |
|    std                  | 1            |
|    value_loss           | 0.000194     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 840         |
|    iterations           | 57          |
|    time_elapsed         | 555         |
|    total_timesteps      | 466944      |
| train/                  |             |
|    approx_kl            | 0.006795839 |
|    clip_fraction        | 0.0819      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.42       |
|    explained_variance   | -1.99       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.031      |
|    n_updates            | 448         |
|    policy_gradient_loss | 0.000625    |
|    std                  | 1           |
|    value_loss           | 0.000192    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 843         |
|    iterations           | 58          |
|    time_elapsed         | 563         |
|    total_timesteps      | 475136      |
| train/                  |             |
|    approx_kl            | 0.007209006 |
|    clip_fraction        | 0.0861      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.42       |
|    explained_variance   | -5.35       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0338     |
|    n_updates            | 456         |
|    policy_gradient_loss | 0.000609    |
|    std                  | 1           |
|    value_loss           | 0.000151    |
-----------------------------------------
Eval num_timesteps=480000, episode_reward=-0.42 +/- 0.04
Episode length: 2340.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 2.34e+03   |
|    mean_reward          | -0.417     |
| time/                   |            |
|    total_timesteps      | 480000     |
| train/                  |            |
|    approx_kl            | 0.00855791 |
|    clip_fraction        | 0.097      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.42      |
|    explained_variance   | -1.93      |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0241    |
|    n_updates            | 464        |
|    policy_gradient_loss | 0.00149    |
|    std                  | 1          |
|    value_loss           | 0.000179   |
----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 815    |
|    iterations      | 59     |
|    time_elapsed    | 592    |
|    total_timesteps | 483328 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 824         |
|    iterations           | 60          |
|    time_elapsed         | 596         |
|    total_timesteps      | 491520      |
| train/                  |             |
|    approx_kl            | 0.008441843 |
|    clip_fraction        | 0.102       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.42       |
|    explained_variance   | -2.5        |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0322     |
|    n_updates            | 472         |
|    policy_gradient_loss | 0.00245     |
|    std                  | 0.999       |
|    value_loss           | 0.000167    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 832          |
|    iterations           | 61           |
|    time_elapsed         | 600          |
|    total_timesteps      | 499712       |
| train/                  |              |
|    approx_kl            | 0.0076943897 |
|    clip_fraction        | 0.093        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.42        |
|    explained_variance   | -1.34        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0281      |
|    n_updates            | 480          |
|    policy_gradient_loss | 0.00249      |
|    std                  | 0.998        |
|    value_loss           | 0.000185     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 839         |
|    iterations           | 62          |
|    time_elapsed         | 605         |
|    total_timesteps      | 507904      |
| train/                  |             |
|    approx_kl            | 0.008234199 |
|    clip_fraction        | 0.0896      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.42       |
|    explained_variance   | -1.93       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0232     |
|    n_updates            | 488         |
|    policy_gradient_loss | 0.00365     |
|    std                  | 0.997       |
|    value_loss           | 0.000169    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 846          |
|    iterations           | 63           |
|    time_elapsed         | 609          |
|    total_timesteps      | 516096       |
| train/                  |              |
|    approx_kl            | 0.0087802345 |
|    clip_fraction        | 0.097        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.42        |
|    explained_variance   | -2.24        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0234      |
|    n_updates            | 496          |
|    policy_gradient_loss | 0.00156      |
|    std                  | 0.996        |
|    value_loss           | 0.000149     |
------------------------------------------
Eval num_timesteps=520000, episode_reward=-0.31 +/- 0.11
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.312      |
| time/                   |             |
|    total_timesteps      | 520000      |
| train/                  |             |
|    approx_kl            | 0.009136439 |
|    clip_fraction        | 0.106       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.41       |
|    explained_variance   | -2.04       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0275     |
|    n_updates            | 504         |
|    policy_gradient_loss | 0.0023      |
|    std                  | 0.994       |
|    value_loss           | 0.000138    |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 822    |
|    iterations      | 64     |
|    time_elapsed    | 637    |
|    total_timesteps | 524288 |
-------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 827        |
|    iterations           | 65         |
|    time_elapsed         | 643        |
|    total_timesteps      | 532480     |
| train/                  |            |
|    approx_kl            | 0.00881494 |
|    clip_fraction        | 0.109      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.41      |
|    explained_variance   | -1.51      |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0257    |
|    n_updates            | 512        |
|    policy_gradient_loss | 0.00175    |
|    std                  | 0.994      |
|    value_loss           | 0.00014    |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 831         |
|    iterations           | 66          |
|    time_elapsed         | 649         |
|    total_timesteps      | 540672      |
| train/                  |             |
|    approx_kl            | 0.009333386 |
|    clip_fraction        | 0.11        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.41       |
|    explained_variance   | -2.8        |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0272     |
|    n_updates            | 520         |
|    policy_gradient_loss | 0.00119     |
|    std                  | 0.993       |
|    value_loss           | 0.000121    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 836         |
|    iterations           | 67          |
|    time_elapsed         | 656         |
|    total_timesteps      | 548864      |
| train/                  |             |
|    approx_kl            | 0.010353678 |
|    clip_fraction        | 0.106       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.41       |
|    explained_variance   | -1.62       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0335     |
|    n_updates            | 528         |
|    policy_gradient_loss | 0.00181     |
|    std                  | 0.991       |
|    value_loss           | 0.000132    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 840         |
|    iterations           | 68          |
|    time_elapsed         | 662         |
|    total_timesteps      | 557056      |
| train/                  |             |
|    approx_kl            | 0.008454749 |
|    clip_fraction        | 0.0966      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.41       |
|    explained_variance   | -1.47       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0278     |
|    n_updates            | 536         |
|    policy_gradient_loss | 0.00163     |
|    std                  | 0.991       |
|    value_loss           | 0.000134    |
-----------------------------------------
Eval num_timesteps=560000, episode_reward=-0.21 +/- 0.06
Episode length: 2340.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 2.34e+03   |
|    mean_reward          | -0.207     |
| time/                   |            |
|    total_timesteps      | 560000     |
| train/                  |            |
|    approx_kl            | 0.00888031 |
|    clip_fraction        | 0.0927     |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.41      |
|    explained_variance   | -1.33      |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0251    |
|    n_updates            | 544        |
|    policy_gradient_loss | 0.00403    |
|    std                  | 0.991      |
|    value_loss           | 0.000133   |
----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 816    |
|    iterations      | 69     |
|    time_elapsed    | 692    |
|    total_timesteps | 565248 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 820         |
|    iterations           | 70          |
|    time_elapsed         | 698         |
|    total_timesteps      | 573440      |
| train/                  |             |
|    approx_kl            | 0.008338865 |
|    clip_fraction        | 0.0945      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.41       |
|    explained_variance   | -1.53       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0266     |
|    n_updates            | 552         |
|    policy_gradient_loss | 0.00441     |
|    std                  | 0.991       |
|    value_loss           | 0.00012     |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 824        |
|    iterations           | 71         |
|    time_elapsed         | 705        |
|    total_timesteps      | 581632     |
| train/                  |            |
|    approx_kl            | 0.00850087 |
|    clip_fraction        | 0.0995     |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.41      |
|    explained_variance   | -1.69      |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0202    |
|    n_updates            | 560        |
|    policy_gradient_loss | 0.00322    |
|    std                  | 0.99       |
|    value_loss           | 0.000114   |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 829         |
|    iterations           | 72          |
|    time_elapsed         | 711         |
|    total_timesteps      | 589824      |
| train/                  |             |
|    approx_kl            | 0.008082973 |
|    clip_fraction        | 0.096       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.41       |
|    explained_variance   | -0.912      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0208     |
|    n_updates            | 568         |
|    policy_gradient_loss | 0.00463     |
|    std                  | 0.988       |
|    value_loss           | 0.00014     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 832         |
|    iterations           | 73          |
|    time_elapsed         | 717         |
|    total_timesteps      | 598016      |
| train/                  |             |
|    approx_kl            | 0.009274468 |
|    clip_fraction        | 0.107       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.41       |
|    explained_variance   | -1.22       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0283     |
|    n_updates            | 576         |
|    policy_gradient_loss | 0.00227     |
|    std                  | 0.987       |
|    value_loss           | 0.000116    |
-----------------------------------------
Eval num_timesteps=600000, episode_reward=-0.07 +/- 0.09
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.0694     |
| time/                   |             |
|    total_timesteps      | 600000      |
| train/                  |             |
|    approx_kl            | 0.008408272 |
|    clip_fraction        | 0.0961      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.4        |
|    explained_variance   | -1.33       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0269     |
|    n_updates            | 584         |
|    policy_gradient_loss | 0.00169     |
|    std                  | 0.985       |
|    value_loss           | 0.000111    |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 810    |
|    iterations      | 74     |
|    time_elapsed    | 748    |
|    total_timesteps | 606208 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 814         |
|    iterations           | 75          |
|    time_elapsed         | 754         |
|    total_timesteps      | 614400      |
| train/                  |             |
|    approx_kl            | 0.008732037 |
|    clip_fraction        | 0.0955      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.4        |
|    explained_variance   | -0.869      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0263     |
|    n_updates            | 592         |
|    policy_gradient_loss | 0.00324     |
|    std                  | 0.984       |
|    value_loss           | 0.000126    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 819         |
|    iterations           | 76          |
|    time_elapsed         | 760         |
|    total_timesteps      | 622592      |
| train/                  |             |
|    approx_kl            | 0.008112883 |
|    clip_fraction        | 0.0937      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.4        |
|    explained_variance   | -1.38       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0301     |
|    n_updates            | 600         |
|    policy_gradient_loss | 0.00283     |
|    std                  | 0.984       |
|    value_loss           | 9.96e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 823         |
|    iterations           | 77          |
|    time_elapsed         | 766         |
|    total_timesteps      | 630784      |
| train/                  |             |
|    approx_kl            | 0.008994504 |
|    clip_fraction        | 0.099       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.4        |
|    explained_variance   | -1.91       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0224     |
|    n_updates            | 608         |
|    policy_gradient_loss | 0.00308     |
|    std                  | 0.983       |
|    value_loss           | 9.13e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 827         |
|    iterations           | 78          |
|    time_elapsed         | 772         |
|    total_timesteps      | 638976      |
| train/                  |             |
|    approx_kl            | 0.008021624 |
|    clip_fraction        | 0.0925      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.4        |
|    explained_variance   | -1.21       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0259     |
|    n_updates            | 616         |
|    policy_gradient_loss | 0.00278     |
|    std                  | 0.983       |
|    value_loss           | 0.000102    |
-----------------------------------------
Eval num_timesteps=640000, episode_reward=-0.16 +/- 0.07
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.161      |
| time/                   |             |
|    total_timesteps      | 640000      |
| train/                  |             |
|    approx_kl            | 0.009685589 |
|    clip_fraction        | 0.11        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.4        |
|    explained_variance   | -1.71       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0276     |
|    n_updates            | 624         |
|    policy_gradient_loss | 0.00374     |
|    std                  | 0.98        |
|    value_loss           | 9.49e-05    |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 809    |
|    iterations      | 79     |
|    time_elapsed    | 799    |
|    total_timesteps | 647168 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 815         |
|    iterations           | 80          |
|    time_elapsed         | 803         |
|    total_timesteps      | 655360      |
| train/                  |             |
|    approx_kl            | 0.009970339 |
|    clip_fraction        | 0.106       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.4        |
|    explained_variance   | -1.8        |
|    learning_rate        | 5e-05       |
|    loss                 | -0.016      |
|    n_updates            | 632         |
|    policy_gradient_loss | 0.00479     |
|    std                  | 0.979       |
|    value_loss           | 9.03e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 821         |
|    iterations           | 81          |
|    time_elapsed         | 807         |
|    total_timesteps      | 663552      |
| train/                  |             |
|    approx_kl            | 0.008773159 |
|    clip_fraction        | 0.0975      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.4        |
|    explained_variance   | -1.13       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0232     |
|    n_updates            | 640         |
|    policy_gradient_loss | 0.00368     |
|    std                  | 0.977       |
|    value_loss           | 9.58e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 827         |
|    iterations           | 82          |
|    time_elapsed         | 811         |
|    total_timesteps      | 671744      |
| train/                  |             |
|    approx_kl            | 0.008833252 |
|    clip_fraction        | 0.102       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.4        |
|    explained_variance   | -1.73       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0319     |
|    n_updates            | 648         |
|    policy_gradient_loss | 0.00333     |
|    std                  | 0.976       |
|    value_loss           | 8.01e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 833         |
|    iterations           | 83          |
|    time_elapsed         | 815         |
|    total_timesteps      | 679936      |
| train/                  |             |
|    approx_kl            | 0.009696314 |
|    clip_fraction        | 0.104       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.39       |
|    explained_variance   | -0.967      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0281     |
|    n_updates            | 656         |
|    policy_gradient_loss | 0.00242     |
|    std                  | 0.974       |
|    value_loss           | 0.0001      |
-----------------------------------------
Eval num_timesteps=680000, episode_reward=-0.12 +/- 0.08
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.123      |
| time/                   |             |
|    total_timesteps      | 680000      |
| train/                  |             |
|    approx_kl            | 0.009366773 |
|    clip_fraction        | 0.106       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.39       |
|    explained_variance   | -1.26       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0277     |
|    n_updates            | 664         |
|    policy_gradient_loss | 0.0033      |
|    std                  | 0.973       |
|    value_loss           | 7.83e-05    |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 816    |
|    iterations      | 84     |
|    time_elapsed    | 842    |
|    total_timesteps | 688128 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 819         |
|    iterations           | 85          |
|    time_elapsed         | 849         |
|    total_timesteps      | 696320      |
| train/                  |             |
|    approx_kl            | 0.010435691 |
|    clip_fraction        | 0.112       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.39       |
|    explained_variance   | -1.73       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0279     |
|    n_updates            | 672         |
|    policy_gradient_loss | 0.00403     |
|    std                  | 0.973       |
|    value_loss           | 8.98e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 822         |
|    iterations           | 86          |
|    time_elapsed         | 856         |
|    total_timesteps      | 704512      |
| train/                  |             |
|    approx_kl            | 0.010517814 |
|    clip_fraction        | 0.111       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.39       |
|    explained_variance   | -1.08       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0262     |
|    n_updates            | 680         |
|    policy_gradient_loss | 0.00274     |
|    std                  | 0.971       |
|    value_loss           | 8.85e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 825         |
|    iterations           | 87          |
|    time_elapsed         | 863         |
|    total_timesteps      | 712704      |
| train/                  |             |
|    approx_kl            | 0.010217244 |
|    clip_fraction        | 0.109       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.39       |
|    explained_variance   | -1.03       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0205     |
|    n_updates            | 688         |
|    policy_gradient_loss | 0.00486     |
|    std                  | 0.97        |
|    value_loss           | 9.03e-05    |
-----------------------------------------
Eval num_timesteps=720000, episode_reward=-0.11 +/- 0.04
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.112      |
| time/                   |             |
|    total_timesteps      | 720000      |
| train/                  |             |
|    approx_kl            | 0.011158913 |
|    clip_fraction        | 0.12        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.39       |
|    explained_variance   | -1.78       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0193     |
|    n_updates            | 696         |
|    policy_gradient_loss | 0.00583     |
|    std                  | 0.969       |
|    value_loss           | 6.86e-05    |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 810    |
|    iterations      | 88     |
|    time_elapsed    | 889    |
|    total_timesteps | 720896 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 815          |
|    iterations           | 89           |
|    time_elapsed         | 893          |
|    total_timesteps      | 729088       |
| train/                  |              |
|    approx_kl            | 0.0104662385 |
|    clip_fraction        | 0.124        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.39        |
|    explained_variance   | -1.18        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0192      |
|    n_updates            | 704          |
|    policy_gradient_loss | 0.00378      |
|    std                  | 0.969        |
|    value_loss           | 7.19e-05     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 820         |
|    iterations           | 90          |
|    time_elapsed         | 898         |
|    total_timesteps      | 737280      |
| train/                  |             |
|    approx_kl            | 0.011048315 |
|    clip_fraction        | 0.124       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.39       |
|    explained_variance   | -1.31       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0235     |
|    n_updates            | 712         |
|    policy_gradient_loss | 0.00421     |
|    std                  | 0.969       |
|    value_loss           | 7.55e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 824         |
|    iterations           | 91          |
|    time_elapsed         | 903         |
|    total_timesteps      | 745472      |
| train/                  |             |
|    approx_kl            | 0.011394752 |
|    clip_fraction        | 0.124       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.39       |
|    explained_variance   | -1.29       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0271     |
|    n_updates            | 720         |
|    policy_gradient_loss | 0.00446     |
|    std                  | 0.97        |
|    value_loss           | 6.39e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 829         |
|    iterations           | 92          |
|    time_elapsed         | 908         |
|    total_timesteps      | 753664      |
| train/                  |             |
|    approx_kl            | 0.010552696 |
|    clip_fraction        | 0.119       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.39       |
|    explained_variance   | -1.08       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0202     |
|    n_updates            | 728         |
|    policy_gradient_loss | 0.00449     |
|    std                  | 0.97        |
|    value_loss           | 7.13e-05    |
-----------------------------------------
Eval num_timesteps=760000, episode_reward=-0.11 +/- 0.08
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.108      |
| time/                   |             |
|    total_timesteps      | 760000      |
| train/                  |             |
|    approx_kl            | 0.011120666 |
|    clip_fraction        | 0.127       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.39       |
|    explained_variance   | -0.773      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0247     |
|    n_updates            | 736         |
|    policy_gradient_loss | 0.00451     |
|    std                  | 0.971       |
|    value_loss           | 8.29e-05    |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 812    |
|    iterations      | 93     |
|    time_elapsed    | 937    |
|    total_timesteps | 761856 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 816         |
|    iterations           | 94          |
|    time_elapsed         | 943         |
|    total_timesteps      | 770048      |
| train/                  |             |
|    approx_kl            | 0.011058766 |
|    clip_fraction        | 0.122       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.39       |
|    explained_variance   | -1.11       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0265     |
|    n_updates            | 744         |
|    policy_gradient_loss | 0.00418     |
|    std                  | 0.97        |
|    value_loss           | 6.21e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 819         |
|    iterations           | 95          |
|    time_elapsed         | 949         |
|    total_timesteps      | 778240      |
| train/                  |             |
|    approx_kl            | 0.010381608 |
|    clip_fraction        | 0.119       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.39       |
|    explained_variance   | -0.992      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.031      |
|    n_updates            | 752         |
|    policy_gradient_loss | 0.00467     |
|    std                  | 0.969       |
|    value_loss           | 6.42e-05    |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 822        |
|    iterations           | 96         |
|    time_elapsed         | 956        |
|    total_timesteps      | 786432     |
| train/                  |            |
|    approx_kl            | 0.01268209 |
|    clip_fraction        | 0.139      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.39      |
|    explained_variance   | -0.909     |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0213    |
|    n_updates            | 760        |
|    policy_gradient_loss | 0.00556    |
|    std                  | 0.969      |
|    value_loss           | 7.22e-05   |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 825         |
|    iterations           | 97          |
|    time_elapsed         | 962         |
|    total_timesteps      | 794624      |
| train/                  |             |
|    approx_kl            | 0.011886928 |
|    clip_fraction        | 0.139       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.39       |
|    explained_variance   | -0.44       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0145     |
|    n_updates            | 768         |
|    policy_gradient_loss | 0.00447     |
|    std                  | 0.969       |
|    value_loss           | 0.000107    |
-----------------------------------------
Eval num_timesteps=800000, episode_reward=-0.07 +/- 0.08
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | -0.0685      |
| time/                   |              |
|    total_timesteps      | 800000       |
| train/                  |              |
|    approx_kl            | 0.0125923455 |
|    clip_fraction        | 0.147        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.39        |
|    explained_variance   | -0.793       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0218      |
|    n_updates            | 776          |
|    policy_gradient_loss | 0.00469      |
|    std                  | 0.97         |
|    value_loss           | 6.58e-05     |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 808    |
|    iterations      | 98     |
|    time_elapsed    | 993    |
|    total_timesteps | 802816 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 811         |
|    iterations           | 99          |
|    time_elapsed         | 999         |
|    total_timesteps      | 811008      |
| train/                  |             |
|    approx_kl            | 0.010764835 |
|    clip_fraction        | 0.135       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.39       |
|    explained_variance   | -1.08       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.027      |
|    n_updates            | 784         |
|    policy_gradient_loss | 0.00574     |
|    std                  | 0.97        |
|    value_loss           | 6.16e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 814         |
|    iterations           | 100         |
|    time_elapsed         | 1005        |
|    total_timesteps      | 819200      |
| train/                  |             |
|    approx_kl            | 0.013634708 |
|    clip_fraction        | 0.145       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.39       |
|    explained_variance   | -0.947      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.028      |
|    n_updates            | 792         |
|    policy_gradient_loss | 0.00507     |
|    std                  | 0.971       |
|    value_loss           | 5.91e-05    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 817          |
|    iterations           | 101          |
|    time_elapsed         | 1011         |
|    total_timesteps      | 827392       |
| train/                  |              |
|    approx_kl            | 0.0124257095 |
|    clip_fraction        | 0.137        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.39        |
|    explained_variance   | -0.795       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0146      |
|    n_updates            | 800          |
|    policy_gradient_loss | 0.00495      |
|    std                  | 0.97         |
|    value_loss           | 6.16e-05     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 820         |
|    iterations           | 102         |
|    time_elapsed         | 1017        |
|    total_timesteps      | 835584      |
| train/                  |             |
|    approx_kl            | 0.014082883 |
|    clip_fraction        | 0.153       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.39       |
|    explained_variance   | -0.721      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0256     |
|    n_updates            | 808         |
|    policy_gradient_loss | 0.00427     |
|    std                  | 0.969       |
|    value_loss           | 6.92e-05    |
-----------------------------------------
Eval num_timesteps=840000, episode_reward=-0.11 +/- 0.09
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.107      |
| time/                   |             |
|    total_timesteps      | 840000      |
| train/                  |             |
|    approx_kl            | 0.012568306 |
|    clip_fraction        | 0.141       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.39       |
|    explained_variance   | -0.647      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0236     |
|    n_updates            | 816         |
|    policy_gradient_loss | 0.00524     |
|    std                  | 0.97        |
|    value_loss           | 6.03e-05    |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 806    |
|    iterations      | 103    |
|    time_elapsed    | 1046   |
|    total_timesteps | 843776 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 810         |
|    iterations           | 104         |
|    time_elapsed         | 1051        |
|    total_timesteps      | 851968      |
| train/                  |             |
|    approx_kl            | 0.013085255 |
|    clip_fraction        | 0.148       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.39       |
|    explained_variance   | -0.855      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0378     |
|    n_updates            | 824         |
|    policy_gradient_loss | 0.00451     |
|    std                  | 0.969       |
|    value_loss           | 5.4e-05     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 813         |
|    iterations           | 105         |
|    time_elapsed         | 1057        |
|    total_timesteps      | 860160      |
| train/                  |             |
|    approx_kl            | 0.011425193 |
|    clip_fraction        | 0.135       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.39       |
|    explained_variance   | -0.765      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0211     |
|    n_updates            | 832         |
|    policy_gradient_loss | 0.0044      |
|    std                  | 0.967       |
|    value_loss           | 5.62e-05    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 817          |
|    iterations           | 106          |
|    time_elapsed         | 1062         |
|    total_timesteps      | 868352       |
| train/                  |              |
|    approx_kl            | 0.0120557025 |
|    clip_fraction        | 0.141        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.39        |
|    explained_variance   | -0.764       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0244      |
|    n_updates            | 840          |
|    policy_gradient_loss | 0.00432      |
|    std                  | 0.967        |
|    value_loss           | 4.58e-05     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 821         |
|    iterations           | 107         |
|    time_elapsed         | 1067        |
|    total_timesteps      | 876544      |
| train/                  |             |
|    approx_kl            | 0.010304718 |
|    clip_fraction        | 0.132       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.39       |
|    explained_variance   | -0.935      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0252     |
|    n_updates            | 848         |
|    policy_gradient_loss | 0.00404     |
|    std                  | 0.966       |
|    value_loss           | 4.42e-05    |
-----------------------------------------
Eval num_timesteps=880000, episode_reward=-0.13 +/- 0.09
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | -0.133       |
| time/                   |              |
|    total_timesteps      | 880000       |
| train/                  |              |
|    approx_kl            | 0.0113563705 |
|    clip_fraction        | 0.134        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.38        |
|    explained_variance   | -0.449       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0215      |
|    n_updates            | 856          |
|    policy_gradient_loss | 0.00459      |
|    std                  | 0.964        |
|    value_loss           | 7.13e-05     |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 810    |
|    iterations      | 108    |
|    time_elapsed    | 1091   |
|    total_timesteps | 884736 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 814         |
|    iterations           | 109         |
|    time_elapsed         | 1096        |
|    total_timesteps      | 892928      |
| train/                  |             |
|    approx_kl            | 0.011531135 |
|    clip_fraction        | 0.133       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.38       |
|    explained_variance   | -0.376      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0251     |
|    n_updates            | 864         |
|    policy_gradient_loss | 0.0037      |
|    std                  | 0.963       |
|    value_loss           | 7.68e-05    |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 818        |
|    iterations           | 110        |
|    time_elapsed         | 1101       |
|    total_timesteps      | 901120     |
| train/                  |            |
|    approx_kl            | 0.01174223 |
|    clip_fraction        | 0.138      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.38      |
|    explained_variance   | -0.587     |
|    learning_rate        | 5e-05      |
|    loss                 | -0.028     |
|    n_updates            | 872        |
|    policy_gradient_loss | 0.00327    |
|    std                  | 0.961      |
|    value_loss           | 6.37e-05   |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 822         |
|    iterations           | 111         |
|    time_elapsed         | 1105        |
|    total_timesteps      | 909312      |
| train/                  |             |
|    approx_kl            | 0.012549652 |
|    clip_fraction        | 0.145       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.38       |
|    explained_variance   | -0.6        |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0237     |
|    n_updates            | 880         |
|    policy_gradient_loss | 0.00353     |
|    std                  | 0.96        |
|    value_loss           | 5.4e-05     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 826         |
|    iterations           | 112         |
|    time_elapsed         | 1110        |
|    total_timesteps      | 917504      |
| train/                  |             |
|    approx_kl            | 0.012525573 |
|    clip_fraction        | 0.143       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.38       |
|    explained_variance   | -0.548      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.027      |
|    n_updates            | 888         |
|    policy_gradient_loss | 0.00431     |
|    std                  | 0.958       |
|    value_loss           | 4.71e-05    |
-----------------------------------------
Eval num_timesteps=920000, episode_reward=-0.06 +/- 0.05
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.0648     |
| time/                   |             |
|    total_timesteps      | 920000      |
| train/                  |             |
|    approx_kl            | 0.011777185 |
|    clip_fraction        | 0.132       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.37       |
|    explained_variance   | -0.519      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0264     |
|    n_updates            | 896         |
|    policy_gradient_loss | 0.00157     |
|    std                  | 0.956       |
|    value_loss           | 4.47e-05    |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 814    |
|    iterations      | 113    |
|    time_elapsed    | 1136   |
|    total_timesteps | 925696 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 817         |
|    iterations           | 114         |
|    time_elapsed         | 1142        |
|    total_timesteps      | 933888      |
| train/                  |             |
|    approx_kl            | 0.009841325 |
|    clip_fraction        | 0.119       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.37       |
|    explained_variance   | -0.33       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0238     |
|    n_updates            | 904         |
|    policy_gradient_loss | 0.00386     |
|    std                  | 0.954       |
|    value_loss           | 7.38e-05    |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 820        |
|    iterations           | 115        |
|    time_elapsed         | 1148       |
|    total_timesteps      | 942080     |
| train/                  |            |
|    approx_kl            | 0.00989558 |
|    clip_fraction        | 0.121      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.37      |
|    explained_variance   | -0.446     |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0272    |
|    n_updates            | 912        |
|    policy_gradient_loss | 0.0023     |
|    std                  | 0.953      |
|    value_loss           | 5.29e-05   |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 823        |
|    iterations           | 116        |
|    time_elapsed         | 1153       |
|    total_timesteps      | 950272     |
| train/                  |            |
|    approx_kl            | 0.00899645 |
|    clip_fraction        | 0.108      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.37      |
|    explained_variance   | -0.204     |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0266    |
|    n_updates            | 920        |
|    policy_gradient_loss | 0.000923   |
|    std                  | 0.951      |
|    value_loss           | 9.29e-05   |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 827        |
|    iterations           | 117        |
|    time_elapsed         | 1158       |
|    total_timesteps      | 958464     |
| train/                  |            |
|    approx_kl            | 0.00853602 |
|    clip_fraction        | 0.107      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.37      |
|    explained_variance   | -0.422     |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0261    |
|    n_updates            | 928        |
|    policy_gradient_loss | 0.00268    |
|    std                  | 0.949      |
|    value_loss           | 5.46e-05   |
----------------------------------------
Eval num_timesteps=960000, episode_reward=-0.04 +/- 0.07
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.0356     |
| time/                   |             |
|    total_timesteps      | 960000      |
| train/                  |             |
|    approx_kl            | 0.008390308 |
|    clip_fraction        | 0.101       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.37       |
|    explained_variance   | -0.634      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0328     |
|    n_updates            | 936         |
|    policy_gradient_loss | 0.00112     |
|    std                  | 0.947       |
|    value_loss           | 4.14e-05    |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 816    |
|    iterations      | 118    |
|    time_elapsed    | 1183   |
|    total_timesteps | 966656 |
-------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 819        |
|    iterations           | 119        |
|    time_elapsed         | 1189       |
|    total_timesteps      | 974848     |
| train/                  |            |
|    approx_kl            | 0.00974602 |
|    clip_fraction        | 0.114      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.36      |
|    explained_variance   | -0.549     |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0241    |
|    n_updates            | 944        |
|    policy_gradient_loss | 0.00065    |
|    std                  | 0.945      |
|    value_loss           | 4.64e-05   |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 823        |
|    iterations           | 120        |
|    time_elapsed         | 1194       |
|    total_timesteps      | 983040     |
| train/                  |            |
|    approx_kl            | 0.00911997 |
|    clip_fraction        | 0.102      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.36      |
|    explained_variance   | -0.434     |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0215    |
|    n_updates            | 952        |
|    policy_gradient_loss | 0.00222    |
|    std                  | 0.943      |
|    value_loss           | 5.3e-05    |
----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 825          |
|    iterations           | 121          |
|    time_elapsed         | 1200         |
|    total_timesteps      | 991232       |
| train/                  |              |
|    approx_kl            | 0.0076711196 |
|    clip_fraction        | 0.0959       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.36        |
|    explained_variance   | -0.629       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0267      |
|    n_updates            | 960          |
|    policy_gradient_loss | 0.000994     |
|    std                  | 0.94         |
|    value_loss           | 4.79e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 828          |
|    iterations           | 122          |
|    time_elapsed         | 1206         |
|    total_timesteps      | 999424       |
| train/                  |              |
|    approx_kl            | 0.0072363634 |
|    clip_fraction        | 0.0901       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.36        |
|    explained_variance   | -0.457       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0279      |
|    n_updates            | 968          |
|    policy_gradient_loss | 0.00202      |
|    std                  | 0.937        |
|    value_loss           | 4.83e-05     |
------------------------------------------
Eval num_timesteps=1000000, episode_reward=-0.00 +/- 0.07
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | -0.00156     |
| time/                   |              |
|    total_timesteps      | 1000000      |
| train/                  |              |
|    approx_kl            | 0.0077713355 |
|    clip_fraction        | 0.0879       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.35        |
|    explained_variance   | -0.322       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0258      |
|    n_updates            | 976          |
|    policy_gradient_loss | 7.77e-05     |
|    std                  | 0.936        |
|    value_loss           | 5.09e-05     |
------------------------------------------
New best mean reward!
--------------------------------
| time/              |         |
|    fps             | 814     |
|    iterations      | 123     |
|    time_elapsed    | 1236    |
|    total_timesteps | 1007616 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 817         |
|    iterations           | 124         |
|    time_elapsed         | 1243        |
|    total_timesteps      | 1015808     |
| train/                  |             |
|    approx_kl            | 0.005803832 |
|    clip_fraction        | 0.0739      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.35       |
|    explained_variance   | -0.633      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0323     |
|    n_updates            | 984         |
|    policy_gradient_loss | -0.000326   |
|    std                  | 0.933       |
|    value_loss           | 4.24e-05    |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 819        |
|    iterations           | 125        |
|    time_elapsed         | 1249       |
|    total_timesteps      | 1024000    |
| train/                  |            |
|    approx_kl            | 0.00611158 |
|    clip_fraction        | 0.0691     |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.35      |
|    explained_variance   | -0.451     |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0249    |
|    n_updates            | 992        |
|    policy_gradient_loss | 0.000134   |
|    std                  | 0.93       |
|    value_loss           | 5.31e-05   |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 822         |
|    iterations           | 126         |
|    time_elapsed         | 1255        |
|    total_timesteps      | 1032192     |
| train/                  |             |
|    approx_kl            | 0.005986816 |
|    clip_fraction        | 0.079       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.35       |
|    explained_variance   | -0.354      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.036      |
|    n_updates            | 1000        |
|    policy_gradient_loss | 0.000518    |
|    std                  | 0.928       |
|    value_loss           | 5.81e-05    |
-----------------------------------------
Eval num_timesteps=1040000, episode_reward=0.05 +/- 0.09
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | 0.0524       |
| time/                   |              |
|    total_timesteps      | 1040000      |
| train/                  |              |
|    approx_kl            | 0.0054830885 |
|    clip_fraction        | 0.061        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.34        |
|    explained_variance   | -0.331       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0263      |
|    n_updates            | 1008         |
|    policy_gradient_loss | 0.000654     |
|    std                  | 0.925        |
|    value_loss           | 4.89e-05     |
------------------------------------------
New best mean reward!
--------------------------------
| time/              |         |
|    fps             | 809     |
|    iterations      | 127     |
|    time_elapsed    | 1285    |
|    total_timesteps | 1040384 |
--------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 811          |
|    iterations           | 128          |
|    time_elapsed         | 1292         |
|    total_timesteps      | 1048576      |
| train/                  |              |
|    approx_kl            | 0.0056718546 |
|    clip_fraction        | 0.0742       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.34        |
|    explained_variance   | -0.4         |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0264      |
|    n_updates            | 1016         |
|    policy_gradient_loss | -0.000548    |
|    std                  | 0.924        |
|    value_loss           | 5.38e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 813          |
|    iterations           | 129          |
|    time_elapsed         | 1298         |
|    total_timesteps      | 1056768      |
| train/                  |              |
|    approx_kl            | 0.0073062233 |
|    clip_fraction        | 0.0759       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.34        |
|    explained_variance   | -0.554       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0281      |
|    n_updates            | 1024         |
|    policy_gradient_loss | -0.000574    |
|    std                  | 0.922        |
|    value_loss           | 3.79e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 816          |
|    iterations           | 130          |
|    time_elapsed         | 1304         |
|    total_timesteps      | 1064960      |
| train/                  |              |
|    approx_kl            | 0.0057134596 |
|    clip_fraction        | 0.0655       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.34        |
|    explained_variance   | -0.584       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.025       |
|    n_updates            | 1032         |
|    policy_gradient_loss | 0.00015      |
|    std                  | 0.921        |
|    value_loss           | 3.87e-05     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 818         |
|    iterations           | 131         |
|    time_elapsed         | 1311        |
|    total_timesteps      | 1073152     |
| train/                  |             |
|    approx_kl            | 0.004354706 |
|    clip_fraction        | 0.0489      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.34       |
|    explained_variance   | -0.127      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0257     |
|    n_updates            | 1040        |
|    policy_gradient_loss | 8.33e-06    |
|    std                  | 0.921       |
|    value_loss           | 0.000115    |
-----------------------------------------
Eval num_timesteps=1080000, episode_reward=0.02 +/- 0.05
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | 0.0167       |
| time/                   |              |
|    total_timesteps      | 1080000      |
| train/                  |              |
|    approx_kl            | 0.0050698044 |
|    clip_fraction        | 0.0543       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.34        |
|    explained_variance   | -0.269       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0242      |
|    n_updates            | 1048         |
|    policy_gradient_loss | 0.000398     |
|    std                  | 0.919        |
|    value_loss           | 8.09e-05     |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 805     |
|    iterations      | 132     |
|    time_elapsed    | 1342    |
|    total_timesteps | 1081344 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 808         |
|    iterations           | 133         |
|    time_elapsed         | 1348        |
|    total_timesteps      | 1089536     |
| train/                  |             |
|    approx_kl            | 0.004731279 |
|    clip_fraction        | 0.0495      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.33       |
|    explained_variance   | -0.417      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0238     |
|    n_updates            | 1056        |
|    policy_gradient_loss | -0.000528   |
|    std                  | 0.918       |
|    value_loss           | 4.7e-05     |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 810          |
|    iterations           | 134          |
|    time_elapsed         | 1354         |
|    total_timesteps      | 1097728      |
| train/                  |              |
|    approx_kl            | 0.0064155506 |
|    clip_fraction        | 0.0614       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.33        |
|    explained_variance   | -0.85        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0255      |
|    n_updates            | 1064         |
|    policy_gradient_loss | -0.00105     |
|    std                  | 0.917        |
|    value_loss           | 3.24e-05     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 812         |
|    iterations           | 135         |
|    time_elapsed         | 1360        |
|    total_timesteps      | 1105920     |
| train/                  |             |
|    approx_kl            | 0.003990245 |
|    clip_fraction        | 0.0518      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.33       |
|    explained_variance   | -0.546      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0312     |
|    n_updates            | 1072        |
|    policy_gradient_loss | -0.000802   |
|    std                  | 0.915       |
|    value_loss           | 4.07e-05    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 815          |
|    iterations           | 136          |
|    time_elapsed         | 1366         |
|    total_timesteps      | 1114112      |
| train/                  |              |
|    approx_kl            | 0.0038619079 |
|    clip_fraction        | 0.0432       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.33        |
|    explained_variance   | -0.714       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0273      |
|    n_updates            | 1080         |
|    policy_gradient_loss | -0.00038     |
|    std                  | 0.914        |
|    value_loss           | 3.16e-05     |
------------------------------------------
Eval num_timesteps=1120000, episode_reward=-0.00 +/- 0.09
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | -2.56e-05    |
| time/                   |              |
|    total_timesteps      | 1120000      |
| train/                  |              |
|    approx_kl            | 0.0045396145 |
|    clip_fraction        | 0.0441       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.33        |
|    explained_variance   | -0.485       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0235      |
|    n_updates            | 1088         |
|    policy_gradient_loss | -0.000645    |
|    std                  | 0.913        |
|    value_loss           | 3.86e-05     |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 804     |
|    iterations      | 137     |
|    time_elapsed    | 1394    |
|    total_timesteps | 1122304 |
--------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 807          |
|    iterations           | 138          |
|    time_elapsed         | 1399         |
|    total_timesteps      | 1130496      |
| train/                  |              |
|    approx_kl            | 0.0034549998 |
|    clip_fraction        | 0.0289       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.33        |
|    explained_variance   | -0.995       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0285      |
|    n_updates            | 1096         |
|    policy_gradient_loss | 5.3e-05      |
|    std                  | 0.912        |
|    value_loss           | 2.6e-05      |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 811         |
|    iterations           | 139         |
|    time_elapsed         | 1403        |
|    total_timesteps      | 1138688     |
| train/                  |             |
|    approx_kl            | 0.003417614 |
|    clip_fraction        | 0.0352      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.33       |
|    explained_variance   | -0.425      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0271     |
|    n_updates            | 1104        |
|    policy_gradient_loss | 1.75e-05    |
|    std                  | 0.912       |
|    value_loss           | 4.05e-05    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 814          |
|    iterations           | 140          |
|    time_elapsed         | 1407         |
|    total_timesteps      | 1146880      |
| train/                  |              |
|    approx_kl            | 0.0032051133 |
|    clip_fraction        | 0.032        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.33        |
|    explained_variance   | -0.482       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.026       |
|    n_updates            | 1112         |
|    policy_gradient_loss | -0.000526    |
|    std                  | 0.911        |
|    value_loss           | 3.69e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 818          |
|    iterations           | 141          |
|    time_elapsed         | 1411         |
|    total_timesteps      | 1155072      |
| train/                  |              |
|    approx_kl            | 0.0031552692 |
|    clip_fraction        | 0.0418       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.32        |
|    explained_variance   | -0.589       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0272      |
|    n_updates            | 1120         |
|    policy_gradient_loss | -0.00028     |
|    std                  | 0.908        |
|    value_loss           | 3.34e-05     |
------------------------------------------
Eval num_timesteps=1160000, episode_reward=-0.02 +/- 0.08
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | -0.0237      |
| time/                   |              |
|    total_timesteps      | 1160000      |
| train/                  |              |
|    approx_kl            | 0.0038659447 |
|    clip_fraction        | 0.0399       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.32        |
|    explained_variance   | -0.729       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0284      |
|    n_updates            | 1128         |
|    policy_gradient_loss | 0.000455     |
|    std                  | 0.907        |
|    value_loss           | 3.06e-05     |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 810     |
|    iterations      | 142     |
|    time_elapsed    | 1434    |
|    total_timesteps | 1163264 |
--------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 814          |
|    iterations           | 143          |
|    time_elapsed         | 1438         |
|    total_timesteps      | 1171456      |
| train/                  |              |
|    approx_kl            | 0.0038381487 |
|    clip_fraction        | 0.05         |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.32        |
|    explained_variance   | -0.559       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.03        |
|    n_updates            | 1136         |
|    policy_gradient_loss | -0.000186    |
|    std                  | 0.905        |
|    value_loss           | 3.42e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 817          |
|    iterations           | 144          |
|    time_elapsed         | 1442         |
|    total_timesteps      | 1179648      |
| train/                  |              |
|    approx_kl            | 0.0038703103 |
|    clip_fraction        | 0.0422       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.32        |
|    explained_variance   | -0.648       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0275      |
|    n_updates            | 1144         |
|    policy_gradient_loss | 0.000344     |
|    std                  | 0.905        |
|    value_loss           | 2.87e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 820          |
|    iterations           | 145          |
|    time_elapsed         | 1446         |
|    total_timesteps      | 1187840      |
| train/                  |              |
|    approx_kl            | 0.0035227856 |
|    clip_fraction        | 0.044        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.32        |
|    explained_variance   | -0.54        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0261      |
|    n_updates            | 1152         |
|    policy_gradient_loss | 0.000494     |
|    std                  | 0.905        |
|    value_loss           | 3.31e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 824          |
|    iterations           | 146          |
|    time_elapsed         | 1450         |
|    total_timesteps      | 1196032      |
| train/                  |              |
|    approx_kl            | 0.0052675614 |
|    clip_fraction        | 0.0648       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.32        |
|    explained_variance   | -0.804       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0236      |
|    n_updates            | 1160         |
|    policy_gradient_loss | 0.000476     |
|    std                  | 0.904        |
|    value_loss           | 2.66e-05     |
------------------------------------------
Eval num_timesteps=1200000, episode_reward=-0.01 +/- 0.09
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.00711    |
| time/                   |             |
|    total_timesteps      | 1200000     |
| train/                  |             |
|    approx_kl            | 0.004649246 |
|    clip_fraction        | 0.0523      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.32       |
|    explained_variance   | -0.224      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0263     |
|    n_updates            | 1168        |
|    policy_gradient_loss | -0.000438   |
|    std                  | 0.903       |
|    value_loss           | 7.13e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 816     |
|    iterations      | 147     |
|    time_elapsed    | 1474    |
|    total_timesteps | 1204224 |
--------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 820          |
|    iterations           | 148          |
|    time_elapsed         | 1478         |
|    total_timesteps      | 1212416      |
| train/                  |              |
|    approx_kl            | 0.0040064417 |
|    clip_fraction        | 0.0435       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.32        |
|    explained_variance   | -0.549       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0216      |
|    n_updates            | 1176         |
|    policy_gradient_loss | -0.000249    |
|    std                  | 0.903        |
|    value_loss           | 3.48e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 823          |
|    iterations           | 149          |
|    time_elapsed         | 1482         |
|    total_timesteps      | 1220608      |
| train/                  |              |
|    approx_kl            | 0.0038418616 |
|    clip_fraction        | 0.0366       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.32        |
|    explained_variance   | -0.384       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0273      |
|    n_updates            | 1184         |
|    policy_gradient_loss | 0.00117      |
|    std                  | 0.903        |
|    value_loss           | 4.15e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 826          |
|    iterations           | 150          |
|    time_elapsed         | 1486         |
|    total_timesteps      | 1228800      |
| train/                  |              |
|    approx_kl            | 0.0033691786 |
|    clip_fraction        | 0.0319       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.32        |
|    explained_variance   | -0.355       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0262      |
|    n_updates            | 1192         |
|    policy_gradient_loss | -0.000372    |
|    std                  | 0.904        |
|    value_loss           | 4.67e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 829          |
|    iterations           | 151          |
|    time_elapsed         | 1490         |
|    total_timesteps      | 1236992      |
| train/                  |              |
|    approx_kl            | 0.0041550756 |
|    clip_fraction        | 0.0371       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.32        |
|    explained_variance   | -0.4         |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0242      |
|    n_updates            | 1200         |
|    policy_gradient_loss | 0.000287     |
|    std                  | 0.905        |
|    value_loss           | 4.46e-05     |
------------------------------------------
Eval num_timesteps=1240000, episode_reward=-0.04 +/- 0.08
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | -0.0365      |
| time/                   |              |
|    total_timesteps      | 1240000      |
| train/                  |              |
|    approx_kl            | 0.0031148007 |
|    clip_fraction        | 0.037        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.32        |
|    explained_variance   | -0.392       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0278      |
|    n_updates            | 1208         |
|    policy_gradient_loss | -0.000295    |
|    std                  | 0.904        |
|    value_loss           | 3.72e-05     |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 822     |
|    iterations      | 152     |
|    time_elapsed    | 1514    |
|    total_timesteps | 1245184 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 825         |
|    iterations           | 153         |
|    time_elapsed         | 1518        |
|    total_timesteps      | 1253376     |
| train/                  |             |
|    approx_kl            | 0.003297667 |
|    clip_fraction        | 0.0374      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.32       |
|    explained_variance   | -0.327      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0264     |
|    n_updates            | 1216        |
|    policy_gradient_loss | 0.000282    |
|    std                  | 0.903       |
|    value_loss           | 3.98e-05    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 828          |
|    iterations           | 154          |
|    time_elapsed         | 1522         |
|    total_timesteps      | 1261568      |
| train/                  |              |
|    approx_kl            | 0.0036208774 |
|    clip_fraction        | 0.035        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.32        |
|    explained_variance   | -0.275       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0259      |
|    n_updates            | 1224         |
|    policy_gradient_loss | 0.000551     |
|    std                  | 0.903        |
|    value_loss           | 4.97e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 831          |
|    iterations           | 155          |
|    time_elapsed         | 1526         |
|    total_timesteps      | 1269760      |
| train/                  |              |
|    approx_kl            | 0.0030284082 |
|    clip_fraction        | 0.033        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.32        |
|    explained_variance   | -0.502       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0266      |
|    n_updates            | 1232         |
|    policy_gradient_loss | 0.000165     |
|    std                  | 0.903        |
|    value_loss           | 3.07e-05     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 835         |
|    iterations           | 156         |
|    time_elapsed         | 1530        |
|    total_timesteps      | 1277952     |
| train/                  |             |
|    approx_kl            | 0.003580032 |
|    clip_fraction        | 0.0317      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.32       |
|    explained_variance   | -0.396      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0279     |
|    n_updates            | 1240        |
|    policy_gradient_loss | -0.000508   |
|    std                  | 0.902       |
|    value_loss           | 3.45e-05    |
-----------------------------------------
Eval num_timesteps=1280000, episode_reward=-0.06 +/- 0.09
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | -0.0579      |
| time/                   |              |
|    total_timesteps      | 1280000      |
| train/                  |              |
|    approx_kl            | 0.0032989592 |
|    clip_fraction        | 0.042        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.32        |
|    explained_variance   | -0.573       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0291      |
|    n_updates            | 1248         |
|    policy_gradient_loss | -0.000644    |
|    std                  | 0.901        |
|    value_loss           | 2.66e-05     |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 827     |
|    iterations      | 157     |
|    time_elapsed    | 1554    |
|    total_timesteps | 1286144 |
--------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 830          |
|    iterations           | 158          |
|    time_elapsed         | 1558         |
|    total_timesteps      | 1294336      |
| train/                  |              |
|    approx_kl            | 0.0035255512 |
|    clip_fraction        | 0.0355       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.31        |
|    explained_variance   | -0.276       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0325      |
|    n_updates            | 1256         |
|    policy_gradient_loss | -0.00123     |
|    std                  | 0.901        |
|    value_loss           | 4.5e-05      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 833          |
|    iterations           | 159          |
|    time_elapsed         | 1562         |
|    total_timesteps      | 1302528      |
| train/                  |              |
|    approx_kl            | 0.0033837114 |
|    clip_fraction        | 0.0291       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.32        |
|    explained_variance   | -0.468       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0269      |
|    n_updates            | 1264         |
|    policy_gradient_loss | -0.000147    |
|    std                  | 0.901        |
|    value_loss           | 2.95e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 836          |
|    iterations           | 160          |
|    time_elapsed         | 1566         |
|    total_timesteps      | 1310720      |
| train/                  |              |
|    approx_kl            | 0.0033242053 |
|    clip_fraction        | 0.0398       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.32        |
|    explained_variance   | -0.509       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0298      |
|    n_updates            | 1272         |
|    policy_gradient_loss | -0.00117     |
|    std                  | 0.901        |
|    value_loss           | 2.93e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 839          |
|    iterations           | 161          |
|    time_elapsed         | 1570         |
|    total_timesteps      | 1318912      |
| train/                  |              |
|    approx_kl            | 0.0033196472 |
|    clip_fraction        | 0.032        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.32        |
|    explained_variance   | -0.321       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0267      |
|    n_updates            | 1280         |
|    policy_gradient_loss | -0.000406    |
|    std                  | 0.901        |
|    value_loss           | 4.13e-05     |
------------------------------------------
Eval num_timesteps=1320000, episode_reward=0.01 +/- 0.06
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | 0.00673     |
| time/                   |             |
|    total_timesteps      | 1320000     |
| train/                  |             |
|    approx_kl            | 0.003347462 |
|    clip_fraction        | 0.0309      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.32       |
|    explained_variance   | -0.277      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0255     |
|    n_updates            | 1288        |
|    policy_gradient_loss | -0.000317   |
|    std                  | 0.901       |
|    value_loss           | 4.31e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 832     |
|    iterations      | 162     |
|    time_elapsed    | 1593    |
|    total_timesteps | 1327104 |
--------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 835          |
|    iterations           | 163          |
|    time_elapsed         | 1597         |
|    total_timesteps      | 1335296      |
| train/                  |              |
|    approx_kl            | 0.0035071643 |
|    clip_fraction        | 0.0415       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.31        |
|    explained_variance   | -0.405       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0281      |
|    n_updates            | 1296         |
|    policy_gradient_loss | -0.0011      |
|    std                  | 0.9          |
|    value_loss           | 3.18e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 838          |
|    iterations           | 164          |
|    time_elapsed         | 1601         |
|    total_timesteps      | 1343488      |
| train/                  |              |
|    approx_kl            | 0.0035076048 |
|    clip_fraction        | 0.032        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.31        |
|    explained_variance   | -0.301       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.029       |
|    n_updates            | 1304         |
|    policy_gradient_loss | -0.000187    |
|    std                  | 0.9          |
|    value_loss           | 3.75e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 841          |
|    iterations           | 165          |
|    time_elapsed         | 1605         |
|    total_timesteps      | 1351680      |
| train/                  |              |
|    approx_kl            | 0.0033403316 |
|    clip_fraction        | 0.036        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.31        |
|    explained_variance   | -0.236       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.028       |
|    n_updates            | 1312         |
|    policy_gradient_loss | 0.000661     |
|    std                  | 0.901        |
|    value_loss           | 4.37e-05     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 844         |
|    iterations           | 166         |
|    time_elapsed         | 1609        |
|    total_timesteps      | 1359872     |
| train/                  |             |
|    approx_kl            | 0.003896276 |
|    clip_fraction        | 0.0371      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.32       |
|    explained_variance   | -0.282      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0261     |
|    n_updates            | 1320        |
|    policy_gradient_loss | -0.000297   |
|    std                  | 0.902       |
|    value_loss           | 3.44e-05    |
-----------------------------------------
Eval num_timesteps=1360000, episode_reward=0.01 +/- 0.08
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | 0.00605      |
| time/                   |              |
|    total_timesteps      | 1360000      |
| train/                  |              |
|    approx_kl            | 0.0030273353 |
|    clip_fraction        | 0.032        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.32        |
|    explained_variance   | -0.217       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0285      |
|    n_updates            | 1328         |
|    policy_gradient_loss | 0.000581     |
|    std                  | 0.903        |
|    value_loss           | 4.12e-05     |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 837     |
|    iterations      | 167     |
|    time_elapsed    | 1632    |
|    total_timesteps | 1368064 |
--------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 840          |
|    iterations           | 168          |
|    time_elapsed         | 1636         |
|    total_timesteps      | 1376256      |
| train/                  |              |
|    approx_kl            | 0.0034989193 |
|    clip_fraction        | 0.0334       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.32        |
|    explained_variance   | -0.36        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0297      |
|    n_updates            | 1336         |
|    policy_gradient_loss | 0.000303     |
|    std                  | 0.904        |
|    value_loss           | 2.95e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 843          |
|    iterations           | 169          |
|    time_elapsed         | 1640         |
|    total_timesteps      | 1384448      |
| train/                  |              |
|    approx_kl            | 0.0042447224 |
|    clip_fraction        | 0.0428       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.32        |
|    explained_variance   | -0.338       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0279      |
|    n_updates            | 1344         |
|    policy_gradient_loss | 0.000632     |
|    std                  | 0.903        |
|    value_loss           | 3.11e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 846          |
|    iterations           | 170          |
|    time_elapsed         | 1645         |
|    total_timesteps      | 1392640      |
| train/                  |              |
|    approx_kl            | 0.0034321651 |
|    clip_fraction        | 0.0341       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.32        |
|    explained_variance   | -0.439       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0243      |
|    n_updates            | 1352         |
|    policy_gradient_loss | 0.0002       |
|    std                  | 0.902        |
|    value_loss           | 2.68e-05     |
------------------------------------------
Eval num_timesteps=1400000, episode_reward=-0.00 +/- 0.11
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | -0.000662    |
| time/                   |              |
|    total_timesteps      | 1400000      |
| train/                  |              |
|    approx_kl            | 0.0037335341 |
|    clip_fraction        | 0.0397       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.32        |
|    explained_variance   | -0.25        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0259      |
|    n_updates            | 1360         |
|    policy_gradient_loss | -0.000795    |
|    std                  | 0.901        |
|    value_loss           | 4.19e-05     |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 839     |
|    iterations      | 171     |
|    time_elapsed    | 1668    |
|    total_timesteps | 1400832 |
--------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 842          |
|    iterations           | 172          |
|    time_elapsed         | 1672         |
|    total_timesteps      | 1409024      |
| train/                  |              |
|    approx_kl            | 0.0042219525 |
|    clip_fraction        | 0.0441       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.31        |
|    explained_variance   | -0.501       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.022       |
|    n_updates            | 1368         |
|    policy_gradient_loss | -0.000726    |
|    std                  | 0.899        |
|    value_loss           | 2.33e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 845          |
|    iterations           | 173          |
|    time_elapsed         | 1676         |
|    total_timesteps      | 1417216      |
| train/                  |              |
|    approx_kl            | 0.0028381958 |
|    clip_fraction        | 0.0343       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.31        |
|    explained_variance   | -0.305       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0231      |
|    n_updates            | 1376         |
|    policy_gradient_loss | 1.78e-05     |
|    std                  | 0.901        |
|    value_loss           | 2.99e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 848          |
|    iterations           | 174          |
|    time_elapsed         | 1680         |
|    total_timesteps      | 1425408      |
| train/                  |              |
|    approx_kl            | 0.0028782915 |
|    clip_fraction        | 0.0293       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.31        |
|    explained_variance   | -0.242       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0247      |
|    n_updates            | 1384         |
|    policy_gradient_loss | 0.000223     |
|    std                  | 0.899        |
|    value_loss           | 3.65e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 851          |
|    iterations           | 175          |
|    time_elapsed         | 1684         |
|    total_timesteps      | 1433600      |
| train/                  |              |
|    approx_kl            | 0.0028738375 |
|    clip_fraction        | 0.031        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.31        |
|    explained_variance   | -0.321       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.025       |
|    n_updates            | 1392         |
|    policy_gradient_loss | 0.000152     |
|    std                  | 0.897        |
|    value_loss           | 2.9e-05      |
------------------------------------------
Eval num_timesteps=1440000, episode_reward=-0.00 +/- 0.07
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.00327    |
| time/                   |             |
|    total_timesteps      | 1440000     |
| train/                  |             |
|    approx_kl            | 0.003026088 |
|    clip_fraction        | 0.0316      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.31       |
|    explained_variance   | -0.304      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0273     |
|    n_updates            | 1400        |
|    policy_gradient_loss | 0.000283    |
|    std                  | 0.896       |
|    value_loss           | 3.12e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 844     |
|    iterations      | 176     |
|    time_elapsed    | 1707    |
|    total_timesteps | 1441792 |
--------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 847          |
|    iterations           | 177          |
|    time_elapsed         | 1711         |
|    total_timesteps      | 1449984      |
| train/                  |              |
|    approx_kl            | 0.0032298209 |
|    clip_fraction        | 0.0399       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.31        |
|    explained_variance   | -0.285       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.028       |
|    n_updates            | 1408         |
|    policy_gradient_loss | -1.72e-05    |
|    std                  | 0.896        |
|    value_loss           | 3.36e-05     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 849         |
|    iterations           | 178         |
|    time_elapsed         | 1715        |
|    total_timesteps      | 1458176     |
| train/                  |             |
|    approx_kl            | 0.004055568 |
|    clip_fraction        | 0.0451      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.31       |
|    explained_variance   | -0.103      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0268     |
|    n_updates            | 1416        |
|    policy_gradient_loss | -0.000139   |
|    std                  | 0.896       |
|    value_loss           | 8.99e-05    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 852          |
|    iterations           | 179          |
|    time_elapsed         | 1719         |
|    total_timesteps      | 1466368      |
| train/                  |              |
|    approx_kl            | 0.0032568015 |
|    clip_fraction        | 0.0295       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.31        |
|    explained_variance   | -0.366       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0279      |
|    n_updates            | 1424         |
|    policy_gradient_loss | -0.000857    |
|    std                  | 0.896        |
|    value_loss           | 2.57e-05     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 855         |
|    iterations           | 180         |
|    time_elapsed         | 1723        |
|    total_timesteps      | 1474560     |
| train/                  |             |
|    approx_kl            | 0.002698449 |
|    clip_fraction        | 0.0275      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.31       |
|    explained_variance   | -0.171      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0297     |
|    n_updates            | 1432        |
|    policy_gradient_loss | -8.86e-05   |
|    std                  | 0.897       |
|    value_loss           | 4.74e-05    |
-----------------------------------------
Eval num_timesteps=1480000, episode_reward=0.05 +/- 0.07
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | 0.0451       |
| time/                   |              |
|    total_timesteps      | 1480000      |
| train/                  |              |
|    approx_kl            | 0.0041885776 |
|    clip_fraction        | 0.0347       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.31        |
|    explained_variance   | -0.11        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0286      |
|    n_updates            | 1440         |
|    policy_gradient_loss | -3.43e-05    |
|    std                  | 0.898        |
|    value_loss           | 6.02e-05     |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 848     |
|    iterations      | 181     |
|    time_elapsed    | 1747    |
|    total_timesteps | 1482752 |
--------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 851          |
|    iterations           | 182          |
|    time_elapsed         | 1751         |
|    total_timesteps      | 1490944      |
| train/                  |              |
|    approx_kl            | 0.0037882756 |
|    clip_fraction        | 0.0334       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.31        |
|    explained_variance   | -0.155       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0247      |
|    n_updates            | 1448         |
|    policy_gradient_loss | -0.00132     |
|    std                  | 0.898        |
|    value_loss           | 4e-05        |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 853         |
|    iterations           | 183         |
|    time_elapsed         | 1755        |
|    total_timesteps      | 1499136     |
| train/                  |             |
|    approx_kl            | 0.005164926 |
|    clip_fraction        | 0.0552      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.31       |
|    explained_variance   | -0.236      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0257     |
|    n_updates            | 1456        |
|    policy_gradient_loss | -0.000263   |
|    std                  | 0.899       |
|    value_loss           | 4.01e-05    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 856          |
|    iterations           | 184          |
|    time_elapsed         | 1759         |
|    total_timesteps      | 1507328      |
| train/                  |              |
|    approx_kl            | 0.0031865416 |
|    clip_fraction        | 0.0363       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.31        |
|    explained_variance   | -0.456       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0267      |
|    n_updates            | 1464         |
|    policy_gradient_loss | -0.000495    |
|    std                  | 0.9          |
|    value_loss           | 2.17e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 859          |
|    iterations           | 185          |
|    time_elapsed         | 1763         |
|    total_timesteps      | 1515520      |
| train/                  |              |
|    approx_kl            | 0.0044281944 |
|    clip_fraction        | 0.0506       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.31        |
|    explained_variance   | -0.217       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0267      |
|    n_updates            | 1472         |
|    policy_gradient_loss | -0.000347    |
|    std                  | 0.9          |
|    value_loss           | 3.72e-05     |
------------------------------------------
Eval num_timesteps=1520000, episode_reward=0.02 +/- 0.09
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | 0.0225       |
| time/                   |              |
|    total_timesteps      | 1520000      |
| train/                  |              |
|    approx_kl            | 0.0032806438 |
|    clip_fraction        | 0.0332       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.31        |
|    explained_variance   | -0.329       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0313      |
|    n_updates            | 1480         |
|    policy_gradient_loss | 0.000133     |
|    std                  | 0.902        |
|    value_loss           | 2.81e-05     |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 852     |
|    iterations      | 186     |
|    time_elapsed    | 1787    |
|    total_timesteps | 1523712 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 855         |
|    iterations           | 187         |
|    time_elapsed         | 1791        |
|    total_timesteps      | 1531904     |
| train/                  |             |
|    approx_kl            | 0.003368987 |
|    clip_fraction        | 0.0359      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.32       |
|    explained_variance   | -0.154      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0265     |
|    n_updates            | 1488        |
|    policy_gradient_loss | 0.000845    |
|    std                  | 0.903       |
|    value_loss           | 5.17e-05    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 857          |
|    iterations           | 188          |
|    time_elapsed         | 1795         |
|    total_timesteps      | 1540096      |
| train/                  |              |
|    approx_kl            | 0.0036487982 |
|    clip_fraction        | 0.0417       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.32        |
|    explained_variance   | -0.174       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0294      |
|    n_updates            | 1496         |
|    policy_gradient_loss | 0.000258     |
|    std                  | 0.904        |
|    value_loss           | 4.58e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 860          |
|    iterations           | 189          |
|    time_elapsed         | 1799         |
|    total_timesteps      | 1548288      |
| train/                  |              |
|    approx_kl            | 0.0036205566 |
|    clip_fraction        | 0.0358       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.32        |
|    explained_variance   | -0.315       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0254      |
|    n_updates            | 1504         |
|    policy_gradient_loss | -0.000459    |
|    std                  | 0.903        |
|    value_loss           | 2.84e-05     |
------------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 863        |
|    iterations           | 190        |
|    time_elapsed         | 1803       |
|    total_timesteps      | 1556480    |
| train/                  |            |
|    approx_kl            | 0.00361089 |
|    clip_fraction        | 0.0415     |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.32      |
|    explained_variance   | -0.179     |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0292    |
|    n_updates            | 1512       |
|    policy_gradient_loss | -0.00133   |
|    std                  | 0.903      |
|    value_loss           | 3.88e-05   |
----------------------------------------
Eval num_timesteps=1560000, episode_reward=0.02 +/- 0.08
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | 0.0242      |
| time/                   |             |
|    total_timesteps      | 1560000     |
| train/                  |             |
|    approx_kl            | 0.003059479 |
|    clip_fraction        | 0.0273      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.32       |
|    explained_variance   | -0.244      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.027      |
|    n_updates            | 1520        |
|    policy_gradient_loss | -0.000471   |
|    std                  | 0.903       |
|    value_loss           | 3.12e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 856     |
|    iterations      | 191     |
|    time_elapsed    | 1826    |
|    total_timesteps | 1564672 |
--------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 859          |
|    iterations           | 192          |
|    time_elapsed         | 1830         |
|    total_timesteps      | 1572864      |
| train/                  |              |
|    approx_kl            | 0.0034201401 |
|    clip_fraction        | 0.0346       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.32        |
|    explained_variance   | -0.167       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0272      |
|    n_updates            | 1528         |
|    policy_gradient_loss | 0.00116      |
|    std                  | 0.903        |
|    value_loss           | 4e-05        |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 861          |
|    iterations           | 193          |
|    time_elapsed         | 1834         |
|    total_timesteps      | 1581056      |
| train/                  |              |
|    approx_kl            | 0.0033408594 |
|    clip_fraction        | 0.0328       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.32        |
|    explained_variance   | -0.329       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0259      |
|    n_updates            | 1536         |
|    policy_gradient_loss | -0.00029     |
|    std                  | 0.903        |
|    value_loss           | 2.37e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 864          |
|    iterations           | 194          |
|    time_elapsed         | 1838         |
|    total_timesteps      | 1589248      |
| train/                  |              |
|    approx_kl            | 0.0036702738 |
|    clip_fraction        | 0.0366       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.32        |
|    explained_variance   | -0.165       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0251      |
|    n_updates            | 1544         |
|    policy_gradient_loss | -0.000341    |
|    std                  | 0.903        |
|    value_loss           | 3.89e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 866          |
|    iterations           | 195          |
|    time_elapsed         | 1842         |
|    total_timesteps      | 1597440      |
| train/                  |              |
|    approx_kl            | 0.0033251827 |
|    clip_fraction        | 0.0326       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.32        |
|    explained_variance   | -0.35        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0277      |
|    n_updates            | 1552         |
|    policy_gradient_loss | 0.00011      |
|    std                  | 0.903        |
|    value_loss           | 1.99e-05     |
------------------------------------------
Eval num_timesteps=1600000, episode_reward=-0.03 +/- 0.10
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.0326     |
| time/                   |             |
|    total_timesteps      | 1600000     |
| train/                  |             |
|    approx_kl            | 0.003226112 |
|    clip_fraction        | 0.0387      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.32       |
|    explained_variance   | -0.205      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0327     |
|    n_updates            | 1560        |
|    policy_gradient_loss | -0.000348   |
|    std                  | 0.904       |
|    value_loss           | 2.87e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 860     |
|    iterations      | 196     |
|    time_elapsed    | 1866    |
|    total_timesteps | 1605632 |
--------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 862          |
|    iterations           | 197          |
|    time_elapsed         | 1870         |
|    total_timesteps      | 1613824      |
| train/                  |              |
|    approx_kl            | 0.0035958583 |
|    clip_fraction        | 0.0356       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.32        |
|    explained_variance   | -0.273       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0242      |
|    n_updates            | 1568         |
|    policy_gradient_loss | -5.03e-05    |
|    std                  | 0.904        |
|    value_loss           | 2.44e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 865          |
|    iterations           | 198          |
|    time_elapsed         | 1874         |
|    total_timesteps      | 1622016      |
| train/                  |              |
|    approx_kl            | 0.0034048557 |
|    clip_fraction        | 0.0367       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.32        |
|    explained_variance   | -0.121       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0232      |
|    n_updates            | 1576         |
|    policy_gradient_loss | 0.000117     |
|    std                  | 0.905        |
|    value_loss           | 4.7e-05      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 867          |
|    iterations           | 199          |
|    time_elapsed         | 1878         |
|    total_timesteps      | 1630208      |
| train/                  |              |
|    approx_kl            | 0.0042284713 |
|    clip_fraction        | 0.0479       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.32        |
|    explained_variance   | -0.189       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0261      |
|    n_updates            | 1584         |
|    policy_gradient_loss | 0.000509     |
|    std                  | 0.906        |
|    value_loss           | 3.59e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 870          |
|    iterations           | 200          |
|    time_elapsed         | 1882         |
|    total_timesteps      | 1638400      |
| train/                  |              |
|    approx_kl            | 0.0031710914 |
|    clip_fraction        | 0.035        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.32        |
|    explained_variance   | -0.186       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0287      |
|    n_updates            | 1592         |
|    policy_gradient_loss | 0.000799     |
|    std                  | 0.908        |
|    value_loss           | 3.28e-05     |
------------------------------------------
Eval num_timesteps=1640000, episode_reward=-0.04 +/- 0.06
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.0384     |
| time/                   |             |
|    total_timesteps      | 1640000     |
| train/                  |             |
|    approx_kl            | 0.003509189 |
|    clip_fraction        | 0.0364      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.32       |
|    explained_variance   | -0.177      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0262     |
|    n_updates            | 1600        |
|    policy_gradient_loss | 0.00041     |
|    std                  | 0.908       |
|    value_loss           | 3.67e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 863     |
|    iterations      | 201     |
|    time_elapsed    | 1906    |
|    total_timesteps | 1646592 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 866         |
|    iterations           | 202         |
|    time_elapsed         | 1910        |
|    total_timesteps      | 1654784     |
| train/                  |             |
|    approx_kl            | 0.004097823 |
|    clip_fraction        | 0.0394      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.32       |
|    explained_variance   | -0.467      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0299     |
|    n_updates            | 1608        |
|    policy_gradient_loss | 0.000332    |
|    std                  | 0.906       |
|    value_loss           | 1.68e-05    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 868          |
|    iterations           | 203          |
|    time_elapsed         | 1914         |
|    total_timesteps      | 1662976      |
| train/                  |              |
|    approx_kl            | 0.0038518272 |
|    clip_fraction        | 0.0419       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.32        |
|    explained_variance   | -0.304       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.03        |
|    n_updates            | 1616         |
|    policy_gradient_loss | -0.000112    |
|    std                  | 0.904        |
|    value_loss           | 1.96e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 871          |
|    iterations           | 204          |
|    time_elapsed         | 1918         |
|    total_timesteps      | 1671168      |
| train/                  |              |
|    approx_kl            | 0.0048196223 |
|    clip_fraction        | 0.0537       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.32        |
|    explained_variance   | -0.15        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0323      |
|    n_updates            | 1624         |
|    policy_gradient_loss | -4.04e-05    |
|    std                  | 0.905        |
|    value_loss           | 3.52e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 873          |
|    iterations           | 205          |
|    time_elapsed         | 1922         |
|    total_timesteps      | 1679360      |
| train/                  |              |
|    approx_kl            | 0.0047337213 |
|    clip_fraction        | 0.0585       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.32        |
|    explained_variance   | -0.202       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0255      |
|    n_updates            | 1632         |
|    policy_gradient_loss | -0.000127    |
|    std                  | 0.904        |
|    value_loss           | 2.97e-05     |
------------------------------------------
Eval num_timesteps=1680000, episode_reward=-0.02 +/- 0.06
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.0239     |
| time/                   |             |
|    total_timesteps      | 1680000     |
| train/                  |             |
|    approx_kl            | 0.004937986 |
|    clip_fraction        | 0.0506      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.32       |
|    explained_variance   | -0.196      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0244     |
|    n_updates            | 1640        |
|    policy_gradient_loss | 0.000332    |
|    std                  | 0.906       |
|    value_loss           | 3.04e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 867     |
|    iterations      | 206     |
|    time_elapsed    | 1945    |
|    total_timesteps | 1687552 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 869         |
|    iterations           | 207         |
|    time_elapsed         | 1949        |
|    total_timesteps      | 1695744     |
| train/                  |             |
|    approx_kl            | 0.004410615 |
|    clip_fraction        | 0.0485      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.32       |
|    explained_variance   | -0.161      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0241     |
|    n_updates            | 1648        |
|    policy_gradient_loss | 0.00145     |
|    std                  | 0.904       |
|    value_loss           | 3.72e-05    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 872          |
|    iterations           | 208          |
|    time_elapsed         | 1953         |
|    total_timesteps      | 1703936      |
| train/                  |              |
|    approx_kl            | 0.0052078012 |
|    clip_fraction        | 0.0583       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.32        |
|    explained_variance   | -0.194       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0251      |
|    n_updates            | 1656         |
|    policy_gradient_loss | -0.000168    |
|    std                  | 0.905        |
|    value_loss           | 4.03e-05     |
------------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 874        |
|    iterations           | 209        |
|    time_elapsed         | 1957       |
|    total_timesteps      | 1712128    |
| train/                  |            |
|    approx_kl            | 0.00328477 |
|    clip_fraction        | 0.0408     |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.32      |
|    explained_variance   | -0.116     |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0217    |
|    n_updates            | 1664       |
|    policy_gradient_loss | 0.00171    |
|    std                  | 0.905      |
|    value_loss           | 4.71e-05   |
----------------------------------------
Eval num_timesteps=1720000, episode_reward=0.02 +/- 0.05
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | 0.0202       |
| time/                   |              |
|    total_timesteps      | 1720000      |
| train/                  |              |
|    approx_kl            | 0.0044588884 |
|    clip_fraction        | 0.0425       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.32        |
|    explained_variance   | -0.318       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0272      |
|    n_updates            | 1672         |
|    policy_gradient_loss | 0.000583     |
|    std                  | 0.905        |
|    value_loss           | 1.9e-05      |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 868     |
|    iterations      | 210     |
|    time_elapsed    | 1981    |
|    total_timesteps | 1720320 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 870         |
|    iterations           | 211         |
|    time_elapsed         | 1985        |
|    total_timesteps      | 1728512     |
| train/                  |             |
|    approx_kl            | 0.004216577 |
|    clip_fraction        | 0.0415      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.32       |
|    explained_variance   | -0.121      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0295     |
|    n_updates            | 1680        |
|    policy_gradient_loss | 0.000317    |
|    std                  | 0.905       |
|    value_loss           | 4.62e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 873         |
|    iterations           | 212         |
|    time_elapsed         | 1989        |
|    total_timesteps      | 1736704     |
| train/                  |             |
|    approx_kl            | 0.003219042 |
|    clip_fraction        | 0.0347      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.32       |
|    explained_variance   | -0.115      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0246     |
|    n_updates            | 1688        |
|    policy_gradient_loss | 0.00073     |
|    std                  | 0.905       |
|    value_loss           | 5.01e-05    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 875          |
|    iterations           | 213          |
|    time_elapsed         | 1993         |
|    total_timesteps      | 1744896      |
| train/                  |              |
|    approx_kl            | 0.0025562607 |
|    clip_fraction        | 0.0261       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.32        |
|    explained_variance   | -0.133       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0295      |
|    n_updates            | 1696         |
|    policy_gradient_loss | 0.000418     |
|    std                  | 0.906        |
|    value_loss           | 4.33e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 877          |
|    iterations           | 214          |
|    time_elapsed         | 1997         |
|    total_timesteps      | 1753088      |
| train/                  |              |
|    approx_kl            | 0.0028016707 |
|    clip_fraction        | 0.0298       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.32        |
|    explained_variance   | -0.219       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0245      |
|    n_updates            | 1704         |
|    policy_gradient_loss | 0.000464     |
|    std                  | 0.907        |
|    value_loss           | 2.67e-05     |
------------------------------------------
Eval num_timesteps=1760000, episode_reward=-0.02 +/- 0.07
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.0242     |
| time/                   |             |
|    total_timesteps      | 1760000     |
| train/                  |             |
|    approx_kl            | 0.003400961 |
|    clip_fraction        | 0.0337      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.32       |
|    explained_variance   | -0.171      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0292     |
|    n_updates            | 1712        |
|    policy_gradient_loss | 0.000325    |
|    std                  | 0.906       |
|    value_loss           | 2.66e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 871     |
|    iterations      | 215     |
|    time_elapsed    | 2020    |
|    total_timesteps | 1761280 |
--------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 873          |
|    iterations           | 216          |
|    time_elapsed         | 2025         |
|    total_timesteps      | 1769472      |
| train/                  |              |
|    approx_kl            | 0.0036839023 |
|    clip_fraction        | 0.0382       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.32        |
|    explained_variance   | -0.143       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.025       |
|    n_updates            | 1720         |
|    policy_gradient_loss | 0.000889     |
|    std                  | 0.906        |
|    value_loss           | 3.24e-05     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 875         |
|    iterations           | 217         |
|    time_elapsed         | 2031        |
|    total_timesteps      | 1777664     |
| train/                  |             |
|    approx_kl            | 0.003908183 |
|    clip_fraction        | 0.039       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.32       |
|    explained_variance   | -0.0619     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0252     |
|    n_updates            | 1728        |
|    policy_gradient_loss | 0.000807    |
|    std                  | 0.907       |
|    value_loss           | 6.36e-05    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 876          |
|    iterations           | 218          |
|    time_elapsed         | 2037         |
|    total_timesteps      | 1785856      |
| train/                  |              |
|    approx_kl            | 0.0033991556 |
|    clip_fraction        | 0.0363       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.32        |
|    explained_variance   | -0.242       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0284      |
|    n_updates            | 1736         |
|    policy_gradient_loss | 0.000191     |
|    std                  | 0.908        |
|    value_loss           | 2.16e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 878          |
|    iterations           | 219          |
|    time_elapsed         | 2042         |
|    total_timesteps      | 1794048      |
| train/                  |              |
|    approx_kl            | 0.0042466745 |
|    clip_fraction        | 0.047        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.32        |
|    explained_variance   | -0.15        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0261      |
|    n_updates            | 1744         |
|    policy_gradient_loss | 0.00042      |
|    std                  | 0.907        |
|    value_loss           | 3.58e-05     |
------------------------------------------
Eval num_timesteps=1800000, episode_reward=-0.03 +/- 0.05
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.0295     |
| time/                   |             |
|    total_timesteps      | 1800000     |
| train/                  |             |
|    approx_kl            | 0.003944876 |
|    clip_fraction        | 0.0435      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.32       |
|    explained_variance   | -0.138      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0296     |
|    n_updates            | 1752        |
|    policy_gradient_loss | -0.000327   |
|    std                  | 0.908       |
|    value_loss           | 3.59e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 869     |
|    iterations      | 220     |
|    time_elapsed    | 2073    |
|    total_timesteps | 1802240 |
--------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 870          |
|    iterations           | 221          |
|    time_elapsed         | 2079         |
|    total_timesteps      | 1810432      |
| train/                  |              |
|    approx_kl            | 0.0036435504 |
|    clip_fraction        | 0.0429       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.32        |
|    explained_variance   | -0.228       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0244      |
|    n_updates            | 1760         |
|    policy_gradient_loss | -0.000153    |
|    std                  | 0.909        |
|    value_loss           | 2.4e-05      |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 872         |
|    iterations           | 222         |
|    time_elapsed         | 2085        |
|    total_timesteps      | 1818624     |
| train/                  |             |
|    approx_kl            | 0.003519058 |
|    clip_fraction        | 0.0399      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.32       |
|    explained_variance   | -0.148      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0279     |
|    n_updates            | 1768        |
|    policy_gradient_loss | -0.000277   |
|    std                  | 0.91        |
|    value_loss           | 3.32e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 873         |
|    iterations           | 223         |
|    time_elapsed         | 2090        |
|    total_timesteps      | 1826816     |
| train/                  |             |
|    approx_kl            | 0.004734918 |
|    clip_fraction        | 0.0559      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.32       |
|    explained_variance   | -0.189      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0264     |
|    n_updates            | 1776        |
|    policy_gradient_loss | 0.000284    |
|    std                  | 0.91        |
|    value_loss           | 2.68e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 875         |
|    iterations           | 224         |
|    time_elapsed         | 2095        |
|    total_timesteps      | 1835008     |
| train/                  |             |
|    approx_kl            | 0.003387706 |
|    clip_fraction        | 0.037       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.33       |
|    explained_variance   | -0.132      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0267     |
|    n_updates            | 1784        |
|    policy_gradient_loss | 0.000545    |
|    std                  | 0.911       |
|    value_loss           | 3.72e-05    |
-----------------------------------------
Eval num_timesteps=1840000, episode_reward=-0.07 +/- 0.10
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.0743     |
| time/                   |             |
|    total_timesteps      | 1840000     |
| train/                  |             |
|    approx_kl            | 0.004309764 |
|    clip_fraction        | 0.0463      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.33       |
|    explained_variance   | -0.18       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0304     |
|    n_updates            | 1792        |
|    policy_gradient_loss | -7.26e-05   |
|    std                  | 0.912       |
|    value_loss           | 2.28e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 869     |
|    iterations      | 225     |
|    time_elapsed    | 2120    |
|    total_timesteps | 1843200 |
--------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 871          |
|    iterations           | 226          |
|    time_elapsed         | 2125         |
|    total_timesteps      | 1851392      |
| train/                  |              |
|    approx_kl            | 0.0033893147 |
|    clip_fraction        | 0.0337       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.33        |
|    explained_variance   | -0.158       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0263      |
|    n_updates            | 1800         |
|    policy_gradient_loss | 0.000311     |
|    std                  | 0.913        |
|    value_loss           | 2.68e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 873          |
|    iterations           | 227          |
|    time_elapsed         | 2129         |
|    total_timesteps      | 1859584      |
| train/                  |              |
|    approx_kl            | 0.0034713866 |
|    clip_fraction        | 0.0334       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.33        |
|    explained_variance   | -0.146       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0245      |
|    n_updates            | 1808         |
|    policy_gradient_loss | 0.000311     |
|    std                  | 0.914        |
|    value_loss           | 3.26e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 875          |
|    iterations           | 228          |
|    time_elapsed         | 2133         |
|    total_timesteps      | 1867776      |
| train/                  |              |
|    approx_kl            | 0.0041498714 |
|    clip_fraction        | 0.0408       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.33        |
|    explained_variance   | -0.147       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0265      |
|    n_updates            | 1816         |
|    policy_gradient_loss | 0.000389     |
|    std                  | 0.915        |
|    value_loss           | 3.04e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 877          |
|    iterations           | 229          |
|    time_elapsed         | 2138         |
|    total_timesteps      | 1875968      |
| train/                  |              |
|    approx_kl            | 0.0042684204 |
|    clip_fraction        | 0.0384       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.33        |
|    explained_variance   | -0.14        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0282      |
|    n_updates            | 1824         |
|    policy_gradient_loss | -0.000256    |
|    std                  | 0.916        |
|    value_loss           | 3.56e-05     |
------------------------------------------
Eval num_timesteps=1880000, episode_reward=0.02 +/- 0.08
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | 0.0182       |
| time/                   |              |
|    total_timesteps      | 1880000      |
| train/                  |              |
|    approx_kl            | 0.0035491644 |
|    clip_fraction        | 0.0408       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.33        |
|    explained_variance   | -0.193       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0255      |
|    n_updates            | 1832         |
|    policy_gradient_loss | 0.000822     |
|    std                  | 0.918        |
|    value_loss           | 2.25e-05     |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 870     |
|    iterations      | 230     |
|    time_elapsed    | 2163    |
|    total_timesteps | 1884160 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 872         |
|    iterations           | 231         |
|    time_elapsed         | 2168        |
|    total_timesteps      | 1892352     |
| train/                  |             |
|    approx_kl            | 0.004434829 |
|    clip_fraction        | 0.0428      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.33       |
|    explained_variance   | -0.113      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0277     |
|    n_updates            | 1840        |
|    policy_gradient_loss | 0.000962    |
|    std                  | 0.918       |
|    value_loss           | 3.24e-05    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 874          |
|    iterations           | 232          |
|    time_elapsed         | 2172         |
|    total_timesteps      | 1900544      |
| train/                  |              |
|    approx_kl            | 0.0064107077 |
|    clip_fraction        | 0.0578       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.33        |
|    explained_variance   | -0.0434      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0259      |
|    n_updates            | 1848         |
|    policy_gradient_loss | -0.000593    |
|    std                  | 0.918        |
|    value_loss           | 5.15e-05     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 876         |
|    iterations           | 233         |
|    time_elapsed         | 2177        |
|    total_timesteps      | 1908736     |
| train/                  |             |
|    approx_kl            | 0.004637741 |
|    clip_fraction        | 0.057       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.33       |
|    explained_variance   | -0.228      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0261     |
|    n_updates            | 1856        |
|    policy_gradient_loss | 0.000118    |
|    std                  | 0.918       |
|    value_loss           | 2.17e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 878         |
|    iterations           | 234         |
|    time_elapsed         | 2182        |
|    total_timesteps      | 1916928     |
| train/                  |             |
|    approx_kl            | 0.004073329 |
|    clip_fraction        | 0.0446      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.33       |
|    explained_variance   | -0.147      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0284     |
|    n_updates            | 1864        |
|    policy_gradient_loss | 0.000575    |
|    std                  | 0.919       |
|    value_loss           | 2.61e-05    |
-----------------------------------------
Eval num_timesteps=1920000, episode_reward=-0.01 +/- 0.12
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | -0.00609     |
| time/                   |              |
|    total_timesteps      | 1920000      |
| train/                  |              |
|    approx_kl            | 0.0041477676 |
|    clip_fraction        | 0.0482       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.33        |
|    explained_variance   | -0.162       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0282      |
|    n_updates            | 1872         |
|    policy_gradient_loss | 0.00162      |
|    std                  | 0.919        |
|    value_loss           | 2.25e-05     |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 871     |
|    iterations      | 235     |
|    time_elapsed    | 2208    |
|    total_timesteps | 1925120 |
--------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 873          |
|    iterations           | 236          |
|    time_elapsed         | 2213         |
|    total_timesteps      | 1933312      |
| train/                  |              |
|    approx_kl            | 0.0050181355 |
|    clip_fraction        | 0.061        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.34        |
|    explained_variance   | -0.116       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0291      |
|    n_updates            | 1880         |
|    policy_gradient_loss | 0.00131      |
|    std                  | 0.92         |
|    value_loss           | 2.83e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 875          |
|    iterations           | 237          |
|    time_elapsed         | 2217         |
|    total_timesteps      | 1941504      |
| train/                  |              |
|    approx_kl            | 0.0052982466 |
|    clip_fraction        | 0.0596       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.34        |
|    explained_variance   | -0.173       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0268      |
|    n_updates            | 1888         |
|    policy_gradient_loss | 0.00174      |
|    std                  | 0.92         |
|    value_loss           | 2.39e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 877          |
|    iterations           | 238          |
|    time_elapsed         | 2222         |
|    total_timesteps      | 1949696      |
| train/                  |              |
|    approx_kl            | 0.0055222316 |
|    clip_fraction        | 0.0602       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.34        |
|    explained_variance   | -0.15        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0297      |
|    n_updates            | 1896         |
|    policy_gradient_loss | 0.000168     |
|    std                  | 0.92         |
|    value_loss           | 2.75e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 878          |
|    iterations           | 239          |
|    time_elapsed         | 2227         |
|    total_timesteps      | 1957888      |
| train/                  |              |
|    approx_kl            | 0.0058682286 |
|    clip_fraction        | 0.065        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.34        |
|    explained_variance   | -0.096       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0221      |
|    n_updates            | 1904         |
|    policy_gradient_loss | 0.00144      |
|    std                  | 0.919        |
|    value_loss           | 3.68e-05     |
------------------------------------------
Eval num_timesteps=1960000, episode_reward=-0.04 +/- 0.07
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.0406     |
| time/                   |             |
|    total_timesteps      | 1960000     |
| train/                  |             |
|    approx_kl            | 0.005696168 |
|    clip_fraction        | 0.0574      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.34       |
|    explained_variance   | -0.169      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0218     |
|    n_updates            | 1912        |
|    policy_gradient_loss | 0.000467    |
|    std                  | 0.921       |
|    value_loss           | 2.08e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 872     |
|    iterations      | 240     |
|    time_elapsed    | 2253    |
|    total_timesteps | 1966080 |
--------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 874          |
|    iterations           | 241          |
|    time_elapsed         | 2258         |
|    total_timesteps      | 1974272      |
| train/                  |              |
|    approx_kl            | 0.0050092307 |
|    clip_fraction        | 0.0642       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.34        |
|    explained_variance   | -0.137       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.028       |
|    n_updates            | 1920         |
|    policy_gradient_loss | 0.000314     |
|    std                  | 0.92         |
|    value_loss           | 2.3e-05      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 876          |
|    iterations           | 242          |
|    time_elapsed         | 2262         |
|    total_timesteps      | 1982464      |
| train/                  |              |
|    approx_kl            | 0.0047613247 |
|    clip_fraction        | 0.0591       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.34        |
|    explained_variance   | -0.201       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0261      |
|    n_updates            | 1928         |
|    policy_gradient_loss | 0.00105      |
|    std                  | 0.92         |
|    value_loss           | 2.26e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 877          |
|    iterations           | 243          |
|    time_elapsed         | 2268         |
|    total_timesteps      | 1990656      |
| train/                  |              |
|    approx_kl            | 0.0048284982 |
|    clip_fraction        | 0.0522       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.34        |
|    explained_variance   | -0.121       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0291      |
|    n_updates            | 1936         |
|    policy_gradient_loss | 0.000776     |
|    std                  | 0.921        |
|    value_loss           | 3.6e-05      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 879          |
|    iterations           | 244          |
|    time_elapsed         | 2273         |
|    total_timesteps      | 1998848      |
| train/                  |              |
|    approx_kl            | 0.0051338198 |
|    clip_fraction        | 0.0633       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.34        |
|    explained_variance   | -0.14        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0272      |
|    n_updates            | 1944         |
|    policy_gradient_loss | 0.00181      |
|    std                  | 0.919        |
|    value_loss           | 2.81e-05     |
------------------------------------------
Eval num_timesteps=2000000, episode_reward=-0.02 +/- 0.07
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | -0.0226      |
| time/                   |              |
|    total_timesteps      | 2000000      |
| train/                  |              |
|    approx_kl            | 0.0051996745 |
|    clip_fraction        | 0.0556       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.33        |
|    explained_variance   | -0.0841      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0275      |
|    n_updates            | 1952         |
|    policy_gradient_loss | 0.000499     |
|    std                  | 0.919        |
|    value_loss           | 4.69e-05     |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 871     |
|    iterations      | 245     |
|    time_elapsed    | 2303    |
|    total_timesteps | 2007040 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 872         |
|    iterations           | 246         |
|    time_elapsed         | 2308        |
|    total_timesteps      | 2015232     |
| train/                  |             |
|    approx_kl            | 0.004861407 |
|    clip_fraction        | 0.0533      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.33       |
|    explained_variance   | -0.0651     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0216     |
|    n_updates            | 1960        |
|    policy_gradient_loss | 0.000686    |
|    std                  | 0.919       |
|    value_loss           | 4.71e-05    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 874          |
|    iterations           | 247          |
|    time_elapsed         | 2314         |
|    total_timesteps      | 2023424      |
| train/                  |              |
|    approx_kl            | 0.0044827666 |
|    clip_fraction        | 0.0482       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.33        |
|    explained_variance   | -0.157       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0286      |
|    n_updates            | 1968         |
|    policy_gradient_loss | 0.000269     |
|    std                  | 0.918        |
|    value_loss           | 2.62e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 875          |
|    iterations           | 248          |
|    time_elapsed         | 2319         |
|    total_timesteps      | 2031616      |
| train/                  |              |
|    approx_kl            | 0.0051805205 |
|    clip_fraction        | 0.0597       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.33        |
|    explained_variance   | -0.115       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0308      |
|    n_updates            | 1976         |
|    policy_gradient_loss | 0.000502     |
|    std                  | 0.917        |
|    value_loss           | 2.63e-05     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 877         |
|    iterations           | 249         |
|    time_elapsed         | 2324        |
|    total_timesteps      | 2039808     |
| train/                  |             |
|    approx_kl            | 0.005339289 |
|    clip_fraction        | 0.0664      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.33       |
|    explained_variance   | -0.056      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0198     |
|    n_updates            | 1984        |
|    policy_gradient_loss | 0.00182     |
|    std                  | 0.918       |
|    value_loss           | 4.9e-05     |
-----------------------------------------
Eval num_timesteps=2040000, episode_reward=-0.02 +/- 0.06
Episode length: 2340.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 2.34e+03   |
|    mean_reward          | -0.0177    |
| time/                   |            |
|    total_timesteps      | 2040000    |
| train/                  |            |
|    approx_kl            | 0.00544665 |
|    clip_fraction        | 0.0687     |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.33      |
|    explained_variance   | -0.0708    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.029     |
|    n_updates            | 1992       |
|    policy_gradient_loss | 0.000747   |
|    std                  | 0.919      |
|    value_loss           | 4.48e-05   |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 870     |
|    iterations      | 250     |
|    time_elapsed    | 2352    |
|    total_timesteps | 2048000 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 872         |
|    iterations           | 251         |
|    time_elapsed         | 2357        |
|    total_timesteps      | 2056192     |
| train/                  |             |
|    approx_kl            | 0.005499349 |
|    clip_fraction        | 0.0671      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.33       |
|    explained_variance   | -0.058      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0256     |
|    n_updates            | 2000        |
|    policy_gradient_loss | 0.00137     |
|    std                  | 0.919       |
|    value_loss           | 4.59e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 873         |
|    iterations           | 252         |
|    time_elapsed         | 2362        |
|    total_timesteps      | 2064384     |
| train/                  |             |
|    approx_kl            | 0.005643201 |
|    clip_fraction        | 0.0677      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.34       |
|    explained_variance   | -0.0965     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0284     |
|    n_updates            | 2008        |
|    policy_gradient_loss | -0.000627   |
|    std                  | 0.92        |
|    value_loss           | 3.17e-05    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 875          |
|    iterations           | 253          |
|    time_elapsed         | 2367         |
|    total_timesteps      | 2072576      |
| train/                  |              |
|    approx_kl            | 0.0045986194 |
|    clip_fraction        | 0.0576       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.34        |
|    explained_variance   | -0.0807      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0252      |
|    n_updates            | 2016         |
|    policy_gradient_loss | 0.00122      |
|    std                  | 0.919        |
|    value_loss           | 3.53e-05     |
------------------------------------------
Eval num_timesteps=2080000, episode_reward=0.04 +/- 0.09
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | 0.0415       |
| time/                   |              |
|    total_timesteps      | 2080000      |
| train/                  |              |
|    approx_kl            | 0.0063657854 |
|    clip_fraction        | 0.069        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.33        |
|    explained_variance   | -0.165       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0224      |
|    n_updates            | 2024         |
|    policy_gradient_loss | 0.000257     |
|    std                  | 0.92         |
|    value_loss           | 2.23e-05     |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 868     |
|    iterations      | 254     |
|    time_elapsed    | 2395    |
|    total_timesteps | 2080768 |
--------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 870          |
|    iterations           | 255          |
|    time_elapsed         | 2399         |
|    total_timesteps      | 2088960      |
| train/                  |              |
|    approx_kl            | 0.0052031707 |
|    clip_fraction        | 0.0565       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.33        |
|    explained_variance   | -0.0849      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0281      |
|    n_updates            | 2032         |
|    policy_gradient_loss | 0.000869     |
|    std                  | 0.919        |
|    value_loss           | 3.98e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 872          |
|    iterations           | 256          |
|    time_elapsed         | 2404         |
|    total_timesteps      | 2097152      |
| train/                  |              |
|    approx_kl            | 0.0052503217 |
|    clip_fraction        | 0.0588       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.33        |
|    explained_variance   | -0.071       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0259      |
|    n_updates            | 2040         |
|    policy_gradient_loss | 0.000142     |
|    std                  | 0.919        |
|    value_loss           | 4.83e-05     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 874         |
|    iterations           | 257         |
|    time_elapsed         | 2408        |
|    total_timesteps      | 2105344     |
| train/                  |             |
|    approx_kl            | 0.005394693 |
|    clip_fraction        | 0.0648      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.33       |
|    explained_variance   | -0.175      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0309     |
|    n_updates            | 2048        |
|    policy_gradient_loss | 0.0019      |
|    std                  | 0.918       |
|    value_loss           | 2.45e-05    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 875          |
|    iterations           | 258          |
|    time_elapsed         | 2413         |
|    total_timesteps      | 2113536      |
| train/                  |              |
|    approx_kl            | 0.0056755487 |
|    clip_fraction        | 0.0692       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.33        |
|    explained_variance   | -0.037       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0266      |
|    n_updates            | 2056         |
|    policy_gradient_loss | 0.00148      |
|    std                  | 0.917        |
|    value_loss           | 8.83e-05     |
------------------------------------------
Eval num_timesteps=2120000, episode_reward=0.00 +/- 0.08
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | 0.000713    |
| time/                   |             |
|    total_timesteps      | 2120000     |
| train/                  |             |
|    approx_kl            | 0.005569066 |
|    clip_fraction        | 0.0659      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.33       |
|    explained_variance   | -0.117      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0253     |
|    n_updates            | 2064        |
|    policy_gradient_loss | 0.00167     |
|    std                  | 0.918       |
|    value_loss           | 2.81e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 869     |
|    iterations      | 259     |
|    time_elapsed    | 2439    |
|    total_timesteps | 2121728 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 871         |
|    iterations           | 260         |
|    time_elapsed         | 2443        |
|    total_timesteps      | 2129920     |
| train/                  |             |
|    approx_kl            | 0.005777882 |
|    clip_fraction        | 0.0692      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.33       |
|    explained_variance   | -0.186      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0253     |
|    n_updates            | 2072        |
|    policy_gradient_loss | 0.00247     |
|    std                  | 0.918       |
|    value_loss           | 1.9e-05     |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 873          |
|    iterations           | 261          |
|    time_elapsed         | 2448         |
|    total_timesteps      | 2138112      |
| train/                  |              |
|    approx_kl            | 0.0066198143 |
|    clip_fraction        | 0.0784       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.33        |
|    explained_variance   | -0.0715      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0189      |
|    n_updates            | 2080         |
|    policy_gradient_loss | 0.00266      |
|    std                  | 0.919        |
|    value_loss           | 4.04e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 875          |
|    iterations           | 262          |
|    time_elapsed         | 2452         |
|    total_timesteps      | 2146304      |
| train/                  |              |
|    approx_kl            | 0.0064776684 |
|    clip_fraction        | 0.0852       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.34        |
|    explained_variance   | -0.102       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0236      |
|    n_updates            | 2088         |
|    policy_gradient_loss | 0.00258      |
|    std                  | 0.92         |
|    value_loss           | 2.46e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 876          |
|    iterations           | 263          |
|    time_elapsed         | 2456         |
|    total_timesteps      | 2154496      |
| train/                  |              |
|    approx_kl            | 0.0073572323 |
|    clip_fraction        | 0.0775       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.34        |
|    explained_variance   | -0.134       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0268      |
|    n_updates            | 2096         |
|    policy_gradient_loss | 0.00249      |
|    std                  | 0.92         |
|    value_loss           | 2.45e-05     |
------------------------------------------
Eval num_timesteps=2160000, episode_reward=-0.01 +/- 0.10
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.00542    |
| time/                   |             |
|    total_timesteps      | 2160000     |
| train/                  |             |
|    approx_kl            | 0.006113432 |
|    clip_fraction        | 0.0756      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.34       |
|    explained_variance   | -0.084      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0242     |
|    n_updates            | 2104        |
|    policy_gradient_loss | 0.00267     |
|    std                  | 0.922       |
|    value_loss           | 3.61e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 870     |
|    iterations      | 264     |
|    time_elapsed    | 2484    |
|    total_timesteps | 2162688 |
--------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 872          |
|    iterations           | 265          |
|    time_elapsed         | 2489         |
|    total_timesteps      | 2170880      |
| train/                  |              |
|    approx_kl            | 0.0068382826 |
|    clip_fraction        | 0.0779       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.34        |
|    explained_variance   | -0.0753      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0273      |
|    n_updates            | 2112         |
|    policy_gradient_loss | 0.00113      |
|    std                  | 0.923        |
|    value_loss           | 3.63e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 873          |
|    iterations           | 266          |
|    time_elapsed         | 2494         |
|    total_timesteps      | 2179072      |
| train/                  |              |
|    approx_kl            | 0.0063891346 |
|    clip_fraction        | 0.08         |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.34        |
|    explained_variance   | -0.0903      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0304      |
|    n_updates            | 2120         |
|    policy_gradient_loss | 0.00228      |
|    std                  | 0.922        |
|    value_loss           | 2.99e-05     |
------------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 875        |
|    iterations           | 267        |
|    time_elapsed         | 2499       |
|    total_timesteps      | 2187264    |
| train/                  |            |
|    approx_kl            | 0.00680934 |
|    clip_fraction        | 0.0794     |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.34      |
|    explained_variance   | -0.121     |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0233    |
|    n_updates            | 2128       |
|    policy_gradient_loss | 0.00261    |
|    std                  | 0.922      |
|    value_loss           | 2.33e-05   |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 876         |
|    iterations           | 268         |
|    time_elapsed         | 2504        |
|    total_timesteps      | 2195456     |
| train/                  |             |
|    approx_kl            | 0.009004861 |
|    clip_fraction        | 0.0939      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.34       |
|    explained_variance   | -0.182      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0322     |
|    n_updates            | 2136        |
|    policy_gradient_loss | 0.000792    |
|    std                  | 0.922       |
|    value_loss           | 1.64e-05    |
-----------------------------------------
Eval num_timesteps=2200000, episode_reward=-0.03 +/- 0.07
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.0261     |
| time/                   |             |
|    total_timesteps      | 2200000     |
| train/                  |             |
|    approx_kl            | 0.006008709 |
|    clip_fraction        | 0.0669      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.34       |
|    explained_variance   | -0.074      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.024      |
|    n_updates            | 2144        |
|    policy_gradient_loss | 0.00132     |
|    std                  | 0.921       |
|    value_loss           | 3.18e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 870     |
|    iterations      | 269     |
|    time_elapsed    | 2531    |
|    total_timesteps | 2203648 |
--------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 871          |
|    iterations           | 270          |
|    time_elapsed         | 2536         |
|    total_timesteps      | 2211840      |
| train/                  |              |
|    approx_kl            | 0.0062255836 |
|    clip_fraction        | 0.0686       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.34        |
|    explained_variance   | -0.0502      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0315      |
|    n_updates            | 2152         |
|    policy_gradient_loss | 0.00162      |
|    std                  | 0.921        |
|    value_loss           | 3.94e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 873          |
|    iterations           | 271          |
|    time_elapsed         | 2542         |
|    total_timesteps      | 2220032      |
| train/                  |              |
|    approx_kl            | 0.0056584314 |
|    clip_fraction        | 0.0746       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.34        |
|    explained_variance   | -0.0808      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0255      |
|    n_updates            | 2160         |
|    policy_gradient_loss | 0.000447     |
|    std                  | 0.92         |
|    value_loss           | 2.98e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 874          |
|    iterations           | 272          |
|    time_elapsed         | 2547         |
|    total_timesteps      | 2228224      |
| train/                  |              |
|    approx_kl            | 0.0051566986 |
|    clip_fraction        | 0.0642       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.34        |
|    explained_variance   | -0.174       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0294      |
|    n_updates            | 2168         |
|    policy_gradient_loss | 0.000645     |
|    std                  | 0.919        |
|    value_loss           | 1.71e-05     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 875         |
|    iterations           | 273         |
|    time_elapsed         | 2553        |
|    total_timesteps      | 2236416     |
| train/                  |             |
|    approx_kl            | 0.005488255 |
|    clip_fraction        | 0.0651      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.33       |
|    explained_variance   | -0.124      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0256     |
|    n_updates            | 2176        |
|    policy_gradient_loss | 0.000603    |
|    std                  | 0.917       |
|    value_loss           | 2.08e-05    |
-----------------------------------------
Eval num_timesteps=2240000, episode_reward=-0.04 +/- 0.06
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | -0.0371      |
| time/                   |              |
|    total_timesteps      | 2240000      |
| train/                  |              |
|    approx_kl            | 0.0049278596 |
|    clip_fraction        | 0.0545       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.33        |
|    explained_variance   | -0.142       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0286      |
|    n_updates            | 2184         |
|    policy_gradient_loss | 0.00126      |
|    std                  | 0.915        |
|    value_loss           | 1.89e-05     |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 869     |
|    iterations      | 274     |
|    time_elapsed    | 2581    |
|    total_timesteps | 2244608 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 871         |
|    iterations           | 275         |
|    time_elapsed         | 2586        |
|    total_timesteps      | 2252800     |
| train/                  |             |
|    approx_kl            | 0.005515597 |
|    clip_fraction        | 0.0624      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.33       |
|    explained_variance   | -0.0657     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0271     |
|    n_updates            | 2192        |
|    policy_gradient_loss | -1.55e-05   |
|    std                  | 0.914       |
|    value_loss           | 3.32e-05    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 872          |
|    iterations           | 276          |
|    time_elapsed         | 2591         |
|    total_timesteps      | 2260992      |
| train/                  |              |
|    approx_kl            | 0.0056569437 |
|    clip_fraction        | 0.0576       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.33        |
|    explained_variance   | -0.0516      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0302      |
|    n_updates            | 2200         |
|    policy_gradient_loss | -0.000233    |
|    std                  | 0.914        |
|    value_loss           | 4.86e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 873          |
|    iterations           | 277          |
|    time_elapsed         | 2596         |
|    total_timesteps      | 2269184      |
| train/                  |              |
|    approx_kl            | 0.0039976006 |
|    clip_fraction        | 0.0408       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.33        |
|    explained_variance   | -0.0616      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0258      |
|    n_updates            | 2208         |
|    policy_gradient_loss | 0.000255     |
|    std                  | 0.913        |
|    value_loss           | 5.08e-05     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 875         |
|    iterations           | 278         |
|    time_elapsed         | 2601        |
|    total_timesteps      | 2277376     |
| train/                  |             |
|    approx_kl            | 0.004054944 |
|    clip_fraction        | 0.0437      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.33       |
|    explained_variance   | -0.045      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0301     |
|    n_updates            | 2216        |
|    policy_gradient_loss | -0.000812   |
|    std                  | 0.912       |
|    value_loss           | 5.33e-05    |
-----------------------------------------
Eval num_timesteps=2280000, episode_reward=-0.03 +/- 0.08
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | -0.0285      |
| time/                   |              |
|    total_timesteps      | 2280000      |
| train/                  |              |
|    approx_kl            | 0.0037703456 |
|    clip_fraction        | 0.0441       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.33        |
|    explained_variance   | -0.0421      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0267      |
|    n_updates            | 2224         |
|    policy_gradient_loss | 0.000885     |
|    std                  | 0.913        |
|    value_loss           | 6.72e-05     |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 869     |
|    iterations      | 279     |
|    time_elapsed    | 2628    |
|    total_timesteps | 2285568 |
--------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 870          |
|    iterations           | 280          |
|    time_elapsed         | 2634         |
|    total_timesteps      | 2293760      |
| train/                  |              |
|    approx_kl            | 0.0050897836 |
|    clip_fraction        | 0.0526       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.33        |
|    explained_variance   | -0.21        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0301      |
|    n_updates            | 2232         |
|    policy_gradient_loss | -0.00104     |
|    std                  | 0.912        |
|    value_loss           | 1.72e-05     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 872         |
|    iterations           | 281         |
|    time_elapsed         | 2639        |
|    total_timesteps      | 2301952     |
| train/                  |             |
|    approx_kl            | 0.004453835 |
|    clip_fraction        | 0.0498      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.33       |
|    explained_variance   | -0.0864     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.033      |
|    n_updates            | 2240        |
|    policy_gradient_loss | -0.000762   |
|    std                  | 0.91        |
|    value_loss           | 3.02e-05    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 873          |
|    iterations           | 282          |
|    time_elapsed         | 2644         |
|    total_timesteps      | 2310144      |
| train/                  |              |
|    approx_kl            | 0.0038149203 |
|    clip_fraction        | 0.0439       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.33        |
|    explained_variance   | -0.0232      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0289      |
|    n_updates            | 2248         |
|    policy_gradient_loss | -0.00061     |
|    std                  | 0.911        |
|    value_loss           | 6.1e-05      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 874          |
|    iterations           | 283          |
|    time_elapsed         | 2650         |
|    total_timesteps      | 2318336      |
| train/                  |              |
|    approx_kl            | 0.0036246264 |
|    clip_fraction        | 0.0443       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.32        |
|    explained_variance   | -0.18        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0273      |
|    n_updates            | 2256         |
|    policy_gradient_loss | -0.00147     |
|    std                  | 0.909        |
|    value_loss           | 2.06e-05     |
------------------------------------------
Eval num_timesteps=2320000, episode_reward=-0.02 +/- 0.10
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | -0.022       |
| time/                   |              |
|    total_timesteps      | 2320000      |
| train/                  |              |
|    approx_kl            | 0.0036162096 |
|    clip_fraction        | 0.0301       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.32        |
|    explained_variance   | -0.107       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0264      |
|    n_updates            | 2264         |
|    policy_gradient_loss | 0.00018      |
|    std                  | 0.907        |
|    value_loss           | 2.17e-05     |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 868     |
|    iterations      | 284     |
|    time_elapsed    | 2679    |
|    total_timesteps | 2326528 |
--------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 869          |
|    iterations           | 285          |
|    time_elapsed         | 2684         |
|    total_timesteps      | 2334720      |
| train/                  |              |
|    approx_kl            | 0.0044107903 |
|    clip_fraction        | 0.037        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.32        |
|    explained_variance   | -0.0393      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0279      |
|    n_updates            | 2272         |
|    policy_gradient_loss | -0.000864    |
|    std                  | 0.906        |
|    value_loss           | 4.91e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 870          |
|    iterations           | 286          |
|    time_elapsed         | 2690         |
|    total_timesteps      | 2342912      |
| train/                  |              |
|    approx_kl            | 0.0028895843 |
|    clip_fraction        | 0.0299       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.32        |
|    explained_variance   | -0.0694      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0276      |
|    n_updates            | 2280         |
|    policy_gradient_loss | -0.000957    |
|    std                  | 0.905        |
|    value_loss           | 3.78e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 872          |
|    iterations           | 287          |
|    time_elapsed         | 2695         |
|    total_timesteps      | 2351104      |
| train/                  |              |
|    approx_kl            | 0.0036791605 |
|    clip_fraction        | 0.0464       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.32        |
|    explained_variance   | -0.0882      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0294      |
|    n_updates            | 2288         |
|    policy_gradient_loss | -0.000857    |
|    std                  | 0.904        |
|    value_loss           | 2.67e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 873          |
|    iterations           | 288          |
|    time_elapsed         | 2700         |
|    total_timesteps      | 2359296      |
| train/                  |              |
|    approx_kl            | 0.0026525082 |
|    clip_fraction        | 0.025        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.32        |
|    explained_variance   | -0.102       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.024       |
|    n_updates            | 2296         |
|    policy_gradient_loss | -0.00137     |
|    std                  | 0.902        |
|    value_loss           | 2.17e-05     |
------------------------------------------
Eval num_timesteps=2360000, episode_reward=-0.02 +/- 0.05
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | -0.0209      |
| time/                   |              |
|    total_timesteps      | 2360000      |
| train/                  |              |
|    approx_kl            | 0.0030453028 |
|    clip_fraction        | 0.0316       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.32        |
|    explained_variance   | -0.0677      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0295      |
|    n_updates            | 2304         |
|    policy_gradient_loss | -0.00159     |
|    std                  | 0.9          |
|    value_loss           | 3.21e-05     |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 867     |
|    iterations      | 289     |
|    time_elapsed    | 2729    |
|    total_timesteps | 2367488 |
--------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 868          |
|    iterations           | 290          |
|    time_elapsed         | 2734         |
|    total_timesteps      | 2375680      |
| train/                  |              |
|    approx_kl            | 0.0048319125 |
|    clip_fraction        | 0.0493       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.31        |
|    explained_variance   | -0.0857      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0299      |
|    n_updates            | 2312         |
|    policy_gradient_loss | -0.00269     |
|    std                  | 0.898        |
|    value_loss           | 2.68e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 870          |
|    iterations           | 291          |
|    time_elapsed         | 2739         |
|    total_timesteps      | 2383872      |
| train/                  |              |
|    approx_kl            | 0.0020617924 |
|    clip_fraction        | 0.0126       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.31        |
|    explained_variance   | -0.052       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0273      |
|    n_updates            | 2320         |
|    policy_gradient_loss | -0.000917    |
|    std                  | 0.898        |
|    value_loss           | 4.58e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 871          |
|    iterations           | 292          |
|    time_elapsed         | 2744         |
|    total_timesteps      | 2392064      |
| train/                  |              |
|    approx_kl            | 0.0032736156 |
|    clip_fraction        | 0.035        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.31        |
|    explained_variance   | -0.0361      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0318      |
|    n_updates            | 2328         |
|    policy_gradient_loss | -0.00129     |
|    std                  | 0.896        |
|    value_loss           | 5.07e-05     |
------------------------------------------
Eval num_timesteps=2400000, episode_reward=0.01 +/- 0.06
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | 0.00913      |
| time/                   |              |
|    total_timesteps      | 2400000      |
| train/                  |              |
|    approx_kl            | 0.0020398558 |
|    clip_fraction        | 0.0146       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.31        |
|    explained_variance   | -0.0805      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0275      |
|    n_updates            | 2336         |
|    policy_gradient_loss | -0.00142     |
|    std                  | 0.894        |
|    value_loss           | 3.46e-05     |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 865     |
|    iterations      | 293     |
|    time_elapsed    | 2771    |
|    total_timesteps | 2400256 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 867         |
|    iterations           | 294         |
|    time_elapsed         | 2776        |
|    total_timesteps      | 2408448     |
| train/                  |             |
|    approx_kl            | 0.002162884 |
|    clip_fraction        | 0.012       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.31       |
|    explained_variance   | -0.0719     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0261     |
|    n_updates            | 2344        |
|    policy_gradient_loss | -0.000552   |
|    std                  | 0.892       |
|    value_loss           | 2.93e-05    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 868          |
|    iterations           | 295          |
|    time_elapsed         | 2781         |
|    total_timesteps      | 2416640      |
| train/                  |              |
|    approx_kl            | 0.0013268089 |
|    clip_fraction        | 0.0079       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.3         |
|    explained_variance   | -0.091       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0233      |
|    n_updates            | 2352         |
|    policy_gradient_loss | -0.000222    |
|    std                  | 0.891        |
|    value_loss           | 2.87e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 870          |
|    iterations           | 296          |
|    time_elapsed         | 2786         |
|    total_timesteps      | 2424832      |
| train/                  |              |
|    approx_kl            | 0.0016109555 |
|    clip_fraction        | 0.0114       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.3         |
|    explained_variance   | -0.0672      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0273      |
|    n_updates            | 2360         |
|    policy_gradient_loss | -0.000752    |
|    std                  | 0.89         |
|    value_loss           | 3.61e-05     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 871         |
|    iterations           | 297         |
|    time_elapsed         | 2790        |
|    total_timesteps      | 2433024     |
| train/                  |             |
|    approx_kl            | 0.001340681 |
|    clip_fraction        | 0.0208      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.3        |
|    explained_variance   | -0.046      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0319     |
|    n_updates            | 2368        |
|    policy_gradient_loss | -0.000581   |
|    std                  | 0.89        |
|    value_loss           | 3.4e-05     |
-----------------------------------------
Eval num_timesteps=2440000, episode_reward=0.01 +/- 0.06
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | 0.0136      |
| time/                   |             |
|    total_timesteps      | 2440000     |
| train/                  |             |
|    approx_kl            | 0.002614309 |
|    clip_fraction        | 0.0189      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.3        |
|    explained_variance   | -0.0566     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0307     |
|    n_updates            | 2376        |
|    policy_gradient_loss | -0.00113    |
|    std                  | 0.89        |
|    value_loss           | 4.19e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 866     |
|    iterations      | 298     |
|    time_elapsed    | 2816    |
|    total_timesteps | 2441216 |
--------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 868          |
|    iterations           | 299          |
|    time_elapsed         | 2821         |
|    total_timesteps      | 2449408      |
| train/                  |              |
|    approx_kl            | 0.0044208076 |
|    clip_fraction        | 0.0335       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.3         |
|    explained_variance   | -0.07        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0243      |
|    n_updates            | 2384         |
|    policy_gradient_loss | -0.00182     |
|    std                  | 0.89         |
|    value_loss           | 2.78e-05     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 869         |
|    iterations           | 300         |
|    time_elapsed         | 2825        |
|    total_timesteps      | 2457600     |
| train/                  |             |
|    approx_kl            | 0.002083294 |
|    clip_fraction        | 0.0104      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.3        |
|    explained_variance   | -0.0712     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0309     |
|    n_updates            | 2392        |
|    policy_gradient_loss | -0.00064    |
|    std                  | 0.889       |
|    value_loss           | 3.66e-05    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 871          |
|    iterations           | 301          |
|    time_elapsed         | 2829         |
|    total_timesteps      | 2465792      |
| train/                  |              |
|    approx_kl            | 0.0024706526 |
|    clip_fraction        | 0.0281       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.3         |
|    explained_variance   | -0.0731      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0293      |
|    n_updates            | 2400         |
|    policy_gradient_loss | -0.00112     |
|    std                  | 0.889        |
|    value_loss           | 3.13e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 872          |
|    iterations           | 302          |
|    time_elapsed         | 2834         |
|    total_timesteps      | 2473984      |
| train/                  |              |
|    approx_kl            | 0.0017521526 |
|    clip_fraction        | 0.00989      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.3         |
|    explained_variance   | -0.0503      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0234      |
|    n_updates            | 2408         |
|    policy_gradient_loss | -0.000466    |
|    std                  | 0.887        |
|    value_loss           | 4.73e-05     |
------------------------------------------
Eval num_timesteps=2480000, episode_reward=0.02 +/- 0.07
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | 0.0187       |
| time/                   |              |
|    total_timesteps      | 2480000      |
| train/                  |              |
|    approx_kl            | 0.0026170833 |
|    clip_fraction        | 0.0196       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.3         |
|    explained_variance   | -0.0675      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0229      |
|    n_updates            | 2416         |
|    policy_gradient_loss | -0.00095     |
|    std                  | 0.889        |
|    value_loss           | 3.28e-05     |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 867     |
|    iterations      | 303     |
|    time_elapsed    | 2859    |
|    total_timesteps | 2482176 |
--------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 869          |
|    iterations           | 304          |
|    time_elapsed         | 2864         |
|    total_timesteps      | 2490368      |
| train/                  |              |
|    approx_kl            | 0.0016216228 |
|    clip_fraction        | 0.0137       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.3         |
|    explained_variance   | -0.0577      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0238      |
|    n_updates            | 2424         |
|    policy_gradient_loss | 3.8e-05      |
|    std                  | 0.888        |
|    value_loss           | 2.9e-05      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 870          |
|    iterations           | 305          |
|    time_elapsed         | 2869         |
|    total_timesteps      | 2498560      |
| train/                  |              |
|    approx_kl            | 0.0017499537 |
|    clip_fraction        | 0.0117       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.3         |
|    explained_variance   | -0.0779      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0278      |
|    n_updates            | 2432         |
|    policy_gradient_loss | -0.000303    |
|    std                  | 0.888        |
|    value_loss           | 3.54e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 871          |
|    iterations           | 306          |
|    time_elapsed         | 2874         |
|    total_timesteps      | 2506752      |
| train/                  |              |
|    approx_kl            | 0.0025630011 |
|    clip_fraction        | 0.0358       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.3         |
|    explained_variance   | -0.121       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0304      |
|    n_updates            | 2440         |
|    policy_gradient_loss | -0.00167     |
|    std                  | 0.887        |
|    value_loss           | 1.71e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 873          |
|    iterations           | 307          |
|    time_elapsed         | 2879         |
|    total_timesteps      | 2514944      |
| train/                  |              |
|    approx_kl            | 0.0018348573 |
|    clip_fraction        | 0.0149       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.3         |
|    explained_variance   | -0.0992      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0246      |
|    n_updates            | 2448         |
|    policy_gradient_loss | 0.000354     |
|    std                  | 0.886        |
|    value_loss           | 2.7e-05      |
------------------------------------------
Eval num_timesteps=2520000, episode_reward=-0.05 +/- 0.12
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | -0.0532      |
| time/                   |              |
|    total_timesteps      | 2520000      |
| train/                  |              |
|    approx_kl            | 0.0016522306 |
|    clip_fraction        | 0.0115       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.3         |
|    explained_variance   | -0.0785      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0275      |
|    n_updates            | 2456         |
|    policy_gradient_loss | -0.00114     |
|    std                  | 0.887        |
|    value_loss           | 2.5e-05      |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 867     |
|    iterations      | 308     |
|    time_elapsed    | 2906    |
|    total_timesteps | 2523136 |
--------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 869          |
|    iterations           | 309          |
|    time_elapsed         | 2911         |
|    total_timesteps      | 2531328      |
| train/                  |              |
|    approx_kl            | 0.0032591769 |
|    clip_fraction        | 0.013        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.3         |
|    explained_variance   | -0.0721      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0274      |
|    n_updates            | 2464         |
|    policy_gradient_loss | -0.000391    |
|    std                  | 0.887        |
|    value_loss           | 2.99e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 870          |
|    iterations           | 310          |
|    time_elapsed         | 2916         |
|    total_timesteps      | 2539520      |
| train/                  |              |
|    approx_kl            | 0.0017155611 |
|    clip_fraction        | 0.0271       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.3         |
|    explained_variance   | -0.0431      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0255      |
|    n_updates            | 2472         |
|    policy_gradient_loss | -0.000665    |
|    std                  | 0.886        |
|    value_loss           | 3.82e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 871          |
|    iterations           | 311          |
|    time_elapsed         | 2921         |
|    total_timesteps      | 2547712      |
| train/                  |              |
|    approx_kl            | 0.0013597701 |
|    clip_fraction        | 0.00859      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.3         |
|    explained_variance   | -0.0369      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0295      |
|    n_updates            | 2480         |
|    policy_gradient_loss | -0.000809    |
|    std                  | 0.885        |
|    value_loss           | 4.08e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 873          |
|    iterations           | 312          |
|    time_elapsed         | 2926         |
|    total_timesteps      | 2555904      |
| train/                  |              |
|    approx_kl            | 0.0016770626 |
|    clip_fraction        | 0.00972      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.3         |
|    explained_variance   | -0.0458      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.028       |
|    n_updates            | 2488         |
|    policy_gradient_loss | -0.000268    |
|    std                  | 0.884        |
|    value_loss           | 4.27e-05     |
------------------------------------------
Eval num_timesteps=2560000, episode_reward=-0.04 +/- 0.15
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | -0.0355      |
| time/                   |              |
|    total_timesteps      | 2560000      |
| train/                  |              |
|    approx_kl            | 0.0020834387 |
|    clip_fraction        | 0.0177       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.3         |
|    explained_variance   | -0.0308      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0292      |
|    n_updates            | 2496         |
|    policy_gradient_loss | -0.000999    |
|    std                  | 0.883        |
|    value_loss           | 4.22e-05     |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 868     |
|    iterations      | 313     |
|    time_elapsed    | 2952    |
|    total_timesteps | 2564096 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 869         |
|    iterations           | 314         |
|    time_elapsed         | 2957        |
|    total_timesteps      | 2572288     |
| train/                  |             |
|    approx_kl            | 0.003265887 |
|    clip_fraction        | 0.0324      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.29       |
|    explained_variance   | -0.0818     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0275     |
|    n_updates            | 2504        |
|    policy_gradient_loss | -0.00221    |
|    std                  | 0.882       |
|    value_loss           | 2.16e-05    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 871          |
|    iterations           | 315          |
|    time_elapsed         | 2962         |
|    total_timesteps      | 2580480      |
| train/                  |              |
|    approx_kl            | 0.0020900236 |
|    clip_fraction        | 0.018        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.29        |
|    explained_variance   | -0.0483      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0256      |
|    n_updates            | 2512         |
|    policy_gradient_loss | -0.000172    |
|    std                  | 0.882        |
|    value_loss           | 4.04e-05     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 872         |
|    iterations           | 316         |
|    time_elapsed         | 2966        |
|    total_timesteps      | 2588672     |
| train/                  |             |
|    approx_kl            | 0.001716616 |
|    clip_fraction        | 0.0113      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.29       |
|    explained_variance   | -0.0624     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0266     |
|    n_updates            | 2520        |
|    policy_gradient_loss | -0.000385   |
|    std                  | 0.881       |
|    value_loss           | 2.56e-05    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 873          |
|    iterations           | 317          |
|    time_elapsed         | 2971         |
|    total_timesteps      | 2596864      |
| train/                  |              |
|    approx_kl            | 0.0017551195 |
|    clip_fraction        | 0.013        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.29        |
|    explained_variance   | -0.0506      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0276      |
|    n_updates            | 2528         |
|    policy_gradient_loss | -0.00061     |
|    std                  | 0.881        |
|    value_loss           | 3.06e-05     |
------------------------------------------
Eval num_timesteps=2600000, episode_reward=0.00 +/- 0.07
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | 0.00216      |
| time/                   |              |
|    total_timesteps      | 2600000      |
| train/                  |              |
|    approx_kl            | 0.0021915822 |
|    clip_fraction        | 0.0246       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.29        |
|    explained_variance   | -0.071       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0282      |
|    n_updates            | 2536         |
|    policy_gradient_loss | -0.00108     |
|    std                  | 0.879        |
|    value_loss           | 2.36e-05     |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 868     |
|    iterations      | 318     |
|    time_elapsed    | 2999    |
|    total_timesteps | 2605056 |
--------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 869          |
|    iterations           | 319          |
|    time_elapsed         | 3004         |
|    total_timesteps      | 2613248      |
| train/                  |              |
|    approx_kl            | 0.0026437873 |
|    clip_fraction        | 0.0207       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.29        |
|    explained_variance   | -0.0699      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0257      |
|    n_updates            | 2544         |
|    policy_gradient_loss | -0.00113     |
|    std                  | 0.878        |
|    value_loss           | 2.91e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 871          |
|    iterations           | 320          |
|    time_elapsed         | 3009         |
|    total_timesteps      | 2621440      |
| train/                  |              |
|    approx_kl            | 0.0015291669 |
|    clip_fraction        | 0.0147       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.29        |
|    explained_variance   | -0.0266      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0265      |
|    n_updates            | 2552         |
|    policy_gradient_loss | -0.000823    |
|    std                  | 0.876        |
|    value_loss           | 4.94e-05     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 872         |
|    iterations           | 321         |
|    time_elapsed         | 3014        |
|    total_timesteps      | 2629632     |
| train/                  |             |
|    approx_kl            | 0.003935928 |
|    clip_fraction        | 0.0378      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.29       |
|    explained_variance   | -0.0395     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0241     |
|    n_updates            | 2560        |
|    policy_gradient_loss | -0.00181    |
|    std                  | 0.875       |
|    value_loss           | 6.91e-05    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 873          |
|    iterations           | 322          |
|    time_elapsed         | 3019         |
|    total_timesteps      | 2637824      |
| train/                  |              |
|    approx_kl            | 0.0020063033 |
|    clip_fraction        | 0.0135       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.28        |
|    explained_variance   | -0.0486      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0281      |
|    n_updates            | 2568         |
|    policy_gradient_loss | -0.0013      |
|    std                  | 0.873        |
|    value_loss           | 3.21e-05     |
------------------------------------------
Eval num_timesteps=2640000, episode_reward=0.05 +/- 0.02
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | 0.0479       |
| time/                   |              |
|    total_timesteps      | 2640000      |
| train/                  |              |
|    approx_kl            | 0.0027774973 |
|    clip_fraction        | 0.0321       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.28        |
|    explained_variance   | -0.171       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.03        |
|    n_updates            | 2576         |
|    policy_gradient_loss | -0.00153     |
|    std                  | 0.87         |
|    value_loss           | 1.57e-05     |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 869     |
|    iterations      | 323     |
|    time_elapsed    | 3044    |
|    total_timesteps | 2646016 |
--------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 870          |
|    iterations           | 324          |
|    time_elapsed         | 3049         |
|    total_timesteps      | 2654208      |
| train/                  |              |
|    approx_kl            | 0.0026635649 |
|    clip_fraction        | 0.0318       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.28        |
|    explained_variance   | -0.0369      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0265      |
|    n_updates            | 2584         |
|    policy_gradient_loss | -0.000984    |
|    std                  | 0.87         |
|    value_loss           | 4.16e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 871          |
|    iterations           | 325          |
|    time_elapsed         | 3053         |
|    total_timesteps      | 2662400      |
| train/                  |              |
|    approx_kl            | 0.0028871195 |
|    clip_fraction        | 0.03         |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.28        |
|    explained_variance   | -0.0874      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0279      |
|    n_updates            | 2592         |
|    policy_gradient_loss | -0.000981    |
|    std                  | 0.869        |
|    value_loss           | 2.49e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 873          |
|    iterations           | 326          |
|    time_elapsed         | 3058         |
|    total_timesteps      | 2670592      |
| train/                  |              |
|    approx_kl            | 0.0022771952 |
|    clip_fraction        | 0.0213       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.28        |
|    explained_variance   | -0.0824      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0242      |
|    n_updates            | 2600         |
|    policy_gradient_loss | -0.000677    |
|    std                  | 0.866        |
|    value_loss           | 2.11e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 874          |
|    iterations           | 327          |
|    time_elapsed         | 3062         |
|    total_timesteps      | 2678784      |
| train/                  |              |
|    approx_kl            | 0.0015974534 |
|    clip_fraction        | 0.00986      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.27        |
|    explained_variance   | -0.0543      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0277      |
|    n_updates            | 2608         |
|    policy_gradient_loss | -7.78e-05    |
|    std                  | 0.865        |
|    value_loss           | 2.79e-05     |
------------------------------------------
Eval num_timesteps=2680000, episode_reward=-0.03 +/- 0.09
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | -0.0327      |
| time/                   |              |
|    total_timesteps      | 2680000      |
| train/                  |              |
|    approx_kl            | 0.0014808592 |
|    clip_fraction        | 0.0104       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.27        |
|    explained_variance   | -0.0304      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0277      |
|    n_updates            | 2616         |
|    policy_gradient_loss | -0.000307    |
|    std                  | 0.863        |
|    value_loss           | 3.96e-05     |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 869     |
|    iterations      | 328     |
|    time_elapsed    | 3088    |
|    total_timesteps | 2686976 |
--------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 871          |
|    iterations           | 329          |
|    time_elapsed         | 3093         |
|    total_timesteps      | 2695168      |
| train/                  |              |
|    approx_kl            | 0.0022018808 |
|    clip_fraction        | 0.0188       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.27        |
|    explained_variance   | -0.0936      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0256      |
|    n_updates            | 2624         |
|    policy_gradient_loss | -0.00115     |
|    std                  | 0.863        |
|    value_loss           | 2.53e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 872          |
|    iterations           | 330          |
|    time_elapsed         | 3097         |
|    total_timesteps      | 2703360      |
| train/                  |              |
|    approx_kl            | 0.0018995384 |
|    clip_fraction        | 0.0252       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.27        |
|    explained_variance   | -0.147       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0284      |
|    n_updates            | 2632         |
|    policy_gradient_loss | -0.00129     |
|    std                  | 0.861        |
|    value_loss           | 1.51e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 873          |
|    iterations           | 331          |
|    time_elapsed         | 3102         |
|    total_timesteps      | 2711552      |
| train/                  |              |
|    approx_kl            | 0.0030334438 |
|    clip_fraction        | 0.027        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.27        |
|    explained_variance   | -0.102       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0257      |
|    n_updates            | 2640         |
|    policy_gradient_loss | -0.000818    |
|    std                  | 0.859        |
|    value_loss           | 1.7e-05      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 875          |
|    iterations           | 332          |
|    time_elapsed         | 3107         |
|    total_timesteps      | 2719744      |
| train/                  |              |
|    approx_kl            | 0.0034496286 |
|    clip_fraction        | 0.0336       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.27        |
|    explained_variance   | -0.0657      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0278      |
|    n_updates            | 2648         |
|    policy_gradient_loss | -0.00153     |
|    std                  | 0.858        |
|    value_loss           | 2.24e-05     |
------------------------------------------
Eval num_timesteps=2720000, episode_reward=0.02 +/- 0.08
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | 0.0196      |
| time/                   |             |
|    total_timesteps      | 2720000     |
| train/                  |             |
|    approx_kl            | 0.002418212 |
|    clip_fraction        | 0.0258      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.27       |
|    explained_variance   | -0.0783     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0288     |
|    n_updates            | 2656        |
|    policy_gradient_loss | -0.00172    |
|    std                  | 0.858       |
|    value_loss           | 2.22e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 870     |
|    iterations      | 333     |
|    time_elapsed    | 3133    |
|    total_timesteps | 2727936 |
--------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 871          |
|    iterations           | 334          |
|    time_elapsed         | 3138         |
|    total_timesteps      | 2736128      |
| train/                  |              |
|    approx_kl            | 0.0019035751 |
|    clip_fraction        | 0.016        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.27        |
|    explained_variance   | -0.0368      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0252      |
|    n_updates            | 2664         |
|    policy_gradient_loss | -0.000608    |
|    std                  | 0.857        |
|    value_loss           | 4.97e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 873          |
|    iterations           | 335          |
|    time_elapsed         | 3142         |
|    total_timesteps      | 2744320      |
| train/                  |              |
|    approx_kl            | 0.0018679874 |
|    clip_fraction        | 0.0141       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.27        |
|    explained_variance   | -0.0396      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0254      |
|    n_updates            | 2672         |
|    policy_gradient_loss | -0.000682    |
|    std                  | 0.858        |
|    value_loss           | 4.16e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 874          |
|    iterations           | 336          |
|    time_elapsed         | 3147         |
|    total_timesteps      | 2752512      |
| train/                  |              |
|    approx_kl            | 0.0015573343 |
|    clip_fraction        | 0.0111       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.27        |
|    explained_variance   | -0.066       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0282      |
|    n_updates            | 2680         |
|    policy_gradient_loss | -0.000529    |
|    std                  | 0.858        |
|    value_loss           | 3.23e-05     |
------------------------------------------
Eval num_timesteps=2760000, episode_reward=-0.03 +/- 0.09
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | -0.0344      |
| time/                   |              |
|    total_timesteps      | 2760000      |
| train/                  |              |
|    approx_kl            | 0.0021787565 |
|    clip_fraction        | 0.0205       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.26        |
|    explained_variance   | -0.0409      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0232      |
|    n_updates            | 2688         |
|    policy_gradient_loss | -0.000205    |
|    std                  | 0.856        |
|    value_loss           | 3.67e-05     |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 869     |
|    iterations      | 337     |
|    time_elapsed    | 3173    |
|    total_timesteps | 2760704 |
--------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 871          |
|    iterations           | 338          |
|    time_elapsed         | 3178         |
|    total_timesteps      | 2768896      |
| train/                  |              |
|    approx_kl            | 0.0026130069 |
|    clip_fraction        | 0.0256       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.26        |
|    explained_variance   | -0.0627      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0284      |
|    n_updates            | 2696         |
|    policy_gradient_loss | -1.7e-05     |
|    std                  | 0.856        |
|    value_loss           | 2.61e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 872          |
|    iterations           | 339          |
|    time_elapsed         | 3183         |
|    total_timesteps      | 2777088      |
| train/                  |              |
|    approx_kl            | 0.0025562802 |
|    clip_fraction        | 0.0232       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.26        |
|    explained_variance   | -0.0622      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.024       |
|    n_updates            | 2704         |
|    policy_gradient_loss | -0.000438    |
|    std                  | 0.856        |
|    value_loss           | 2.3e-05      |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 873         |
|    iterations           | 340         |
|    time_elapsed         | 3189        |
|    total_timesteps      | 2785280     |
| train/                  |             |
|    approx_kl            | 0.002323382 |
|    clip_fraction        | 0.0216      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.26       |
|    explained_variance   | -0.0303     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0241     |
|    n_updates            | 2712        |
|    policy_gradient_loss | -0.000707   |
|    std                  | 0.856       |
|    value_loss           | 4.32e-05    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 874          |
|    iterations           | 341          |
|    time_elapsed         | 3194         |
|    total_timesteps      | 2793472      |
| train/                  |              |
|    approx_kl            | 0.0019062299 |
|    clip_fraction        | 0.0168       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.26        |
|    explained_variance   | -0.0254      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0279      |
|    n_updates            | 2720         |
|    policy_gradient_loss | 0.00022      |
|    std                  | 0.856        |
|    value_loss           | 5.95e-05     |
------------------------------------------
Eval num_timesteps=2800000, episode_reward=-0.03 +/- 0.12
Episode length: 2340.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 2.34e+03   |
|    mean_reward          | -0.0273    |
| time/                   |            |
|    total_timesteps      | 2800000    |
| train/                  |            |
|    approx_kl            | 0.00344609 |
|    clip_fraction        | 0.0251     |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.26      |
|    explained_variance   | -0.0428    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.023     |
|    n_updates            | 2728       |
|    policy_gradient_loss | -0.00126   |
|    std                  | 0.856      |
|    value_loss           | 3.8e-05    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 869     |
|    iterations      | 342     |
|    time_elapsed    | 3223    |
|    total_timesteps | 2801664 |
--------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 870          |
|    iterations           | 343          |
|    time_elapsed         | 3229         |
|    total_timesteps      | 2809856      |
| train/                  |              |
|    approx_kl            | 0.0023203725 |
|    clip_fraction        | 0.0218       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.26        |
|    explained_variance   | -0.076       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.025       |
|    n_updates            | 2736         |
|    policy_gradient_loss | 0.00035      |
|    std                  | 0.854        |
|    value_loss           | 2.24e-05     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 871         |
|    iterations           | 344         |
|    time_elapsed         | 3235        |
|    total_timesteps      | 2818048     |
| train/                  |             |
|    approx_kl            | 0.002977008 |
|    clip_fraction        | 0.0235      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.26       |
|    explained_variance   | -0.0852     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0228     |
|    n_updates            | 2744        |
|    policy_gradient_loss | -0.000373   |
|    std                  | 0.854       |
|    value_loss           | 2.18e-05    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 871          |
|    iterations           | 345          |
|    time_elapsed         | 3241         |
|    total_timesteps      | 2826240      |
| train/                  |              |
|    approx_kl            | 0.0032961536 |
|    clip_fraction        | 0.0332       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.26        |
|    explained_variance   | -0.0404      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.023       |
|    n_updates            | 2752         |
|    policy_gradient_loss | -0.00024     |
|    std                  | 0.853        |
|    value_loss           | 4.27e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 872          |
|    iterations           | 346          |
|    time_elapsed         | 3247         |
|    total_timesteps      | 2834432      |
| train/                  |              |
|    approx_kl            | 0.0045506316 |
|    clip_fraction        | 0.047        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.26        |
|    explained_variance   | -0.0998      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0245      |
|    n_updates            | 2760         |
|    policy_gradient_loss | -0.000328    |
|    std                  | 0.852        |
|    value_loss           | 1.54e-05     |
------------------------------------------
Eval num_timesteps=2840000, episode_reward=0.02 +/- 0.06
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | 0.0165       |
| time/                   |              |
|    total_timesteps      | 2840000      |
| train/                  |              |
|    approx_kl            | 0.0036667923 |
|    clip_fraction        | 0.0377       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.26        |
|    explained_variance   | -0.0755      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0263      |
|    n_updates            | 2768         |
|    policy_gradient_loss | -0.000177    |
|    std                  | 0.852        |
|    value_loss           | 1.95e-05     |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 866     |
|    iterations      | 347     |
|    time_elapsed    | 3278    |
|    total_timesteps | 2842624 |
--------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 867          |
|    iterations           | 348          |
|    time_elapsed         | 3284         |
|    total_timesteps      | 2850816      |
| train/                  |              |
|    approx_kl            | 0.0036138757 |
|    clip_fraction        | 0.0384       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.26        |
|    explained_variance   | -0.0716      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0247      |
|    n_updates            | 2776         |
|    policy_gradient_loss | -0.000914    |
|    std                  | 0.853        |
|    value_loss           | 2.1e-05      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 868          |
|    iterations           | 349          |
|    time_elapsed         | 3290         |
|    total_timesteps      | 2859008      |
| train/                  |              |
|    approx_kl            | 0.0026314438 |
|    clip_fraction        | 0.0385       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.26        |
|    explained_variance   | -0.06        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0263      |
|    n_updates            | 2784         |
|    policy_gradient_loss | -0.000529    |
|    std                  | 0.852        |
|    value_loss           | 3.14e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 869          |
|    iterations           | 350          |
|    time_elapsed         | 3296         |
|    total_timesteps      | 2867200      |
| train/                  |              |
|    approx_kl            | 0.0024404135 |
|    clip_fraction        | 0.025        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.26        |
|    explained_variance   | -0.0475      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0259      |
|    n_updates            | 2792         |
|    policy_gradient_loss | -0.000413    |
|    std                  | 0.852        |
|    value_loss           | 3.52e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 870          |
|    iterations           | 351          |
|    time_elapsed         | 3302         |
|    total_timesteps      | 2875392      |
| train/                  |              |
|    approx_kl            | 0.0031514512 |
|    clip_fraction        | 0.0308       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.26        |
|    explained_variance   | -0.0666      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0276      |
|    n_updates            | 2800         |
|    policy_gradient_loss | -0.000335    |
|    std                  | 0.853        |
|    value_loss           | 2.3e-05      |
------------------------------------------
Eval num_timesteps=2880000, episode_reward=0.03 +/- 0.07
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | 0.035       |
| time/                   |             |
|    total_timesteps      | 2880000     |
| train/                  |             |
|    approx_kl            | 0.002712249 |
|    clip_fraction        | 0.0264      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.26       |
|    explained_variance   | -0.0638     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0277     |
|    n_updates            | 2808        |
|    policy_gradient_loss | -0.000579   |
|    std                  | 0.853       |
|    value_loss           | 2.06e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 865     |
|    iterations      | 352     |
|    time_elapsed    | 3330    |
|    total_timesteps | 2883584 |
--------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 866          |
|    iterations           | 353          |
|    time_elapsed         | 3336         |
|    total_timesteps      | 2891776      |
| train/                  |              |
|    approx_kl            | 0.0031187022 |
|    clip_fraction        | 0.0264       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.26        |
|    explained_variance   | -0.0759      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.028       |
|    n_updates            | 2816         |
|    policy_gradient_loss | -0.000609    |
|    std                  | 0.852        |
|    value_loss           | 2.16e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 867          |
|    iterations           | 354          |
|    time_elapsed         | 3342         |
|    total_timesteps      | 2899968      |
| train/                  |              |
|    approx_kl            | 0.0031252415 |
|    clip_fraction        | 0.038        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.26        |
|    explained_variance   | -0.0839      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0299      |
|    n_updates            | 2824         |
|    policy_gradient_loss | -0.000644    |
|    std                  | 0.851        |
|    value_loss           | 1.96e-05     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 868         |
|    iterations           | 355         |
|    time_elapsed         | 3347        |
|    total_timesteps      | 2908160     |
| train/                  |             |
|    approx_kl            | 0.003093293 |
|    clip_fraction        | 0.0326      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.26       |
|    explained_variance   | -0.0673     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0271     |
|    n_updates            | 2832        |
|    policy_gradient_loss | -0.0014     |
|    std                  | 0.851       |
|    value_loss           | 2.31e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 869         |
|    iterations           | 356         |
|    time_elapsed         | 3353        |
|    total_timesteps      | 2916352     |
| train/                  |             |
|    approx_kl            | 0.003844732 |
|    clip_fraction        | 0.0321      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.26       |
|    explained_variance   | -0.0626     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0263     |
|    n_updates            | 2840        |
|    policy_gradient_loss | -0.00142    |
|    std                  | 0.851       |
|    value_loss           | 2.47e-05    |
-----------------------------------------
Eval num_timesteps=2920000, episode_reward=0.01 +/- 0.05
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | 0.0105       |
| time/                   |              |
|    total_timesteps      | 2920000      |
| train/                  |              |
|    approx_kl            | 0.0048248237 |
|    clip_fraction        | 0.0347       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.26        |
|    explained_variance   | -0.0572      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0287      |
|    n_updates            | 2848         |
|    policy_gradient_loss | -0.00034     |
|    std                  | 0.851        |
|    value_loss           | 2.37e-05     |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 864     |
|    iterations      | 357     |
|    time_elapsed    | 3381    |
|    total_timesteps | 2924544 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 865         |
|    iterations           | 358         |
|    time_elapsed         | 3386        |
|    total_timesteps      | 2932736     |
| train/                  |             |
|    approx_kl            | 0.002536796 |
|    clip_fraction        | 0.0212      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.26       |
|    explained_variance   | -0.0312     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0278     |
|    n_updates            | 2856        |
|    policy_gradient_loss | -0.00027    |
|    std                  | 0.852       |
|    value_loss           | 2.66e-05    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 866          |
|    iterations           | 359          |
|    time_elapsed         | 3392         |
|    total_timesteps      | 2940928      |
| train/                  |              |
|    approx_kl            | 0.0031042183 |
|    clip_fraction        | 0.0303       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.26        |
|    explained_variance   | -0.041       |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0253      |
|    n_updates            | 2864         |
|    policy_gradient_loss | -0.000691    |
|    std                  | 0.851        |
|    value_loss           | 3.86e-05     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 867         |
|    iterations           | 360         |
|    time_elapsed         | 3397        |
|    total_timesteps      | 2949120     |
| train/                  |             |
|    approx_kl            | 0.004107155 |
|    clip_fraction        | 0.0314      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.26       |
|    explained_variance   | -0.083      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0155     |
|    n_updates            | 2872        |
|    policy_gradient_loss | -0.00032    |
|    std                  | 0.85        |
|    value_loss           | 2.63e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 869         |
|    iterations           | 361         |
|    time_elapsed         | 3402        |
|    total_timesteps      | 2957312     |
| train/                  |             |
|    approx_kl            | 0.003986284 |
|    clip_fraction        | 0.0366      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.26       |
|    explained_variance   | -0.0613     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0277     |
|    n_updates            | 2880        |
|    policy_gradient_loss | -0.000395   |
|    std                  | 0.848       |
|    value_loss           | 2.16e-05    |
-----------------------------------------
Eval num_timesteps=2960000, episode_reward=0.01 +/- 0.08
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | 0.0108      |
| time/                   |             |
|    total_timesteps      | 2960000     |
| train/                  |             |
|    approx_kl            | 0.003866768 |
|    clip_fraction        | 0.0379      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.25       |
|    explained_variance   | -0.0366     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0261     |
|    n_updates            | 2888        |
|    policy_gradient_loss | -0.000526   |
|    std                  | 0.849       |
|    value_loss           | 4.89e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 864     |
|    iterations      | 362     |
|    time_elapsed    | 3430    |
|    total_timesteps | 2965504 |
--------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 865          |
|    iterations           | 363          |
|    time_elapsed         | 3435         |
|    total_timesteps      | 2973696      |
| train/                  |              |
|    approx_kl            | 0.0032145232 |
|    clip_fraction        | 0.034        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.26        |
|    explained_variance   | -0.0486      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0264      |
|    n_updates            | 2896         |
|    policy_gradient_loss | -0.000338    |
|    std                  | 0.849        |
|    value_loss           | 3.16e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 866          |
|    iterations           | 364          |
|    time_elapsed         | 3440         |
|    total_timesteps      | 2981888      |
| train/                  |              |
|    approx_kl            | 0.0045999573 |
|    clip_fraction        | 0.0457       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.25        |
|    explained_variance   | -0.0345      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0272      |
|    n_updates            | 2904         |
|    policy_gradient_loss | -0.000286    |
|    std                  | 0.848        |
|    value_loss           | 3.13e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 867          |
|    iterations           | 365          |
|    time_elapsed         | 3444         |
|    total_timesteps      | 2990080      |
| train/                  |              |
|    approx_kl            | 0.0032723984 |
|    clip_fraction        | 0.0362       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.25        |
|    explained_variance   | -0.0595      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0312      |
|    n_updates            | 2912         |
|    policy_gradient_loss | -0.000656    |
|    std                  | 0.847        |
|    value_loss           | 3.48e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 869          |
|    iterations           | 366          |
|    time_elapsed         | 3449         |
|    total_timesteps      | 2998272      |
| train/                  |              |
|    approx_kl            | 0.0033427482 |
|    clip_fraction        | 0.0409       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.25        |
|    explained_variance   | -0.0475      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0205      |
|    n_updates            | 2920         |
|    policy_gradient_loss | 0.00138      |
|    std                  | 0.848        |
|    value_loss           | 2.71e-05     |
------------------------------------------
Eval num_timesteps=3000000, episode_reward=0.01 +/- 0.05
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | 0.0119      |
| time/                   |             |
|    total_timesteps      | 3000000     |
| train/                  |             |
|    approx_kl            | 0.003944739 |
|    clip_fraction        | 0.0463      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.26       |
|    explained_variance   | -0.0296     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0231     |
|    n_updates            | 2928        |
|    policy_gradient_loss | -0.000623   |
|    std                  | 0.85        |
|    value_loss           | 4.65e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 864     |
|    iterations      | 367     |
|    time_elapsed    | 3478    |
|    total_timesteps | 3006464 |
--------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 865          |
|    iterations           | 368          |
|    time_elapsed         | 3484         |
|    total_timesteps      | 3014656      |
| train/                  |              |
|    approx_kl            | 0.0042539747 |
|    clip_fraction        | 0.0463       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.26        |
|    explained_variance   | -0.0358      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0272      |
|    n_updates            | 2936         |
|    policy_gradient_loss | 0.000244     |
|    std                  | 0.851        |
|    value_loss           | 3.68e-05     |
------------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 866        |
|    iterations           | 369        |
|    time_elapsed         | 3489       |
|    total_timesteps      | 3022848    |
| train/                  |            |
|    approx_kl            | 0.00528474 |
|    clip_fraction        | 0.0543     |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.26      |
|    explained_variance   | -0.0957    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0266    |
|    n_updates            | 2944       |
|    policy_gradient_loss | 0.000241   |
|    std                  | 0.851      |
|    value_loss           | 1.43e-05   |
----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 867          |
|    iterations           | 370          |
|    time_elapsed         | 3495         |
|    total_timesteps      | 3031040      |
| train/                  |              |
|    approx_kl            | 0.0049092583 |
|    clip_fraction        | 0.058        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.26        |
|    explained_variance   | -0.0682      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0184      |
|    n_updates            | 2952         |
|    policy_gradient_loss | 0.00118      |
|    std                  | 0.851        |
|    value_loss           | 2.35e-05     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 868         |
|    iterations           | 371         |
|    time_elapsed         | 3500        |
|    total_timesteps      | 3039232     |
| train/                  |             |
|    approx_kl            | 0.006911898 |
|    clip_fraction        | 0.0803      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.26       |
|    explained_variance   | -0.11       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0289     |
|    n_updates            | 2960        |
|    policy_gradient_loss | -0.000276   |
|    std                  | 0.85        |
|    value_loss           | 1.2e-05     |
-----------------------------------------
Eval num_timesteps=3040000, episode_reward=-0.02 +/- 0.07
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | -0.0218      |
| time/                   |              |
|    total_timesteps      | 3040000      |
| train/                  |              |
|    approx_kl            | 0.0049867877 |
|    clip_fraction        | 0.0556       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.26        |
|    explained_variance   | -0.0631      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0259      |
|    n_updates            | 2968         |
|    policy_gradient_loss | 0.000835     |
|    std                  | 0.85         |
|    value_loss           | 2.04e-05     |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 863     |
|    iterations      | 372     |
|    time_elapsed    | 3529    |
|    total_timesteps | 3047424 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 864         |
|    iterations           | 373         |
|    time_elapsed         | 3534        |
|    total_timesteps      | 3055616     |
| train/                  |             |
|    approx_kl            | 0.005907054 |
|    clip_fraction        | 0.0696      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.26       |
|    explained_variance   | -0.0196     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0312     |
|    n_updates            | 2976        |
|    policy_gradient_loss | 0.000815    |
|    std                  | 0.851       |
|    value_loss           | 4.45e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 865         |
|    iterations           | 374         |
|    time_elapsed         | 3539        |
|    total_timesteps      | 3063808     |
| train/                  |             |
|    approx_kl            | 0.006772875 |
|    clip_fraction        | 0.072       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.26       |
|    explained_variance   | -0.0455     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0245     |
|    n_updates            | 2984        |
|    policy_gradient_loss | 0.00207     |
|    std                  | 0.85        |
|    value_loss           | 2.67e-05    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 866          |
|    iterations           | 375          |
|    time_elapsed         | 3545         |
|    total_timesteps      | 3072000      |
| train/                  |              |
|    approx_kl            | 0.0064651305 |
|    clip_fraction        | 0.0823       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.26        |
|    explained_variance   | -0.0452      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0279      |
|    n_updates            | 2992         |
|    policy_gradient_loss | 0.00121      |
|    std                  | 0.85         |
|    value_loss           | 3.6e-05      |
------------------------------------------
Eval num_timesteps=3080000, episode_reward=0.01 +/- 0.09
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | 0.0143      |
| time/                   |             |
|    total_timesteps      | 3080000     |
| train/                  |             |
|    approx_kl            | 0.006553097 |
|    clip_fraction        | 0.0773      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.26       |
|    explained_variance   | -0.0538     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0252     |
|    n_updates            | 3000        |
|    policy_gradient_loss | 0.00283     |
|    std                  | 0.849       |
|    value_loss           | 3.03e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 861     |
|    iterations      | 376     |
|    time_elapsed    | 3574    |
|    total_timesteps | 3080192 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 862         |
|    iterations           | 377         |
|    time_elapsed         | 3580        |
|    total_timesteps      | 3088384     |
| train/                  |             |
|    approx_kl            | 0.008935882 |
|    clip_fraction        | 0.0982      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.25       |
|    explained_variance   | -0.0655     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0267     |
|    n_updates            | 3008        |
|    policy_gradient_loss | 0.00208     |
|    std                  | 0.848       |
|    value_loss           | 2.05e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 863         |
|    iterations           | 378         |
|    time_elapsed         | 3585        |
|    total_timesteps      | 3096576     |
| train/                  |             |
|    approx_kl            | 0.009261394 |
|    clip_fraction        | 0.102       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.25       |
|    explained_variance   | -0.0488     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.023      |
|    n_updates            | 3016        |
|    policy_gradient_loss | 0.00187     |
|    std                  | 0.848       |
|    value_loss           | 2.91e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 864         |
|    iterations           | 379         |
|    time_elapsed         | 3591        |
|    total_timesteps      | 3104768     |
| train/                  |             |
|    approx_kl            | 0.008968038 |
|    clip_fraction        | 0.11        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.26       |
|    explained_variance   | -0.0751     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0244     |
|    n_updates            | 3024        |
|    policy_gradient_loss | 0.000842    |
|    std                  | 0.849       |
|    value_loss           | 1.51e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 865         |
|    iterations           | 380         |
|    time_elapsed         | 3596        |
|    total_timesteps      | 3112960     |
| train/                  |             |
|    approx_kl            | 0.008535411 |
|    clip_fraction        | 0.103       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.26       |
|    explained_variance   | -0.0114     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0253     |
|    n_updates            | 3032        |
|    policy_gradient_loss | 0.0033      |
|    std                  | 0.849       |
|    value_loss           | 4.49e-05    |
-----------------------------------------
Eval num_timesteps=3120000, episode_reward=-0.00 +/- 0.06
Episode length: 2340.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 2.34e+03   |
|    mean_reward          | -0.00128   |
| time/                   |            |
|    total_timesteps      | 3120000    |
| train/                  |            |
|    approx_kl            | 0.00800468 |
|    clip_fraction        | 0.0999     |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.25      |
|    explained_variance   | -0.000106  |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0228    |
|    n_updates            | 3040       |
|    policy_gradient_loss | 0.00337    |
|    std                  | 0.848      |
|    value_loss           | 2.59e-05   |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 860     |
|    iterations      | 381     |
|    time_elapsed    | 3625    |
|    total_timesteps | 3121152 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 861         |
|    iterations           | 382         |
|    time_elapsed         | 3630        |
|    total_timesteps      | 3129344     |
| train/                  |             |
|    approx_kl            | 0.007615164 |
|    clip_fraction        | 0.101       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.25       |
|    explained_variance   | -0.0651     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0207     |
|    n_updates            | 3048        |
|    policy_gradient_loss | 0.00259     |
|    std                  | 0.847       |
|    value_loss           | 2.12e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 862         |
|    iterations           | 383         |
|    time_elapsed         | 3636        |
|    total_timesteps      | 3137536     |
| train/                  |             |
|    approx_kl            | 0.007966349 |
|    clip_fraction        | 0.0944      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.25       |
|    explained_variance   | -0.0374     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0284     |
|    n_updates            | 3056        |
|    policy_gradient_loss | 0.00373     |
|    std                  | 0.847       |
|    value_loss           | 3.22e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 863         |
|    iterations           | 384         |
|    time_elapsed         | 3641        |
|    total_timesteps      | 3145728     |
| train/                  |             |
|    approx_kl            | 0.009303015 |
|    clip_fraction        | 0.111       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.25       |
|    explained_variance   | -0.0257     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0166     |
|    n_updates            | 3064        |
|    policy_gradient_loss | 0.00352     |
|    std                  | 0.847       |
|    value_loss           | 3.52e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 864         |
|    iterations           | 385         |
|    time_elapsed         | 3647        |
|    total_timesteps      | 3153920     |
| train/                  |             |
|    approx_kl            | 0.009055613 |
|    clip_fraction        | 0.117       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.25       |
|    explained_variance   | -0.0676     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0289     |
|    n_updates            | 3072        |
|    policy_gradient_loss | 0.00172     |
|    std                  | 0.847       |
|    value_loss           | 2.6e-05     |
-----------------------------------------
Eval num_timesteps=3160000, episode_reward=0.09 +/- 0.09
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | 0.092       |
| time/                   |             |
|    total_timesteps      | 3160000     |
| train/                  |             |
|    approx_kl            | 0.010071466 |
|    clip_fraction        | 0.117       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.25       |
|    explained_variance   | -0.015      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0287     |
|    n_updates            | 3080        |
|    policy_gradient_loss | 0.00256     |
|    std                  | 0.846       |
|    value_loss           | 3.48e-05    |
-----------------------------------------
New best mean reward!
--------------------------------
| time/              |         |
|    fps             | 860     |
|    iterations      | 386     |
|    time_elapsed    | 3676    |
|    total_timesteps | 3162112 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 861         |
|    iterations           | 387         |
|    time_elapsed         | 3681        |
|    total_timesteps      | 3170304     |
| train/                  |             |
|    approx_kl            | 0.009605639 |
|    clip_fraction        | 0.113       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.25       |
|    explained_variance   | -0.0312     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0265     |
|    n_updates            | 3088        |
|    policy_gradient_loss | 0.00334     |
|    std                  | 0.845       |
|    value_loss           | 4.45e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 862         |
|    iterations           | 388         |
|    time_elapsed         | 3687        |
|    total_timesteps      | 3178496     |
| train/                  |             |
|    approx_kl            | 0.011120573 |
|    clip_fraction        | 0.132       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.25       |
|    explained_variance   | -0.0323     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0253     |
|    n_updates            | 3096        |
|    policy_gradient_loss | 0.0044      |
|    std                  | 0.844       |
|    value_loss           | 2.6e-05     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 863         |
|    iterations           | 389         |
|    time_elapsed         | 3692        |
|    total_timesteps      | 3186688     |
| train/                  |             |
|    approx_kl            | 0.010969631 |
|    clip_fraction        | 0.131       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.25       |
|    explained_variance   | -0.0139     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0229     |
|    n_updates            | 3104        |
|    policy_gradient_loss | 0.00351     |
|    std                  | 0.843       |
|    value_loss           | 4.32e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 863         |
|    iterations           | 390         |
|    time_elapsed         | 3697        |
|    total_timesteps      | 3194880     |
| train/                  |             |
|    approx_kl            | 0.010874032 |
|    clip_fraction        | 0.134       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.25       |
|    explained_variance   | -0.000844   |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0325     |
|    n_updates            | 3112        |
|    policy_gradient_loss | 0.00385     |
|    std                  | 0.843       |
|    value_loss           | 5.73e-05    |
-----------------------------------------
Eval num_timesteps=3200000, episode_reward=-0.09 +/- 0.14
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.0862     |
| time/                   |             |
|    total_timesteps      | 3200000     |
| train/                  |             |
|    approx_kl            | 0.014140192 |
|    clip_fraction        | 0.148       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.25       |
|    explained_variance   | -0.01       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0226     |
|    n_updates            | 3120        |
|    policy_gradient_loss | 0.00451     |
|    std                  | 0.842       |
|    value_loss           | 2.5e-05     |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 859     |
|    iterations      | 391     |
|    time_elapsed    | 3727    |
|    total_timesteps | 3203072 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 860         |
|    iterations           | 392         |
|    time_elapsed         | 3732        |
|    total_timesteps      | 3211264     |
| train/                  |             |
|    approx_kl            | 0.011807242 |
|    clip_fraction        | 0.139       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.25       |
|    explained_variance   | -0.0218     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0188     |
|    n_updates            | 3128        |
|    policy_gradient_loss | 0.00513     |
|    std                  | 0.84        |
|    value_loss           | 1.61e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 861         |
|    iterations           | 393         |
|    time_elapsed         | 3737        |
|    total_timesteps      | 3219456     |
| train/                  |             |
|    approx_kl            | 0.012348633 |
|    clip_fraction        | 0.144       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.24       |
|    explained_variance   | -0.00443    |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0224     |
|    n_updates            | 3136        |
|    policy_gradient_loss | 0.00285     |
|    std                  | 0.839       |
|    value_loss           | 2.58e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 862         |
|    iterations           | 394         |
|    time_elapsed         | 3742        |
|    total_timesteps      | 3227648     |
| train/                  |             |
|    approx_kl            | 0.011427224 |
|    clip_fraction        | 0.129       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.24       |
|    explained_variance   | -0.01       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0209     |
|    n_updates            | 3144        |
|    policy_gradient_loss | 0.00561     |
|    std                  | 0.838       |
|    value_loss           | 3.14e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 863         |
|    iterations           | 395         |
|    time_elapsed         | 3747        |
|    total_timesteps      | 3235840     |
| train/                  |             |
|    approx_kl            | 0.012488513 |
|    clip_fraction        | 0.15        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.24       |
|    explained_variance   | -0.0557     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0232     |
|    n_updates            | 3152        |
|    policy_gradient_loss | 0.00229     |
|    std                  | 0.837       |
|    value_loss           | 1.56e-05    |
-----------------------------------------
Eval num_timesteps=3240000, episode_reward=0.03 +/- 0.05
Episode length: 2340.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 2.34e+03   |
|    mean_reward          | 0.0267     |
| time/                   |            |
|    total_timesteps      | 3240000    |
| train/                  |            |
|    approx_kl            | 0.01200331 |
|    clip_fraction        | 0.147      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.24      |
|    explained_variance   | 0.0077     |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0275    |
|    n_updates            | 3160       |
|    policy_gradient_loss | 0.00346    |
|    std                  | 0.836      |
|    value_loss           | 2.31e-05   |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 859     |
|    iterations      | 396     |
|    time_elapsed    | 3774    |
|    total_timesteps | 3244032 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 860         |
|    iterations           | 397         |
|    time_elapsed         | 3779        |
|    total_timesteps      | 3252224     |
| train/                  |             |
|    approx_kl            | 0.012942325 |
|    clip_fraction        | 0.15        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.24       |
|    explained_variance   | -0.0353     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0291     |
|    n_updates            | 3168        |
|    policy_gradient_loss | 0.00333     |
|    std                  | 0.834       |
|    value_loss           | 1.65e-05    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 861          |
|    iterations           | 398          |
|    time_elapsed         | 3784         |
|    total_timesteps      | 3260416      |
| train/                  |              |
|    approx_kl            | 0.0118072815 |
|    clip_fraction        | 0.13         |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.24        |
|    explained_variance   | -0.0142      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0202      |
|    n_updates            | 3176         |
|    policy_gradient_loss | 0.0043       |
|    std                  | 0.833        |
|    value_loss           | 2.79e-05     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 862         |
|    iterations           | 399         |
|    time_elapsed         | 3789        |
|    total_timesteps      | 3268608     |
| train/                  |             |
|    approx_kl            | 0.012631791 |
|    clip_fraction        | 0.138       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.24       |
|    explained_variance   | -0.0327     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0203     |
|    n_updates            | 3184        |
|    policy_gradient_loss | 0.00361     |
|    std                  | 0.832       |
|    value_loss           | 4e-05       |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 863         |
|    iterations           | 400         |
|    time_elapsed         | 3794        |
|    total_timesteps      | 3276800     |
| train/                  |             |
|    approx_kl            | 0.011620329 |
|    clip_fraction        | 0.128       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.23       |
|    explained_variance   | -0.0718     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0232     |
|    n_updates            | 3192        |
|    policy_gradient_loss | 0.00471     |
|    std                  | 0.831       |
|    value_loss           | 2.76e-05    |
-----------------------------------------
Eval num_timesteps=3280000, episode_reward=0.01 +/- 0.09
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | 0.0094      |
| time/                   |             |
|    total_timesteps      | 3280000     |
| train/                  |             |
|    approx_kl            | 0.012952707 |
|    clip_fraction        | 0.149       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.23       |
|    explained_variance   | -0.0623     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0211     |
|    n_updates            | 3200        |
|    policy_gradient_loss | 0.0039      |
|    std                  | 0.829       |
|    value_loss           | 1.33e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 859     |
|    iterations      | 401     |
|    time_elapsed    | 3820    |
|    total_timesteps | 3284992 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 860         |
|    iterations           | 402         |
|    time_elapsed         | 3825        |
|    total_timesteps      | 3293184     |
| train/                  |             |
|    approx_kl            | 0.014167219 |
|    clip_fraction        | 0.155       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.23       |
|    explained_variance   | -0.0307     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0228     |
|    n_updates            | 3208        |
|    policy_gradient_loss | 0.00185     |
|    std                  | 0.827       |
|    value_loss           | 1.54e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 862         |
|    iterations           | 403         |
|    time_elapsed         | 3829        |
|    total_timesteps      | 3301376     |
| train/                  |             |
|    approx_kl            | 0.011969099 |
|    clip_fraction        | 0.129       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.23       |
|    explained_variance   | -0.018      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0208     |
|    n_updates            | 3216        |
|    policy_gradient_loss | 0.00401     |
|    std                  | 0.825       |
|    value_loss           | 3.77e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 863         |
|    iterations           | 404         |
|    time_elapsed         | 3834        |
|    total_timesteps      | 3309568     |
| train/                  |             |
|    approx_kl            | 0.012816803 |
|    clip_fraction        | 0.139       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.23       |
|    explained_variance   | -0.0174     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.017      |
|    n_updates            | 3224        |
|    policy_gradient_loss | 0.00378     |
|    std                  | 0.823       |
|    value_loss           | 4.93e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 864         |
|    iterations           | 405         |
|    time_elapsed         | 3838        |
|    total_timesteps      | 3317760     |
| train/                  |             |
|    approx_kl            | 0.011266166 |
|    clip_fraction        | 0.127       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.22       |
|    explained_variance   | -0.00856    |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0161     |
|    n_updates            | 3232        |
|    policy_gradient_loss | 0.00536     |
|    std                  | 0.822       |
|    value_loss           | 3.97e-05    |
-----------------------------------------
Eval num_timesteps=3320000, episode_reward=-0.06 +/- 0.12
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.0557     |
| time/                   |             |
|    total_timesteps      | 3320000     |
| train/                  |             |
|    approx_kl            | 0.012788869 |
|    clip_fraction        | 0.137       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.22       |
|    explained_variance   | -0.0227     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.025      |
|    n_updates            | 3240        |
|    policy_gradient_loss | 0.00374     |
|    std                  | 0.819       |
|    value_loss           | 3.83e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 860     |
|    iterations      | 406     |
|    time_elapsed    | 3863    |
|    total_timesteps | 3325952 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 861         |
|    iterations           | 407         |
|    time_elapsed         | 3868        |
|    total_timesteps      | 3334144     |
| train/                  |             |
|    approx_kl            | 0.011770828 |
|    clip_fraction        | 0.13        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.22       |
|    explained_variance   | -0.0388     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0179     |
|    n_updates            | 3248        |
|    policy_gradient_loss | 0.00513     |
|    std                  | 0.818       |
|    value_loss           | 3.27e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 863         |
|    iterations           | 408         |
|    time_elapsed         | 3872        |
|    total_timesteps      | 3342336     |
| train/                  |             |
|    approx_kl            | 0.014236117 |
|    clip_fraction        | 0.145       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.22       |
|    explained_variance   | -0.0152     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0165     |
|    n_updates            | 3256        |
|    policy_gradient_loss | 0.00339     |
|    std                  | 0.817       |
|    value_loss           | 4.34e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 864         |
|    iterations           | 409         |
|    time_elapsed         | 3877        |
|    total_timesteps      | 3350528     |
| train/                  |             |
|    approx_kl            | 0.011953073 |
|    clip_fraction        | 0.128       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.22       |
|    explained_variance   | -0.0236     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0228     |
|    n_updates            | 3264        |
|    policy_gradient_loss | 0.00332     |
|    std                  | 0.816       |
|    value_loss           | 2.85e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 865         |
|    iterations           | 410         |
|    time_elapsed         | 3881        |
|    total_timesteps      | 3358720     |
| train/                  |             |
|    approx_kl            | 0.013208628 |
|    clip_fraction        | 0.128       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.22       |
|    explained_variance   | -0.00214    |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0225     |
|    n_updates            | 3272        |
|    policy_gradient_loss | 0.00342     |
|    std                  | 0.816       |
|    value_loss           | 6.72e-05    |
-----------------------------------------
Eval num_timesteps=3360000, episode_reward=-0.00 +/- 0.08
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.00484    |
| time/                   |             |
|    total_timesteps      | 3360000     |
| train/                  |             |
|    approx_kl            | 0.014659476 |
|    clip_fraction        | 0.142       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.21       |
|    explained_variance   | -0.0162     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0151     |
|    n_updates            | 3280        |
|    policy_gradient_loss | 0.00484     |
|    std                  | 0.814       |
|    value_loss           | 1.94e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 861     |
|    iterations      | 411     |
|    time_elapsed    | 3906    |
|    total_timesteps | 3366912 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 862         |
|    iterations           | 412         |
|    time_elapsed         | 3911        |
|    total_timesteps      | 3375104     |
| train/                  |             |
|    approx_kl            | 0.013855876 |
|    clip_fraction        | 0.143       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.21       |
|    explained_variance   | 0.00231     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0225     |
|    n_updates            | 3288        |
|    policy_gradient_loss | 0.00268     |
|    std                  | 0.813       |
|    value_loss           | 1.98e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 864         |
|    iterations           | 413         |
|    time_elapsed         | 3915        |
|    total_timesteps      | 3383296     |
| train/                  |             |
|    approx_kl            | 0.013261125 |
|    clip_fraction        | 0.136       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.21       |
|    explained_variance   | -0.0459     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0186     |
|    n_updates            | 3296        |
|    policy_gradient_loss | 0.00448     |
|    std                  | 0.812       |
|    value_loss           | 2.54e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 865         |
|    iterations           | 414         |
|    time_elapsed         | 3920        |
|    total_timesteps      | 3391488     |
| train/                  |             |
|    approx_kl            | 0.012222076 |
|    clip_fraction        | 0.118       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.21       |
|    explained_variance   | -0.0381     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0186     |
|    n_updates            | 3304        |
|    policy_gradient_loss | 0.00383     |
|    std                  | 0.812       |
|    value_loss           | 5.11e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 866         |
|    iterations           | 415         |
|    time_elapsed         | 3924        |
|    total_timesteps      | 3399680     |
| train/                  |             |
|    approx_kl            | 0.013036718 |
|    clip_fraction        | 0.123       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.21       |
|    explained_variance   | -0.0306     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0208     |
|    n_updates            | 3312        |
|    policy_gradient_loss | 0.00366     |
|    std                  | 0.812       |
|    value_loss           | 4.84e-05    |
-----------------------------------------
Eval num_timesteps=3400000, episode_reward=-0.01 +/- 0.09
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.00997    |
| time/                   |             |
|    total_timesteps      | 3400000     |
| train/                  |             |
|    approx_kl            | 0.013210394 |
|    clip_fraction        | 0.149       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.21       |
|    explained_variance   | -0.0422     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0211     |
|    n_updates            | 3320        |
|    policy_gradient_loss | 0.00472     |
|    std                  | 0.81        |
|    value_loss           | 2.54e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 862     |
|    iterations      | 416     |
|    time_elapsed    | 3950    |
|    total_timesteps | 3407872 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 863         |
|    iterations           | 417         |
|    time_elapsed         | 3954        |
|    total_timesteps      | 3416064     |
| train/                  |             |
|    approx_kl            | 0.015719794 |
|    clip_fraction        | 0.146       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.21       |
|    explained_variance   | -0.00786    |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0222     |
|    n_updates            | 3328        |
|    policy_gradient_loss | 0.00328     |
|    std                  | 0.809       |
|    value_loss           | 4.81e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 864         |
|    iterations           | 418         |
|    time_elapsed         | 3959        |
|    total_timesteps      | 3424256     |
| train/                  |             |
|    approx_kl            | 0.014574109 |
|    clip_fraction        | 0.135       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.21       |
|    explained_variance   | -0.0186     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.016      |
|    n_updates            | 3336        |
|    policy_gradient_loss | 0.00578     |
|    std                  | 0.808       |
|    value_loss           | 3.46e-05    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 865          |
|    iterations           | 419          |
|    time_elapsed         | 3963         |
|    total_timesteps      | 3432448      |
| train/                  |              |
|    approx_kl            | 0.0147852665 |
|    clip_fraction        | 0.137        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.2         |
|    explained_variance   | -0.0647      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0174      |
|    n_updates            | 3344         |
|    policy_gradient_loss | 0.00359      |
|    std                  | 0.806        |
|    value_loss           | 1.79e-05     |
------------------------------------------
Eval num_timesteps=3440000, episode_reward=0.02 +/- 0.11
Episode length: 2340.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 2.34e+03     |
|    mean_reward          | 0.0223       |
| time/                   |              |
|    total_timesteps      | 3440000      |
| train/                  |              |
|    approx_kl            | 0.0144194495 |
|    clip_fraction        | 0.136        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.2         |
|    explained_variance   | -0.0879      |
|    learning_rate        | 5e-05        |
|    loss                 | -0.0242      |
|    n_updates            | 3352         |
|    policy_gradient_loss | 0.00419      |
|    std                  | 0.804        |
|    value_loss           | 1.33e-05     |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 862     |
|    iterations      | 420     |
|    time_elapsed    | 3989    |
|    total_timesteps | 3440640 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 863         |
|    iterations           | 421         |
|    time_elapsed         | 3993        |
|    total_timesteps      | 3448832     |
| train/                  |             |
|    approx_kl            | 0.015141933 |
|    clip_fraction        | 0.142       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.2        |
|    explained_variance   | -0.0582     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0125     |
|    n_updates            | 3360        |
|    policy_gradient_loss | 0.00546     |
|    std                  | 0.803       |
|    value_loss           | 1.74e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 864         |
|    iterations           | 422         |
|    time_elapsed         | 3998        |
|    total_timesteps      | 3457024     |
| train/                  |             |
|    approx_kl            | 0.016267968 |
|    clip_fraction        | 0.141       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.2        |
|    explained_variance   | -0.0329     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.019      |
|    n_updates            | 3368        |
|    policy_gradient_loss | 0.00443     |
|    std                  | 0.801       |
|    value_loss           | 2.2e-05     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 865         |
|    iterations           | 423         |
|    time_elapsed         | 4002        |
|    total_timesteps      | 3465216     |
| train/                  |             |
|    approx_kl            | 0.015428696 |
|    clip_fraction        | 0.155       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.2        |
|    explained_variance   | -0.0193     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0195     |
|    n_updates            | 3376        |
|    policy_gradient_loss | 0.0043      |
|    std                  | 0.8         |
|    value_loss           | 3.26e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 866         |
|    iterations           | 424         |
|    time_elapsed         | 4006        |
|    total_timesteps      | 3473408     |
| train/                  |             |
|    approx_kl            | 0.014118562 |
|    clip_fraction        | 0.132       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.2        |
|    explained_variance   | -0.0201     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0206     |
|    n_updates            | 3384        |
|    policy_gradient_loss | 0.00447     |
|    std                  | 0.799       |
|    value_loss           | 2.64e-05    |
-----------------------------------------
Eval num_timesteps=3480000, episode_reward=0.01 +/- 0.09
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | 0.00603     |
| time/                   |             |
|    total_timesteps      | 3480000     |
| train/                  |             |
|    approx_kl            | 0.014954006 |
|    clip_fraction        | 0.149       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.19       |
|    explained_variance   | -0.0497     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0218     |
|    n_updates            | 3392        |
|    policy_gradient_loss | 0.0045      |
|    std                  | 0.797       |
|    value_loss           | 2.58e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 863     |
|    iterations      | 425     |
|    time_elapsed    | 4033    |
|    total_timesteps | 3481600 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 864         |
|    iterations           | 426         |
|    time_elapsed         | 4038        |
|    total_timesteps      | 3489792     |
| train/                  |             |
|    approx_kl            | 0.015393527 |
|    clip_fraction        | 0.131       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.19       |
|    explained_variance   | -0.0106     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0148     |
|    n_updates            | 3400        |
|    policy_gradient_loss | 0.00522     |
|    std                  | 0.797       |
|    value_loss           | 3.71e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 864         |
|    iterations           | 427         |
|    time_elapsed         | 4044        |
|    total_timesteps      | 3497984     |
| train/                  |             |
|    approx_kl            | 0.015986357 |
|    clip_fraction        | 0.13        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.19       |
|    explained_variance   | -0.0185     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0235     |
|    n_updates            | 3408        |
|    policy_gradient_loss | 0.00615     |
|    std                  | 0.797       |
|    value_loss           | 3.74e-05    |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 865        |
|    iterations           | 428        |
|    time_elapsed         | 4051       |
|    total_timesteps      | 3506176    |
| train/                  |            |
|    approx_kl            | 0.01695972 |
|    clip_fraction        | 0.148      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.19      |
|    explained_variance   | -0.0186    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0271    |
|    n_updates            | 3416       |
|    policy_gradient_loss | 0.00438    |
|    std                  | 0.796      |
|    value_loss           | 4.16e-05   |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 866         |
|    iterations           | 429         |
|    time_elapsed         | 4056        |
|    total_timesteps      | 3514368     |
| train/                  |             |
|    approx_kl            | 0.016645398 |
|    clip_fraction        | 0.141       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.19       |
|    explained_variance   | -0.00203    |
|    learning_rate        | 5e-05       |
|    loss                 | -0.021      |
|    n_updates            | 3424        |
|    policy_gradient_loss | 0.0052      |
|    std                  | 0.795       |
|    value_loss           | 5.31e-05    |
-----------------------------------------
Eval num_timesteps=3520000, episode_reward=-0.01 +/- 0.06
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.0149     |
| time/                   |             |
|    total_timesteps      | 3520000     |
| train/                  |             |
|    approx_kl            | 0.017239068 |
|    clip_fraction        | 0.143       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.19       |
|    explained_variance   | -0.00789    |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0241     |
|    n_updates            | 3432        |
|    policy_gradient_loss | 0.00448     |
|    std                  | 0.795       |
|    value_loss           | 3.69e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 862     |
|    iterations      | 430     |
|    time_elapsed    | 4083    |
|    total_timesteps | 3522560 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 863         |
|    iterations           | 431         |
|    time_elapsed         | 4088        |
|    total_timesteps      | 3530752     |
| train/                  |             |
|    approx_kl            | 0.016117003 |
|    clip_fraction        | 0.134       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.19       |
|    explained_variance   | -0.113      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.017      |
|    n_updates            | 3440        |
|    policy_gradient_loss | 0.00404     |
|    std                  | 0.794       |
|    value_loss           | 2.17e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 864         |
|    iterations           | 432         |
|    time_elapsed         | 4093        |
|    total_timesteps      | 3538944     |
| train/                  |             |
|    approx_kl            | 0.015428448 |
|    clip_fraction        | 0.135       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.19       |
|    explained_variance   | -0.0498     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0268     |
|    n_updates            | 3448        |
|    policy_gradient_loss | 0.00304     |
|    std                  | 0.794       |
|    value_loss           | 2.15e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 865         |
|    iterations           | 433         |
|    time_elapsed         | 4098        |
|    total_timesteps      | 3547136     |
| train/                  |             |
|    approx_kl            | 0.017159825 |
|    clip_fraction        | 0.125       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.19       |
|    explained_variance   | -0.0337     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0195     |
|    n_updates            | 3456        |
|    policy_gradient_loss | 0.00433     |
|    std                  | 0.794       |
|    value_loss           | 2.88e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 866         |
|    iterations           | 434         |
|    time_elapsed         | 4103        |
|    total_timesteps      | 3555328     |
| train/                  |             |
|    approx_kl            | 0.016939446 |
|    clip_fraction        | 0.128       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.19       |
|    explained_variance   | -0.0294     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.019      |
|    n_updates            | 3464        |
|    policy_gradient_loss | 0.00501     |
|    std                  | 0.794       |
|    value_loss           | 3.15e-05    |
-----------------------------------------
Early stopping at step 1 due to reaching max kl: 0.03
Eval num_timesteps=3560000, episode_reward=-0.01 +/- 0.06
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.0104     |
| time/                   |             |
|    total_timesteps      | 3560000     |
| train/                  |             |
|    approx_kl            | 0.020307476 |
|    clip_fraction        | 0.124       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.19       |
|    explained_variance   | -0.0639     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0111     |
|    n_updates            | 3466        |
|    policy_gradient_loss | 0.00705     |
|    std                  | 0.793       |
|    value_loss           | 1.58e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 862     |
|    iterations      | 435     |
|    time_elapsed    | 4129    |
|    total_timesteps | 3563520 |
--------------------------------
Early stopping at step 4 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 864         |
|    iterations           | 436         |
|    time_elapsed         | 4133        |
|    total_timesteps      | 3571712     |
| train/                  |             |
|    approx_kl            | 0.018721601 |
|    clip_fraction        | 0.131       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.19       |
|    explained_variance   | -0.0253     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00329    |
|    n_updates            | 3471        |
|    policy_gradient_loss | 0.00617     |
|    std                  | 0.793       |
|    value_loss           | 3.05e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 864         |
|    iterations           | 437         |
|    time_elapsed         | 4139        |
|    total_timesteps      | 3579904     |
| train/                  |             |
|    approx_kl            | 0.018400155 |
|    clip_fraction        | 0.12        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.19       |
|    explained_variance   | -0.0097     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0198     |
|    n_updates            | 3479        |
|    policy_gradient_loss | 0.00538     |
|    std                  | 0.792       |
|    value_loss           | 5.75e-05    |
-----------------------------------------
Early stopping at step 4 due to reaching max kl: 0.03
----------------------------------------
| time/                   |            |
|    fps                  | 865        |
|    iterations           | 438        |
|    time_elapsed         | 4143       |
|    total_timesteps      | 3588096    |
| train/                  |            |
|    approx_kl            | 0.01765332 |
|    clip_fraction        | 0.11       |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.19      |
|    explained_variance   | -0.0177    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0161    |
|    n_updates            | 3484       |
|    policy_gradient_loss | 0.00597    |
|    std                  | 0.792      |
|    value_loss           | 4.35e-05   |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 866        |
|    iterations           | 439        |
|    time_elapsed         | 4149       |
|    total_timesteps      | 3596288    |
| train/                  |            |
|    approx_kl            | 0.01523421 |
|    clip_fraction        | 0.113      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.19      |
|    explained_variance   | -0.0328    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.021     |
|    n_updates            | 3492       |
|    policy_gradient_loss | 0.0057     |
|    std                  | 0.791      |
|    value_loss           | 2.69e-05   |
----------------------------------------
Eval num_timesteps=3600000, episode_reward=0.03 +/- 0.06
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | 0.0254      |
| time/                   |             |
|    total_timesteps      | 3600000     |
| train/                  |             |
|    approx_kl            | 0.017352903 |
|    clip_fraction        | 0.147       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.18       |
|    explained_variance   | -0.0343     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0254     |
|    n_updates            | 3500        |
|    policy_gradient_loss | 0.00198     |
|    std                  | 0.791       |
|    value_loss           | 2.2e-05     |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 862     |
|    iterations      | 440     |
|    time_elapsed    | 4178    |
|    total_timesteps | 3604480 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 863         |
|    iterations           | 441         |
|    time_elapsed         | 4184        |
|    total_timesteps      | 3612672     |
| train/                  |             |
|    approx_kl            | 0.014873184 |
|    clip_fraction        | 0.115       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.18       |
|    explained_variance   | -0.0334     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00937    |
|    n_updates            | 3508        |
|    policy_gradient_loss | 0.00685     |
|    std                  | 0.789       |
|    value_loss           | 2.77e-05    |
-----------------------------------------
Early stopping at step 3 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 864         |
|    iterations           | 442         |
|    time_elapsed         | 4188        |
|    total_timesteps      | 3620864     |
| train/                  |             |
|    approx_kl            | 0.030466536 |
|    clip_fraction        | 0.115       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.18       |
|    explained_variance   | -0.0107     |
|    learning_rate        | 5e-05       |
|    loss                 | 0.009       |
|    n_updates            | 3512        |
|    policy_gradient_loss | 0.0082      |
|    std                  | 0.788       |
|    value_loss           | 5.02e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 865         |
|    iterations           | 443         |
|    time_elapsed         | 4194        |
|    total_timesteps      | 3629056     |
| train/                  |             |
|    approx_kl            | 0.018789124 |
|    clip_fraction        | 0.134       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.18       |
|    explained_variance   | -0.0457     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0257     |
|    n_updates            | 3520        |
|    policy_gradient_loss | 0.00643     |
|    std                  | 0.788       |
|    value_loss           | 1.88e-05    |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 866        |
|    iterations           | 444        |
|    time_elapsed         | 4199       |
|    total_timesteps      | 3637248    |
| train/                  |            |
|    approx_kl            | 0.01860295 |
|    clip_fraction        | 0.133      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.18      |
|    explained_variance   | -0.045     |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0184    |
|    n_updates            | 3528       |
|    policy_gradient_loss | 0.00558    |
|    std                  | 0.787      |
|    value_loss           | 2.2e-05    |
----------------------------------------
Eval num_timesteps=3640000, episode_reward=-0.00 +/- 0.08
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.00162    |
| time/                   |             |
|    total_timesteps      | 3640000     |
| train/                  |             |
|    approx_kl            | 0.017021284 |
|    clip_fraction        | 0.127       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.18       |
|    explained_variance   | -0.0486     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.022      |
|    n_updates            | 3536        |
|    policy_gradient_loss | 0.00555     |
|    std                  | 0.786       |
|    value_loss           | 2.26e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 862     |
|    iterations      | 445     |
|    time_elapsed    | 4229    |
|    total_timesteps | 3645440 |
--------------------------------
Early stopping at step 2 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 863         |
|    iterations           | 446         |
|    time_elapsed         | 4233        |
|    total_timesteps      | 3653632     |
| train/                  |             |
|    approx_kl            | 0.022667337 |
|    clip_fraction        | 0.114       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.18       |
|    explained_variance   | -0.0295     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0127     |
|    n_updates            | 3539        |
|    policy_gradient_loss | 0.00706     |
|    std                  | 0.786       |
|    value_loss           | 3.76e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 863         |
|    iterations           | 447         |
|    time_elapsed         | 4239        |
|    total_timesteps      | 3661824     |
| train/                  |             |
|    approx_kl            | 0.017192831 |
|    clip_fraction        | 0.125       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.18       |
|    explained_variance   | -0.0153     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0196     |
|    n_updates            | 3547        |
|    policy_gradient_loss | 0.00377     |
|    std                  | 0.787       |
|    value_loss           | 3.1e-05     |
-----------------------------------------
Early stopping at step 2 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 864         |
|    iterations           | 448         |
|    time_elapsed         | 4243        |
|    total_timesteps      | 3670016     |
| train/                  |             |
|    approx_kl            | 0.026898913 |
|    clip_fraction        | 0.137       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.18       |
|    explained_variance   | -0.0545     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.011      |
|    n_updates            | 3550        |
|    policy_gradient_loss | 0.00704     |
|    std                  | 0.787       |
|    value_loss           | 3.14e-05    |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 865        |
|    iterations           | 449        |
|    time_elapsed         | 4249       |
|    total_timesteps      | 3678208    |
| train/                  |            |
|    approx_kl            | 0.01655075 |
|    clip_fraction        | 0.123      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.18      |
|    explained_variance   | -0.0191    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0248    |
|    n_updates            | 3558       |
|    policy_gradient_loss | 0.00317    |
|    std                  | 0.788      |
|    value_loss           | 4.75e-05   |
----------------------------------------
Eval num_timesteps=3680000, episode_reward=0.00 +/- 0.06
Episode length: 2340.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 2.34e+03   |
|    mean_reward          | 0.00438    |
| time/                   |            |
|    total_timesteps      | 3680000    |
| train/                  |            |
|    approx_kl            | 0.02087222 |
|    clip_fraction        | 0.135      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.18      |
|    explained_variance   | -0.0231    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0243    |
|    n_updates            | 3566       |
|    policy_gradient_loss | 0.0035     |
|    std                  | 0.788      |
|    value_loss           | 3.87e-05   |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 861     |
|    iterations      | 450     |
|    time_elapsed    | 4278    |
|    total_timesteps | 3686400 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 862        |
|    iterations           | 451        |
|    time_elapsed         | 4284       |
|    total_timesteps      | 3694592    |
| train/                  |            |
|    approx_kl            | 0.01688945 |
|    clip_fraction        | 0.118      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.18      |
|    explained_variance   | -0.0127    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0159    |
|    n_updates            | 3574       |
|    policy_gradient_loss | 0.00409    |
|    std                  | 0.788      |
|    value_loss           | 4.34e-05   |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 863         |
|    iterations           | 452         |
|    time_elapsed         | 4289        |
|    total_timesteps      | 3702784     |
| train/                  |             |
|    approx_kl            | 0.015313122 |
|    clip_fraction        | 0.109       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.18       |
|    explained_variance   | -0.00956    |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0205     |
|    n_updates            | 3582        |
|    policy_gradient_loss | 0.00557     |
|    std                  | 0.786       |
|    value_loss           | 4.42e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 863         |
|    iterations           | 453         |
|    time_elapsed         | 4295        |
|    total_timesteps      | 3710976     |
| train/                  |             |
|    approx_kl            | 0.017611552 |
|    clip_fraction        | 0.123       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.18       |
|    explained_variance   | -0.0462     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0153     |
|    n_updates            | 3590        |
|    policy_gradient_loss | 0.00528     |
|    std                  | 0.784       |
|    value_loss           | 4.14e-05    |
-----------------------------------------
Early stopping at step 1 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 865         |
|    iterations           | 454         |
|    time_elapsed         | 4299        |
|    total_timesteps      | 3719168     |
| train/                  |             |
|    approx_kl            | 0.026670104 |
|    clip_fraction        | 0.146       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.18       |
|    explained_variance   | -0.0255     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0137     |
|    n_updates            | 3592        |
|    policy_gradient_loss | 0.00638     |
|    std                  | 0.784       |
|    value_loss           | 2.76e-05    |
-----------------------------------------
Eval num_timesteps=3720000, episode_reward=-0.00 +/- 0.06
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.00123    |
| time/                   |             |
|    total_timesteps      | 3720000     |
| train/                  |             |
|    approx_kl            | 0.016652688 |
|    clip_fraction        | 0.127       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.18       |
|    explained_variance   | -0.0522     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0146     |
|    n_updates            | 3600        |
|    policy_gradient_loss | 0.00657     |
|    std                  | 0.784       |
|    value_loss           | 2.19e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 861     |
|    iterations      | 455     |
|    time_elapsed    | 4328    |
|    total_timesteps | 3727360 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 861         |
|    iterations           | 456         |
|    time_elapsed         | 4334        |
|    total_timesteps      | 3735552     |
| train/                  |             |
|    approx_kl            | 0.017849443 |
|    clip_fraction        | 0.132       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.18       |
|    explained_variance   | -0.0205     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0159     |
|    n_updates            | 3608        |
|    policy_gradient_loss | 0.00519     |
|    std                  | 0.785       |
|    value_loss           | 3.83e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 862         |
|    iterations           | 457         |
|    time_elapsed         | 4340        |
|    total_timesteps      | 3743744     |
| train/                  |             |
|    approx_kl            | 0.020405445 |
|    clip_fraction        | 0.112       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.18       |
|    explained_variance   | -0.0514     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0146     |
|    n_updates            | 3616        |
|    policy_gradient_loss | 0.00597     |
|    std                  | 0.787       |
|    value_loss           | 3.58e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 863         |
|    iterations           | 458         |
|    time_elapsed         | 4345        |
|    total_timesteps      | 3751936     |
| train/                  |             |
|    approx_kl            | 0.018621702 |
|    clip_fraction        | 0.12        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.18       |
|    explained_variance   | -0.0758     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0174     |
|    n_updates            | 3624        |
|    policy_gradient_loss | 0.0065      |
|    std                  | 0.785       |
|    value_loss           | 1.8e-05     |
-----------------------------------------
Eval num_timesteps=3760000, episode_reward=0.01 +/- 0.08
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | 0.00829     |
| time/                   |             |
|    total_timesteps      | 3760000     |
| train/                  |             |
|    approx_kl            | 0.020009264 |
|    clip_fraction        | 0.144       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.18       |
|    explained_variance   | -0.037      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.024      |
|    n_updates            | 3632        |
|    policy_gradient_loss | 0.00322     |
|    std                  | 0.785       |
|    value_loss           | 2.41e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 859     |
|    iterations      | 459     |
|    time_elapsed    | 4375    |
|    total_timesteps | 3760128 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 860        |
|    iterations           | 460        |
|    time_elapsed         | 4380       |
|    total_timesteps      | 3768320    |
| train/                  |            |
|    approx_kl            | 0.01794018 |
|    clip_fraction        | 0.116      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.18      |
|    explained_variance   | -0.0701    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0228    |
|    n_updates            | 3640       |
|    policy_gradient_loss | 0.00595    |
|    std                  | 0.784      |
|    value_loss           | 1.68e-05   |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 860         |
|    iterations           | 461         |
|    time_elapsed         | 4386        |
|    total_timesteps      | 3776512     |
| train/                  |             |
|    approx_kl            | 0.018367909 |
|    clip_fraction        | 0.113       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.17       |
|    explained_variance   | -0.0407     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0209     |
|    n_updates            | 3648        |
|    policy_gradient_loss | 0.005       |
|    std                  | 0.783       |
|    value_loss           | 2.34e-05    |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 861        |
|    iterations           | 462        |
|    time_elapsed         | 4392       |
|    total_timesteps      | 3784704    |
| train/                  |            |
|    approx_kl            | 0.01698833 |
|    clip_fraction        | 0.113      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.17      |
|    explained_variance   | -0.0175    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0156    |
|    n_updates            | 3656       |
|    policy_gradient_loss | 0.00569    |
|    std                  | 0.782      |
|    value_loss           | 2.97e-05   |
----------------------------------------
Early stopping at step 7 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 862         |
|    iterations           | 463         |
|    time_elapsed         | 4397        |
|    total_timesteps      | 3792896     |
| train/                  |             |
|    approx_kl            | 0.021783128 |
|    clip_fraction        | 0.123       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.17       |
|    explained_variance   | -0.0511     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0086     |
|    n_updates            | 3664        |
|    policy_gradient_loss | 0.00634     |
|    std                  | 0.78        |
|    value_loss           | 2.26e-05    |
-----------------------------------------
Eval num_timesteps=3800000, episode_reward=-0.02 +/- 0.10
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.0179     |
| time/                   |             |
|    total_timesteps      | 3800000     |
| train/                  |             |
|    approx_kl            | 0.017301712 |
|    clip_fraction        | 0.111       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.17       |
|    explained_variance   | -0.0582     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0225     |
|    n_updates            | 3672        |
|    policy_gradient_loss | 0.00461     |
|    std                  | 0.778       |
|    value_loss           | 1.94e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 859     |
|    iterations      | 464     |
|    time_elapsed    | 4423    |
|    total_timesteps | 3801088 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 860         |
|    iterations           | 465         |
|    time_elapsed         | 4428        |
|    total_timesteps      | 3809280     |
| train/                  |             |
|    approx_kl            | 0.018747594 |
|    clip_fraction        | 0.12        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.17       |
|    explained_variance   | -0.0171     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0158     |
|    n_updates            | 3680        |
|    policy_gradient_loss | 0.00288     |
|    std                  | 0.778       |
|    value_loss           | 6.51e-05    |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 860        |
|    iterations           | 466        |
|    time_elapsed         | 4434       |
|    total_timesteps      | 3817472    |
| train/                  |            |
|    approx_kl            | 0.01651525 |
|    clip_fraction        | 0.101      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.17      |
|    explained_variance   | -0.0144    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0214    |
|    n_updates            | 3688       |
|    policy_gradient_loss | 0.00577    |
|    std                  | 0.778      |
|    value_loss           | 5.86e-05   |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 861         |
|    iterations           | 467         |
|    time_elapsed         | 4439        |
|    total_timesteps      | 3825664     |
| train/                  |             |
|    approx_kl            | 0.014871584 |
|    clip_fraction        | 0.109       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.17       |
|    explained_variance   | -0.0292     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0185     |
|    n_updates            | 3696        |
|    policy_gradient_loss | 0.00441     |
|    std                  | 0.777       |
|    value_loss           | 4.39e-05    |
-----------------------------------------
Early stopping at step 1 due to reaching max kl: 0.04
----------------------------------------
| time/                   |            |
|    fps                  | 862        |
|    iterations           | 468        |
|    time_elapsed         | 4443       |
|    total_timesteps      | 3833856    |
| train/                  |            |
|    approx_kl            | 0.02131314 |
|    clip_fraction        | 0.105      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.17      |
|    explained_variance   | -0.0715    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0212    |
|    n_updates            | 3698       |
|    policy_gradient_loss | 0.00515    |
|    std                  | 0.777      |
|    value_loss           | 1.41e-05   |
----------------------------------------
Early stopping at step 3 due to reaching max kl: 0.03
Eval num_timesteps=3840000, episode_reward=0.06 +/- 0.06
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | 0.061       |
| time/                   |             |
|    total_timesteps      | 3840000     |
| train/                  |             |
|    approx_kl            | 0.022257973 |
|    clip_fraction        | 0.114       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.17       |
|    explained_variance   | -0.0557     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0215     |
|    n_updates            | 3702        |
|    policy_gradient_loss | 0.00528     |
|    std                  | 0.776       |
|    value_loss           | 1.95e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 858     |
|    iterations      | 469     |
|    time_elapsed    | 4473    |
|    total_timesteps | 3842048 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 859         |
|    iterations           | 470         |
|    time_elapsed         | 4478        |
|    total_timesteps      | 3850240     |
| train/                  |             |
|    approx_kl            | 0.018536577 |
|    clip_fraction        | 0.129       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.16       |
|    explained_variance   | -0.0485     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0276     |
|    n_updates            | 3710        |
|    policy_gradient_loss | 0.0042      |
|    std                  | 0.775       |
|    value_loss           | 2.65e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 860         |
|    iterations           | 471         |
|    time_elapsed         | 4484        |
|    total_timesteps      | 3858432     |
| train/                  |             |
|    approx_kl            | 0.017356895 |
|    clip_fraction        | 0.104       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.16       |
|    explained_variance   | -0.0294     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0187     |
|    n_updates            | 3718        |
|    policy_gradient_loss | 0.00329     |
|    std                  | 0.774       |
|    value_loss           | 3.49e-05    |
-----------------------------------------
Early stopping at step 1 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 861         |
|    iterations           | 472         |
|    time_elapsed         | 4488        |
|    total_timesteps      | 3866624     |
| train/                  |             |
|    approx_kl            | 0.029076735 |
|    clip_fraction        | 0.101       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.16       |
|    explained_variance   | -0.0162     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0187     |
|    n_updates            | 3720        |
|    policy_gradient_loss | 0.00383     |
|    std                  | 0.774       |
|    value_loss           | 3.26e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 862         |
|    iterations           | 473         |
|    time_elapsed         | 4494        |
|    total_timesteps      | 3874816     |
| train/                  |             |
|    approx_kl            | 0.016645022 |
|    clip_fraction        | 0.109       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.16       |
|    explained_variance   | -0.0354     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0224     |
|    n_updates            | 3728        |
|    policy_gradient_loss | 0.00494     |
|    std                  | 0.772       |
|    value_loss           | 2.58e-05    |
-----------------------------------------
Early stopping at step 4 due to reaching max kl: 0.04
Eval num_timesteps=3880000, episode_reward=-0.06 +/- 0.06
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.0587     |
| time/                   |             |
|    total_timesteps      | 3880000     |
| train/                  |             |
|    approx_kl            | 0.022582171 |
|    clip_fraction        | 0.108       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.16       |
|    explained_variance   | -0.0226     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0153     |
|    n_updates            | 3733        |
|    policy_gradient_loss | 0.0041      |
|    std                  | 0.771       |
|    value_loss           | 3.92e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 858     |
|    iterations      | 474     |
|    time_elapsed    | 4522    |
|    total_timesteps | 3883008 |
--------------------------------
Early stopping at step 4 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 859         |
|    iterations           | 475         |
|    time_elapsed         | 4526        |
|    total_timesteps      | 3891200     |
| train/                  |             |
|    approx_kl            | 0.020373788 |
|    clip_fraction        | 0.113       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.16       |
|    explained_variance   | -0.022      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0171     |
|    n_updates            | 3738        |
|    policy_gradient_loss | 0.0043      |
|    std                  | 0.769       |
|    value_loss           | 3.23e-05    |
-----------------------------------------
Early stopping at step 1 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 860         |
|    iterations           | 476         |
|    time_elapsed         | 4530        |
|    total_timesteps      | 3899392     |
| train/                  |             |
|    approx_kl            | 0.025912317 |
|    clip_fraction        | 0.0952      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.16       |
|    explained_variance   | -0.0234     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.021      |
|    n_updates            | 3740        |
|    policy_gradient_loss | 0.00294     |
|    std                  | 0.769       |
|    value_loss           | 5.61e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 861         |
|    iterations           | 477         |
|    time_elapsed         | 4535        |
|    total_timesteps      | 3907584     |
| train/                  |             |
|    approx_kl            | 0.013587452 |
|    clip_fraction        | 0.0973      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.16       |
|    explained_variance   | -0.0292     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0193     |
|    n_updates            | 3748        |
|    policy_gradient_loss | 0.00383     |
|    std                  | 0.768       |
|    value_loss           | 3.22e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 862         |
|    iterations           | 478         |
|    time_elapsed         | 4540        |
|    total_timesteps      | 3915776     |
| train/                  |             |
|    approx_kl            | 0.018048258 |
|    clip_fraction        | 0.107       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.023      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0241     |
|    n_updates            | 3756        |
|    policy_gradient_loss | 0.0038      |
|    std                  | 0.767       |
|    value_loss           | 3.46e-05    |
-----------------------------------------
Eval num_timesteps=3920000, episode_reward=0.01 +/- 0.08
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | 0.0078      |
| time/                   |             |
|    total_timesteps      | 3920000     |
| train/                  |             |
|    approx_kl            | 0.016902622 |
|    clip_fraction        | 0.109       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0317     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0113     |
|    n_updates            | 3764        |
|    policy_gradient_loss | 0.00487     |
|    std                  | 0.767       |
|    value_loss           | 3.9e-05     |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 859     |
|    iterations      | 479     |
|    time_elapsed    | 4566    |
|    total_timesteps | 3923968 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 860         |
|    iterations           | 480         |
|    time_elapsed         | 4571        |
|    total_timesteps      | 3932160     |
| train/                  |             |
|    approx_kl            | 0.018316861 |
|    clip_fraction        | 0.114       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0146     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0136     |
|    n_updates            | 3772        |
|    policy_gradient_loss | 0.00546     |
|    std                  | 0.766       |
|    value_loss           | 2.82e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 860         |
|    iterations           | 481         |
|    time_elapsed         | 4576        |
|    total_timesteps      | 3940352     |
| train/                  |             |
|    approx_kl            | 0.016077295 |
|    clip_fraction        | 0.113       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0205     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0185     |
|    n_updates            | 3780        |
|    policy_gradient_loss | 0.00471     |
|    std                  | 0.766       |
|    value_loss           | 3.51e-05    |
-----------------------------------------
Early stopping at step 3 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 862         |
|    iterations           | 482         |
|    time_elapsed         | 4580        |
|    total_timesteps      | 3948544     |
| train/                  |             |
|    approx_kl            | 0.022292772 |
|    clip_fraction        | 0.119       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0311     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0203     |
|    n_updates            | 3784        |
|    policy_gradient_loss | 0.00492     |
|    std                  | 0.765       |
|    value_loss           | 4.04e-05    |
-----------------------------------------
Early stopping at step 4 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 862         |
|    iterations           | 483         |
|    time_elapsed         | 4584        |
|    total_timesteps      | 3956736     |
| train/                  |             |
|    approx_kl            | 0.023880467 |
|    clip_fraction        | 0.123       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0245     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0149     |
|    n_updates            | 3789        |
|    policy_gradient_loss | 0.00508     |
|    std                  | 0.765       |
|    value_loss           | 2.37e-05    |
-----------------------------------------
Eval num_timesteps=3960000, episode_reward=-0.01 +/- 0.08
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.00702    |
| time/                   |             |
|    total_timesteps      | 3960000     |
| train/                  |             |
|    approx_kl            | 0.018422145 |
|    clip_fraction        | 0.0994      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0173     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0134     |
|    n_updates            | 3797        |
|    policy_gradient_loss | 0.00694     |
|    std                  | 0.764       |
|    value_loss           | 4.14e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 859     |
|    iterations      | 484     |
|    time_elapsed    | 4612    |
|    total_timesteps | 3964928 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 860         |
|    iterations           | 485         |
|    time_elapsed         | 4617        |
|    total_timesteps      | 3973120     |
| train/                  |             |
|    approx_kl            | 0.017054776 |
|    clip_fraction        | 0.0984      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.00293    |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0151     |
|    n_updates            | 3805        |
|    policy_gradient_loss | 0.00551     |
|    std                  | 0.765       |
|    value_loss           | 5.51e-05    |
-----------------------------------------
Early stopping at step 5 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 861         |
|    iterations           | 486         |
|    time_elapsed         | 4621        |
|    total_timesteps      | 3981312     |
| train/                  |             |
|    approx_kl            | 0.022320546 |
|    clip_fraction        | 0.123       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0254     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00603    |
|    n_updates            | 3811        |
|    policy_gradient_loss | 0.0068      |
|    std                  | 0.764       |
|    value_loss           | 3.13e-05    |
-----------------------------------------
Early stopping at step 1 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 862         |
|    iterations           | 487         |
|    time_elapsed         | 4625        |
|    total_timesteps      | 3989504     |
| train/                  |             |
|    approx_kl            | 0.025721364 |
|    clip_fraction        | 0.126       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0364     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0176     |
|    n_updates            | 3813        |
|    policy_gradient_loss | 0.00722     |
|    std                  | 0.764       |
|    value_loss           | 2.72e-05    |
-----------------------------------------
Early stopping at step 2 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 863         |
|    iterations           | 488         |
|    time_elapsed         | 4629        |
|    total_timesteps      | 3997696     |
| train/                  |             |
|    approx_kl            | 0.022706373 |
|    clip_fraction        | 0.126       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0351     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0142     |
|    n_updates            | 3816        |
|    policy_gradient_loss | 0.00675     |
|    std                  | 0.763       |
|    value_loss           | 2.04e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
Eval num_timesteps=4000000, episode_reward=-0.06 +/- 0.08
Episode length: 2340.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 2.34e+03   |
|    mean_reward          | -0.0618    |
| time/                   |            |
|    total_timesteps      | 4000000    |
| train/                  |            |
|    approx_kl            | 0.02368524 |
|    clip_fraction        | 0.116      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.029     |
|    learning_rate        | 5e-05      |
|    loss                 | 0.00348    |
|    n_updates            | 3817       |
|    policy_gradient_loss | 0.0103     |
|    std                  | 0.763      |
|    value_loss           | 3.23e-05   |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 860     |
|    iterations      | 489     |
|    time_elapsed    | 4655    |
|    total_timesteps | 4005888 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 861         |
|    iterations           | 490         |
|    time_elapsed         | 4660        |
|    total_timesteps      | 4014080     |
| train/                  |             |
|    approx_kl            | 0.017957995 |
|    clip_fraction        | 0.108       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0481     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0185     |
|    n_updates            | 3825        |
|    policy_gradient_loss | 0.00546     |
|    std                  | 0.762       |
|    value_loss           | 2.23e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 862         |
|    iterations           | 491         |
|    time_elapsed         | 4663        |
|    total_timesteps      | 4022272     |
| train/                  |             |
|    approx_kl            | 0.028408183 |
|    clip_fraction        | 0.131       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.038      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0232     |
|    n_updates            | 3826        |
|    policy_gradient_loss | 0.00693     |
|    std                  | 0.762       |
|    value_loss           | 2.33e-05    |
-----------------------------------------
Early stopping at step 5 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 863         |
|    iterations           | 492         |
|    time_elapsed         | 4668        |
|    total_timesteps      | 4030464     |
| train/                  |             |
|    approx_kl            | 0.024889914 |
|    clip_fraction        | 0.134       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0094     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0214     |
|    n_updates            | 3832        |
|    policy_gradient_loss | 0.00322     |
|    std                  | 0.762       |
|    value_loss           | 9.84e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 864         |
|    iterations           | 493         |
|    time_elapsed         | 4671        |
|    total_timesteps      | 4038656     |
| train/                  |             |
|    approx_kl            | 0.023431867 |
|    clip_fraction        | 0.112       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0313     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0113     |
|    n_updates            | 3833        |
|    policy_gradient_loss | 0.00982     |
|    std                  | 0.762       |
|    value_loss           | 4.4e-05     |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
Eval num_timesteps=4040000, episode_reward=0.02 +/- 0.07
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | 0.0186      |
| time/                   |             |
|    total_timesteps      | 4040000     |
| train/                  |             |
|    approx_kl            | 0.029455375 |
|    clip_fraction        | 0.128       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0215     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0219     |
|    n_updates            | 3834        |
|    policy_gradient_loss | 0.0043      |
|    std                  | 0.762       |
|    value_loss           | 5.05e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 861     |
|    iterations      | 494     |
|    time_elapsed    | 4697    |
|    total_timesteps | 4046848 |
--------------------------------
Early stopping at step 2 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 862         |
|    iterations           | 495         |
|    time_elapsed         | 4700        |
|    total_timesteps      | 4055040     |
| train/                  |             |
|    approx_kl            | 0.030750953 |
|    clip_fraction        | 0.145       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0806     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0205     |
|    n_updates            | 3837        |
|    policy_gradient_loss | 0.00682     |
|    std                  | 0.762       |
|    value_loss           | 1.94e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 863         |
|    iterations           | 496         |
|    time_elapsed         | 4704        |
|    total_timesteps      | 4063232     |
| train/                  |             |
|    approx_kl            | 0.026267145 |
|    clip_fraction        | 0.126       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0593     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0113     |
|    n_updates            | 3838        |
|    policy_gradient_loss | 0.00995     |
|    std                  | 0.762       |
|    value_loss           | 2.06e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 864         |
|    iterations           | 497         |
|    time_elapsed         | 4707        |
|    total_timesteps      | 4071424     |
| train/                  |             |
|    approx_kl            | 0.027264815 |
|    clip_fraction        | 0.119       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0272     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0207     |
|    n_updates            | 3839        |
|    policy_gradient_loss | 0.00438     |
|    std                  | 0.762       |
|    value_loss           | 2.97e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 866         |
|    iterations           | 498         |
|    time_elapsed         | 4710        |
|    total_timesteps      | 4079616     |
| train/                  |             |
|    approx_kl            | 0.026273325 |
|    clip_fraction        | 0.125       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.00507    |
|    learning_rate        | 5e-05       |
|    loss                 | 0.000213    |
|    n_updates            | 3840        |
|    policy_gradient_loss | 0.0123      |
|    std                  | 0.762       |
|    value_loss           | 6.1e-05     |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
Eval num_timesteps=4080000, episode_reward=-0.02 +/- 0.09
Episode length: 2340.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 2.34e+03   |
|    mean_reward          | -0.0224    |
| time/                   |            |
|    total_timesteps      | 4080000    |
| train/                  |            |
|    approx_kl            | 0.02402337 |
|    clip_fraction        | 0.12       |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0246    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.00625   |
|    n_updates            | 3841       |
|    policy_gradient_loss | 0.00926    |
|    std                  | 0.762      |
|    value_loss           | 4.31e-05   |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 863     |
|    iterations      | 499     |
|    time_elapsed    | 4735    |
|    total_timesteps | 4087808 |
--------------------------------
Early stopping at step 1 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 864         |
|    iterations           | 500         |
|    time_elapsed         | 4738        |
|    total_timesteps      | 4096000     |
| train/                  |             |
|    approx_kl            | 0.025330605 |
|    clip_fraction        | 0.119       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.015      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0174     |
|    n_updates            | 3843        |
|    policy_gradient_loss | 0.00773     |
|    std                  | 0.762       |
|    value_loss           | 4.75e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
----------------------------------------
| time/                   |            |
|    fps                  | 865        |
|    iterations           | 501        |
|    time_elapsed         | 4741       |
|    total_timesteps      | 4104192    |
| train/                  |            |
|    approx_kl            | 0.02902788 |
|    clip_fraction        | 0.125      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0619    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0149    |
|    n_updates            | 3844       |
|    policy_gradient_loss | 0.00743    |
|    std                  | 0.762      |
|    value_loss           | 1.9e-05    |
----------------------------------------
Early stopping at step 1 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 866         |
|    iterations           | 502         |
|    time_elapsed         | 4745        |
|    total_timesteps      | 4112384     |
| train/                  |             |
|    approx_kl            | 0.024690252 |
|    clip_fraction        | 0.125       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0478     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00594    |
|    n_updates            | 3846        |
|    policy_gradient_loss | 0.0103      |
|    std                  | 0.762       |
|    value_loss           | 1.64e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.05
Eval num_timesteps=4120000, episode_reward=-0.06 +/- 0.07
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.0582     |
| time/                   |             |
|    total_timesteps      | 4120000     |
| train/                  |             |
|    approx_kl            | 0.026699696 |
|    clip_fraction        | 0.137       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.042      |
|    learning_rate        | 5e-05       |
|    loss                 | 0.00663     |
|    n_updates            | 3847        |
|    policy_gradient_loss | 0.0102      |
|    std                  | 0.762       |
|    value_loss           | 2.32e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 863     |
|    iterations      | 503     |
|    time_elapsed    | 4774    |
|    total_timesteps | 4120576 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 864         |
|    iterations           | 504         |
|    time_elapsed         | 4777        |
|    total_timesteps      | 4128768     |
| train/                  |             |
|    approx_kl            | 0.023033787 |
|    clip_fraction        | 0.132       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0621     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0132     |
|    n_updates            | 3848        |
|    policy_gradient_loss | 0.00979     |
|    std                  | 0.762       |
|    value_loss           | 1.56e-05    |
-----------------------------------------
Early stopping at step 1 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 865         |
|    iterations           | 505         |
|    time_elapsed         | 4780        |
|    total_timesteps      | 4136960     |
| train/                  |             |
|    approx_kl            | 0.030243702 |
|    clip_fraction        | 0.132       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0293     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0153     |
|    n_updates            | 3850        |
|    policy_gradient_loss | 0.00651     |
|    std                  | 0.761       |
|    value_loss           | 2.53e-05    |
-----------------------------------------
Early stopping at step 1 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 866         |
|    iterations           | 506         |
|    time_elapsed         | 4783        |
|    total_timesteps      | 4145152     |
| train/                  |             |
|    approx_kl            | 0.025431572 |
|    clip_fraction        | 0.128       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.062      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00917    |
|    n_updates            | 3852        |
|    policy_gradient_loss | 0.0102      |
|    std                  | 0.761       |
|    value_loss           | 1.63e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 867         |
|    iterations           | 507         |
|    time_elapsed         | 4786        |
|    total_timesteps      | 4153344     |
| train/                  |             |
|    approx_kl            | 0.022195898 |
|    clip_fraction        | 0.115       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.094      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0052     |
|    n_updates            | 3853        |
|    policy_gradient_loss | 0.0115      |
|    std                  | 0.761       |
|    value_loss           | 1.05e-05    |
-----------------------------------------
Eval num_timesteps=4160000, episode_reward=-0.02 +/- 0.09
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.0241     |
| time/                   |             |
|    total_timesteps      | 4160000     |
| train/                  |             |
|    approx_kl            | 0.024110364 |
|    clip_fraction        | 0.137       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0147     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0211     |
|    n_updates            | 3861        |
|    policy_gradient_loss | 0.00591     |
|    std                  | 0.761       |
|    value_loss           | 5.04e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 864     |
|    iterations      | 508     |
|    time_elapsed    | 4813    |
|    total_timesteps | 4161536 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
----------------------------------------
| time/                   |            |
|    fps                  | 865        |
|    iterations           | 509        |
|    time_elapsed         | 4817       |
|    total_timesteps      | 4169728    |
| train/                  |            |
|    approx_kl            | 0.02771417 |
|    clip_fraction        | 0.138      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0232    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0178    |
|    n_updates            | 3862       |
|    policy_gradient_loss | 0.0096     |
|    std                  | 0.762      |
|    value_loss           | 3.42e-05   |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 866         |
|    iterations           | 510         |
|    time_elapsed         | 4820        |
|    total_timesteps      | 4177920     |
| train/                  |             |
|    approx_kl            | 0.030274078 |
|    clip_fraction        | 0.116       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0304     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0099     |
|    n_updates            | 3863        |
|    policy_gradient_loss | 0.00813     |
|    std                  | 0.762       |
|    value_loss           | 3.55e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 867         |
|    iterations           | 511         |
|    time_elapsed         | 4824        |
|    total_timesteps      | 4186112     |
| train/                  |             |
|    approx_kl            | 0.028079966 |
|    clip_fraction        | 0.124       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0246     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0167     |
|    n_updates            | 3864        |
|    policy_gradient_loss | 0.00554     |
|    std                  | 0.762       |
|    value_loss           | 3.01e-05    |
-----------------------------------------
Early stopping at step 1 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 868         |
|    iterations           | 512         |
|    time_elapsed         | 4828        |
|    total_timesteps      | 4194304     |
| train/                  |             |
|    approx_kl            | 0.025093079 |
|    clip_fraction        | 0.117       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0263     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0159     |
|    n_updates            | 3866        |
|    policy_gradient_loss | 0.00791     |
|    std                  | 0.762       |
|    value_loss           | 3.57e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
Eval num_timesteps=4200000, episode_reward=-0.03 +/- 0.11
Episode length: 2340.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 2.34e+03   |
|    mean_reward          | -0.0298    |
| time/                   |            |
|    total_timesteps      | 4200000    |
| train/                  |            |
|    approx_kl            | 0.02376367 |
|    clip_fraction        | 0.116      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0536    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0117    |
|    n_updates            | 3867       |
|    policy_gradient_loss | 0.00897    |
|    std                  | 0.762      |
|    value_loss           | 1.62e-05   |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 865     |
|    iterations      | 513     |
|    time_elapsed    | 4855    |
|    total_timesteps | 4202496 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 866         |
|    iterations           | 514         |
|    time_elapsed         | 4858        |
|    total_timesteps      | 4210688     |
| train/                  |             |
|    approx_kl            | 0.024361664 |
|    clip_fraction        | 0.108       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0397     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00868    |
|    n_updates            | 3868        |
|    policy_gradient_loss | 0.0118      |
|    std                  | 0.762       |
|    value_loss           | 2.22e-05    |
-----------------------------------------
Early stopping at step 3 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 867         |
|    iterations           | 515         |
|    time_elapsed         | 4863        |
|    total_timesteps      | 4218880     |
| train/                  |             |
|    approx_kl            | 0.032757655 |
|    clip_fraction        | 0.133       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0145     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0146     |
|    n_updates            | 3872        |
|    policy_gradient_loss | 0.00805     |
|    std                  | 0.762       |
|    value_loss           | 5.42e-05    |
-----------------------------------------
Early stopping at step 5 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 868         |
|    iterations           | 516         |
|    time_elapsed         | 4868        |
|    total_timesteps      | 4227072     |
| train/                  |             |
|    approx_kl            | 0.021383302 |
|    clip_fraction        | 0.11        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.029      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00595    |
|    n_updates            | 3878        |
|    policy_gradient_loss | 0.00849     |
|    std                  | 0.761       |
|    value_loss           | 2.18e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.06
-----------------------------------------
| time/                   |             |
|    fps                  | 869         |
|    iterations           | 517         |
|    time_elapsed         | 4871        |
|    total_timesteps      | 4235264     |
| train/                  |             |
|    approx_kl            | 0.060920212 |
|    clip_fraction        | 0.106       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0606     |
|    learning_rate        | 5e-05       |
|    loss                 | 0.0261      |
|    n_updates            | 3879        |
|    policy_gradient_loss | 0.049       |
|    std                  | 0.761       |
|    value_loss           | 2.26e-05    |
-----------------------------------------
Early stopping at step 2 due to reaching max kl: 0.03
Eval num_timesteps=4240000, episode_reward=0.00 +/- 0.10
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | 0.00168     |
| time/                   |             |
|    total_timesteps      | 4240000     |
| train/                  |             |
|    approx_kl            | 0.025482709 |
|    clip_fraction        | 0.136       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0499     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0163     |
|    n_updates            | 3882        |
|    policy_gradient_loss | 0.00568     |
|    std                  | 0.761       |
|    value_loss           | 2.58e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 866     |
|    iterations      | 518     |
|    time_elapsed    | 4899    |
|    total_timesteps | 4243456 |
--------------------------------
Early stopping at step 1 due to reaching max kl: 0.07
-----------------------------------------
| time/                   |             |
|    fps                  | 867         |
|    iterations           | 519         |
|    time_elapsed         | 4903        |
|    total_timesteps      | 4251648     |
| train/                  |             |
|    approx_kl            | 0.026673779 |
|    clip_fraction        | 0.104       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0511     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00981    |
|    n_updates            | 3884        |
|    policy_gradient_loss | 0.0058      |
|    std                  | 0.761       |
|    value_loss           | 1.79e-05    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 867         |
|    iterations           | 520         |
|    time_elapsed         | 4908        |
|    total_timesteps      | 4259840     |
| train/                  |             |
|    approx_kl            | 0.018063273 |
|    clip_fraction        | 0.0991      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0209     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0167     |
|    n_updates            | 3892        |
|    policy_gradient_loss | 0.00461     |
|    std                  | 0.761       |
|    value_loss           | 2.39e-05    |
-----------------------------------------
Early stopping at step 3 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 868         |
|    iterations           | 521         |
|    time_elapsed         | 4913        |
|    total_timesteps      | 4268032     |
| train/                  |             |
|    approx_kl            | 0.021019766 |
|    clip_fraction        | 0.117       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0624     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0115     |
|    n_updates            | 3896        |
|    policy_gradient_loss | 0.00726     |
|    std                  | 0.761       |
|    value_loss           | 1.96e-05    |
-----------------------------------------
Early stopping at step 3 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 869         |
|    iterations           | 522         |
|    time_elapsed         | 4917        |
|    total_timesteps      | 4276224     |
| train/                  |             |
|    approx_kl            | 0.030850865 |
|    clip_fraction        | 0.116       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0491     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0242     |
|    n_updates            | 3900        |
|    policy_gradient_loss | 0.00848     |
|    std                  | 0.76        |
|    value_loss           | 1.77e-05    |
-----------------------------------------
Early stopping at step 1 due to reaching max kl: 0.03
Eval num_timesteps=4280000, episode_reward=-0.05 +/- 0.05
Episode length: 2340.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 2.34e+03   |
|    mean_reward          | -0.0506    |
| time/                   |            |
|    total_timesteps      | 4280000    |
| train/                  |            |
|    approx_kl            | 0.02424854 |
|    clip_fraction        | 0.113      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.034     |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0192    |
|    n_updates            | 3902       |
|    policy_gradient_loss | 0.00816    |
|    std                  | 0.76       |
|    value_loss           | 2.44e-05   |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 866     |
|    iterations      | 523     |
|    time_elapsed    | 4943    |
|    total_timesteps | 4284416 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 867         |
|    iterations           | 524         |
|    time_elapsed         | 4946        |
|    total_timesteps      | 4292608     |
| train/                  |             |
|    approx_kl            | 0.024612617 |
|    clip_fraction        | 0.11        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0268     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00773    |
|    n_updates            | 3903        |
|    policy_gradient_loss | 0.00882     |
|    std                  | 0.76        |
|    value_loss           | 4.34e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 868         |
|    iterations           | 525         |
|    time_elapsed         | 4949        |
|    total_timesteps      | 4300800     |
| train/                  |             |
|    approx_kl            | 0.021694845 |
|    clip_fraction        | 0.102       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.14       |
|    explained_variance   | -0.0169     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.021      |
|    n_updates            | 3904        |
|    policy_gradient_loss | 0.00664     |
|    std                  | 0.76        |
|    value_loss           | 4.31e-05    |
-----------------------------------------
Early stopping at step 1 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 870         |
|    iterations           | 526         |
|    time_elapsed         | 4952        |
|    total_timesteps      | 4308992     |
| train/                  |             |
|    approx_kl            | 0.023966564 |
|    clip_fraction        | 0.127       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.14       |
|    explained_variance   | -0.0289     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.018      |
|    n_updates            | 3906        |
|    policy_gradient_loss | 0.00377     |
|    std                  | 0.76        |
|    value_loss           | 2.89e-05    |
-----------------------------------------
Early stopping at step 3 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 870         |
|    iterations           | 527         |
|    time_elapsed         | 4956        |
|    total_timesteps      | 4317184     |
| train/                  |             |
|    approx_kl            | 0.024063107 |
|    clip_fraction        | 0.118       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.14       |
|    explained_variance   | -0.0381     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0149     |
|    n_updates            | 3910        |
|    policy_gradient_loss | 0.00436     |
|    std                  | 0.76        |
|    value_loss           | 1.47e-05    |
-----------------------------------------
Early stopping at step 1 due to reaching max kl: 0.03
Eval num_timesteps=4320000, episode_reward=0.01 +/- 0.11
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | 0.0115      |
| time/                   |             |
|    total_timesteps      | 4320000     |
| train/                  |             |
|    approx_kl            | 0.025177004 |
|    clip_fraction        | 0.106       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0206     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.000646   |
|    n_updates            | 3912        |
|    policy_gradient_loss | 0.0102      |
|    std                  | 0.76        |
|    value_loss           | 2.5e-05     |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 868     |
|    iterations      | 528     |
|    time_elapsed    | 4981    |
|    total_timesteps | 4325376 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 869         |
|    iterations           | 529         |
|    time_elapsed         | 4985        |
|    total_timesteps      | 4333568     |
| train/                  |             |
|    approx_kl            | 0.021099646 |
|    clip_fraction        | 0.101       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0301     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0133     |
|    n_updates            | 3913        |
|    policy_gradient_loss | 0.0079      |
|    std                  | 0.761       |
|    value_loss           | 3.78e-05    |
-----------------------------------------
Early stopping at step 1 due to reaching max kl: 0.07
-----------------------------------------
| time/                   |             |
|    fps                  | 870         |
|    iterations           | 530         |
|    time_elapsed         | 4988        |
|    total_timesteps      | 4341760     |
| train/                  |             |
|    approx_kl            | 0.025728779 |
|    clip_fraction        | 0.1         |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0345     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0166     |
|    n_updates            | 3915        |
|    policy_gradient_loss | 0.00487     |
|    std                  | 0.761       |
|    value_loss           | 3.84e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 871         |
|    iterations           | 531         |
|    time_elapsed         | 4991        |
|    total_timesteps      | 4349952     |
| train/                  |             |
|    approx_kl            | 0.026885137 |
|    clip_fraction        | 0.102       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0472     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0199     |
|    n_updates            | 3916        |
|    policy_gradient_loss | 0.00606     |
|    std                  | 0.761       |
|    value_loss           | 1.69e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
----------------------------------------
| time/                   |            |
|    fps                  | 872        |
|    iterations           | 532        |
|    time_elapsed         | 4995       |
|    total_timesteps      | 4358144    |
| train/                  |            |
|    approx_kl            | 0.02221793 |
|    clip_fraction        | 0.117      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0476    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0132    |
|    n_updates            | 3917       |
|    policy_gradient_loss | 0.00875    |
|    std                  | 0.761      |
|    value_loss           | 1.65e-05   |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
Eval num_timesteps=4360000, episode_reward=0.03 +/- 0.07
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | 0.0331      |
| time/                   |             |
|    total_timesteps      | 4360000     |
| train/                  |             |
|    approx_kl            | 0.032937292 |
|    clip_fraction        | 0.138       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0202     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00889    |
|    n_updates            | 3918        |
|    policy_gradient_loss | 0.014       |
|    std                  | 0.761       |
|    value_loss           | 3.08e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 869     |
|    iterations      | 533     |
|    time_elapsed    | 5022    |
|    total_timesteps | 4366336 |
--------------------------------
Early stopping at step 3 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 870         |
|    iterations           | 534         |
|    time_elapsed         | 5026        |
|    total_timesteps      | 4374528     |
| train/                  |             |
|    approx_kl            | 0.032029808 |
|    clip_fraction        | 0.114       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.000286   |
|    learning_rate        | 5e-05       |
|    loss                 | -0.017      |
|    n_updates            | 3922        |
|    policy_gradient_loss | 0.00651     |
|    std                  | 0.761       |
|    value_loss           | 7.81e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 871         |
|    iterations           | 535         |
|    time_elapsed         | 5030        |
|    total_timesteps      | 4382720     |
| train/                  |             |
|    approx_kl            | 0.025868028 |
|    clip_fraction        | 0.115       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0272     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00446    |
|    n_updates            | 3923        |
|    policy_gradient_loss | 0.00859     |
|    std                  | 0.761       |
|    value_loss           | 2.99e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.05
----------------------------------------
| time/                   |            |
|    fps                  | 872        |
|    iterations           | 536        |
|    time_elapsed         | 5033       |
|    total_timesteps      | 4390912    |
| train/                  |            |
|    approx_kl            | 0.03800539 |
|    clip_fraction        | 0.0981     |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0272    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0172    |
|    n_updates            | 3924       |
|    policy_gradient_loss | 0.00581    |
|    std                  | 0.761      |
|    value_loss           | 3.02e-05   |
----------------------------------------
Early stopping at step 5 due to reaching max kl: 0.03
----------------------------------------
| time/                   |            |
|    fps                  | 873        |
|    iterations           | 537        |
|    time_elapsed         | 5038       |
|    total_timesteps      | 4399104    |
| train/                  |            |
|    approx_kl            | 0.02070772 |
|    clip_fraction        | 0.101      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0219    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0132    |
|    n_updates            | 3930       |
|    policy_gradient_loss | 0.00594    |
|    std                  | 0.761      |
|    value_loss           | 3.86e-05   |
----------------------------------------
Early stopping at step 1 due to reaching max kl: 0.04
Eval num_timesteps=4400000, episode_reward=0.05 +/- 0.05
Episode length: 2340.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 2.34e+03   |
|    mean_reward          | 0.0466     |
| time/                   |            |
|    total_timesteps      | 4400000    |
| train/                  |            |
|    approx_kl            | 0.04382362 |
|    clip_fraction        | 0.124      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0127    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0134    |
|    n_updates            | 3932       |
|    policy_gradient_loss | 0.00852    |
|    std                  | 0.761      |
|    value_loss           | 2.1e-05    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 869     |
|    iterations      | 538     |
|    time_elapsed    | 5066    |
|    total_timesteps | 4407296 |
--------------------------------
Early stopping at step 1 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 870         |
|    iterations           | 539         |
|    time_elapsed         | 5069        |
|    total_timesteps      | 4415488     |
| train/                  |             |
|    approx_kl            | 0.023008166 |
|    clip_fraction        | 0.116       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0254     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00702    |
|    n_updates            | 3934        |
|    policy_gradient_loss | 0.00845     |
|    std                  | 0.761       |
|    value_loss           | 3.39e-05    |
-----------------------------------------
Early stopping at step 1 due to reaching max kl: 0.04
----------------------------------------
| time/                   |            |
|    fps                  | 872        |
|    iterations           | 540        |
|    time_elapsed         | 5072       |
|    total_timesteps      | 4423680    |
| train/                  |            |
|    approx_kl            | 0.04341887 |
|    clip_fraction        | 0.143      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0183    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0102    |
|    n_updates            | 3936       |
|    policy_gradient_loss | 0.00745    |
|    std                  | 0.761      |
|    value_loss           | 2.65e-05   |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
----------------------------------------
| time/                   |            |
|    fps                  | 873        |
|    iterations           | 541        |
|    time_elapsed         | 5075       |
|    total_timesteps      | 4431872    |
| train/                  |            |
|    approx_kl            | 0.02624663 |
|    clip_fraction        | 0.12       |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0123    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0158    |
|    n_updates            | 3937       |
|    policy_gradient_loss | 0.00399    |
|    std                  | 0.761      |
|    value_loss           | 4.64e-05   |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
Eval num_timesteps=4440000, episode_reward=-0.02 +/- 0.10
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.0198     |
| time/                   |             |
|    total_timesteps      | 4440000     |
| train/                  |             |
|    approx_kl            | 0.027743733 |
|    clip_fraction        | 0.124       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0153     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0131     |
|    n_updates            | 3938        |
|    policy_gradient_loss | 0.00923     |
|    std                  | 0.761       |
|    value_loss           | 2.84e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 870     |
|    iterations      | 542     |
|    time_elapsed    | 5101    |
|    total_timesteps | 4440064 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 871         |
|    iterations           | 543         |
|    time_elapsed         | 5104        |
|    total_timesteps      | 4448256     |
| train/                  |             |
|    approx_kl            | 0.027148018 |
|    clip_fraction        | 0.118       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0447     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00372    |
|    n_updates            | 3939        |
|    policy_gradient_loss | 0.00871     |
|    std                  | 0.761       |
|    value_loss           | 2.77e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
----------------------------------------
| time/                   |            |
|    fps                  | 872        |
|    iterations           | 544        |
|    time_elapsed         | 5107       |
|    total_timesteps      | 4456448    |
| train/                  |            |
|    approx_kl            | 0.02761926 |
|    clip_fraction        | 0.125      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0502    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.00503   |
|    n_updates            | 3940       |
|    policy_gradient_loss | 0.0132     |
|    std                  | 0.761      |
|    value_loss           | 2.05e-05   |
----------------------------------------
Early stopping at step 3 due to reaching max kl: 0.04
----------------------------------------
| time/                   |            |
|    fps                  | 873        |
|    iterations           | 545        |
|    time_elapsed         | 5110       |
|    total_timesteps      | 4464640    |
| train/                  |            |
|    approx_kl            | 0.02971867 |
|    clip_fraction        | 0.121      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0611    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0138    |
|    n_updates            | 3944       |
|    policy_gradient_loss | 0.00855    |
|    std                  | 0.761      |
|    value_loss           | 1.8e-05    |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
----------------------------------------
| time/                   |            |
|    fps                  | 874        |
|    iterations           | 546        |
|    time_elapsed         | 5113       |
|    total_timesteps      | 4472832    |
| train/                  |            |
|    approx_kl            | 0.03185309 |
|    clip_fraction        | 0.12       |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0311    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.00923   |
|    n_updates            | 3945       |
|    policy_gradient_loss | 0.0152     |
|    std                  | 0.761      |
|    value_loss           | 1.84e-05   |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
Eval num_timesteps=4480000, episode_reward=-0.02 +/- 0.08
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.0244     |
| time/                   |             |
|    total_timesteps      | 4480000     |
| train/                  |             |
|    approx_kl            | 0.026852598 |
|    clip_fraction        | 0.136       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0263     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0123     |
|    n_updates            | 3946        |
|    policy_gradient_loss | 0.00677     |
|    std                  | 0.762       |
|    value_loss           | 2.47e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 872     |
|    iterations      | 547     |
|    time_elapsed    | 5136    |
|    total_timesteps | 4481024 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 873         |
|    iterations           | 548         |
|    time_elapsed         | 5139        |
|    total_timesteps      | 4489216     |
| train/                  |             |
|    approx_kl            | 0.023234528 |
|    clip_fraction        | 0.131       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0288     |
|    learning_rate        | 5e-05       |
|    loss                 | -9.4e-05    |
|    n_updates            | 3947        |
|    policy_gradient_loss | 0.013       |
|    std                  | 0.762       |
|    value_loss           | 3.08e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 874         |
|    iterations           | 549         |
|    time_elapsed         | 5141        |
|    total_timesteps      | 4497408     |
| train/                  |             |
|    approx_kl            | 0.031108014 |
|    clip_fraction        | 0.134       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0203     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0145     |
|    n_updates            | 3948        |
|    policy_gradient_loss | 0.0113      |
|    std                  | 0.762       |
|    value_loss           | 4.16e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 875         |
|    iterations           | 550         |
|    time_elapsed         | 5144        |
|    total_timesteps      | 4505600     |
| train/                  |             |
|    approx_kl            | 0.026179885 |
|    clip_fraction        | 0.123       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0098     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0156     |
|    n_updates            | 3949        |
|    policy_gradient_loss | 0.00699     |
|    std                  | 0.762       |
|    value_loss           | 5.76e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
----------------------------------------
| time/                   |            |
|    fps                  | 877        |
|    iterations           | 551        |
|    time_elapsed         | 5146       |
|    total_timesteps      | 4513792    |
| train/                  |            |
|    approx_kl            | 0.03490983 |
|    clip_fraction        | 0.126      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0191    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.00121   |
|    n_updates            | 3950       |
|    policy_gradient_loss | 0.0217     |
|    std                  | 0.762      |
|    value_loss           | 4.99e-05   |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
Eval num_timesteps=4520000, episode_reward=-0.02 +/- 0.05
Episode length: 2340.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 2.34e+03  |
|    mean_reward          | -0.0176   |
| time/                   |           |
|    total_timesteps      | 4520000   |
| train/                  |           |
|    approx_kl            | 0.0252023 |
|    clip_fraction        | 0.139     |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.15     |
|    explained_variance   | -0.037    |
|    learning_rate        | 5e-05     |
|    loss                 | -0.0133   |
|    n_updates            | 3951      |
|    policy_gradient_loss | 0.00952   |
|    std                  | 0.762     |
|    value_loss           | 3.5e-05   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 874     |
|    iterations      | 552     |
|    time_elapsed    | 5170    |
|    total_timesteps | 4521984 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 875         |
|    iterations           | 553         |
|    time_elapsed         | 5172        |
|    total_timesteps      | 4530176     |
| train/                  |             |
|    approx_kl            | 0.027312659 |
|    clip_fraction        | 0.122       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0233     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0138     |
|    n_updates            | 3952        |
|    policy_gradient_loss | 0.00701     |
|    std                  | 0.762       |
|    value_loss           | 2.84e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 876         |
|    iterations           | 554         |
|    time_elapsed         | 5175        |
|    total_timesteps      | 4538368     |
| train/                  |             |
|    approx_kl            | 0.023445848 |
|    clip_fraction        | 0.114       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0577     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0131     |
|    n_updates            | 3953        |
|    policy_gradient_loss | 0.00785     |
|    std                  | 0.762       |
|    value_loss           | 1.71e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 877         |
|    iterations           | 555         |
|    time_elapsed         | 5178        |
|    total_timesteps      | 4546560     |
| train/                  |             |
|    approx_kl            | 0.027375638 |
|    clip_fraction        | 0.129       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0168     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0162     |
|    n_updates            | 3954        |
|    policy_gradient_loss | 0.00841     |
|    std                  | 0.762       |
|    value_loss           | 3.52e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
----------------------------------------
| time/                   |            |
|    fps                  | 879        |
|    iterations           | 556        |
|    time_elapsed         | 5180       |
|    total_timesteps      | 4554752    |
| train/                  |            |
|    approx_kl            | 0.03253199 |
|    clip_fraction        | 0.103      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0308    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0162    |
|    n_updates            | 3955       |
|    policy_gradient_loss | 0.00778    |
|    std                  | 0.762      |
|    value_loss           | 2.91e-05   |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.05
Eval num_timesteps=4560000, episode_reward=0.01 +/- 0.08
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | 0.00983     |
| time/                   |             |
|    total_timesteps      | 4560000     |
| train/                  |             |
|    approx_kl            | 0.050727136 |
|    clip_fraction        | 0.143       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0288     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0088     |
|    n_updates            | 3956        |
|    policy_gradient_loss | 0.0141      |
|    std                  | 0.762       |
|    value_loss           | 2.49e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 876     |
|    iterations      | 557     |
|    time_elapsed    | 5204    |
|    total_timesteps | 4562944 |
--------------------------------
Early stopping at step 4 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 877         |
|    iterations           | 558         |
|    time_elapsed         | 5208        |
|    total_timesteps      | 4571136     |
| train/                  |             |
|    approx_kl            | 0.028749557 |
|    clip_fraction        | 0.124       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0262     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0142     |
|    n_updates            | 3961        |
|    policy_gradient_loss | 0.00716     |
|    std                  | 0.762       |
|    value_loss           | 2.76e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 878         |
|    iterations           | 559         |
|    time_elapsed         | 5210        |
|    total_timesteps      | 4579328     |
| train/                  |             |
|    approx_kl            | 0.025678223 |
|    clip_fraction        | 0.127       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.03       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0138     |
|    n_updates            | 3962        |
|    policy_gradient_loss | 0.011       |
|    std                  | 0.762       |
|    value_loss           | 2.56e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 879         |
|    iterations           | 560         |
|    time_elapsed         | 5213        |
|    total_timesteps      | 4587520     |
| train/                  |             |
|    approx_kl            | 0.024760112 |
|    clip_fraction        | 0.126       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0342     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00544    |
|    n_updates            | 3963        |
|    policy_gradient_loss | 0.0119      |
|    std                  | 0.762       |
|    value_loss           | 2.09e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
----------------------------------------
| time/                   |            |
|    fps                  | 881        |
|    iterations           | 561        |
|    time_elapsed         | 5216       |
|    total_timesteps      | 4595712    |
| train/                  |            |
|    approx_kl            | 0.03391705 |
|    clip_fraction        | 0.121      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0295    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.00931   |
|    n_updates            | 3964       |
|    policy_gradient_loss | 0.0136     |
|    std                  | 0.762      |
|    value_loss           | 2.65e-05   |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
Eval num_timesteps=4600000, episode_reward=0.00 +/- 0.10
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | 0.00427     |
| time/                   |             |
|    total_timesteps      | 4600000     |
| train/                  |             |
|    approx_kl            | 0.025844779 |
|    clip_fraction        | 0.128       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0348     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00935    |
|    n_updates            | 3965        |
|    policy_gradient_loss | 0.00924     |
|    std                  | 0.762       |
|    value_loss           | 2.56e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 878     |
|    iterations      | 562     |
|    time_elapsed    | 5240    |
|    total_timesteps | 4603904 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 879         |
|    iterations           | 563         |
|    time_elapsed         | 5243        |
|    total_timesteps      | 4612096     |
| train/                  |             |
|    approx_kl            | 0.033943024 |
|    clip_fraction        | 0.119       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.018      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00984    |
|    n_updates            | 3966        |
|    policy_gradient_loss | 0.0131      |
|    std                  | 0.762       |
|    value_loss           | 2.45e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 880         |
|    iterations           | 564         |
|    time_elapsed         | 5246        |
|    total_timesteps      | 4620288     |
| train/                  |             |
|    approx_kl            | 0.030710265 |
|    clip_fraction        | 0.134       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0164     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0205     |
|    n_updates            | 3967        |
|    policy_gradient_loss | 0.00776     |
|    std                  | 0.762       |
|    value_loss           | 3.93e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
----------------------------------------
| time/                   |            |
|    fps                  | 881        |
|    iterations           | 565        |
|    time_elapsed         | 5249       |
|    total_timesteps      | 4628480    |
| train/                  |            |
|    approx_kl            | 0.02964307 |
|    clip_fraction        | 0.119      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0246    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0185    |
|    n_updates            | 3968       |
|    policy_gradient_loss | 0.00579    |
|    std                  | 0.762      |
|    value_loss           | 2.7e-05    |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 882         |
|    iterations           | 566         |
|    time_elapsed         | 5252        |
|    total_timesteps      | 4636672     |
| train/                  |             |
|    approx_kl            | 0.024114938 |
|    clip_fraction        | 0.129       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0321     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00657    |
|    n_updates            | 3969        |
|    policy_gradient_loss | 0.0109      |
|    std                  | 0.762       |
|    value_loss           | 2.62e-05    |
-----------------------------------------
Early stopping at step 1 due to reaching max kl: 0.05
Eval num_timesteps=4640000, episode_reward=-0.02 +/- 0.07
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.0205     |
| time/                   |             |
|    total_timesteps      | 4640000     |
| train/                  |             |
|    approx_kl            | 0.048651107 |
|    clip_fraction        | 0.14        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0548     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0169     |
|    n_updates            | 3971        |
|    policy_gradient_loss | 0.00811     |
|    std                  | 0.762       |
|    value_loss           | 1.67e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 880     |
|    iterations      | 567     |
|    time_elapsed    | 5277    |
|    total_timesteps | 4644864 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 881         |
|    iterations           | 568         |
|    time_elapsed         | 5280        |
|    total_timesteps      | 4653056     |
| train/                  |             |
|    approx_kl            | 0.031057116 |
|    clip_fraction        | 0.129       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0426     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00396    |
|    n_updates            | 3972        |
|    policy_gradient_loss | 0.019       |
|    std                  | 0.762       |
|    value_loss           | 1.86e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 882         |
|    iterations           | 569         |
|    time_elapsed         | 5283        |
|    total_timesteps      | 4661248     |
| train/                  |             |
|    approx_kl            | 0.027024383 |
|    clip_fraction        | 0.125       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0516     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0083     |
|    n_updates            | 3973        |
|    policy_gradient_loss | 0.0115      |
|    std                  | 0.762       |
|    value_loss           | 1.39e-05    |
-----------------------------------------
Early stopping at step 1 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 883         |
|    iterations           | 570         |
|    time_elapsed         | 5286        |
|    total_timesteps      | 4669440     |
| train/                  |             |
|    approx_kl            | 0.028428009 |
|    clip_fraction        | 0.136       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0285     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0131     |
|    n_updates            | 3975        |
|    policy_gradient_loss | 0.0106      |
|    std                  | 0.762       |
|    value_loss           | 3.79e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 884         |
|    iterations           | 571         |
|    time_elapsed         | 5289        |
|    total_timesteps      | 4677632     |
| train/                  |             |
|    approx_kl            | 0.027881736 |
|    clip_fraction        | 0.131       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.013      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0224     |
|    n_updates            | 3976        |
|    policy_gradient_loss | 0.00505     |
|    std                  | 0.762       |
|    value_loss           | 5.8e-05     |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
Eval num_timesteps=4680000, episode_reward=-0.00 +/- 0.05
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.00484    |
| time/                   |             |
|    total_timesteps      | 4680000     |
| train/                  |             |
|    approx_kl            | 0.029028792 |
|    clip_fraction        | 0.109       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0246     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00716    |
|    n_updates            | 3977        |
|    policy_gradient_loss | 0.012       |
|    std                  | 0.762       |
|    value_loss           | 3.51e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 881     |
|    iterations      | 572     |
|    time_elapsed    | 5313    |
|    total_timesteps | 4685824 |
--------------------------------
Early stopping at step 1 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 882         |
|    iterations           | 573         |
|    time_elapsed         | 5317        |
|    total_timesteps      | 4694016     |
| train/                  |             |
|    approx_kl            | 0.027870206 |
|    clip_fraction        | 0.125       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0174     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0172     |
|    n_updates            | 3979        |
|    policy_gradient_loss | 0.00981     |
|    std                  | 0.762       |
|    value_loss           | 5.02e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.05
-----------------------------------------
| time/                   |             |
|    fps                  | 883         |
|    iterations           | 574         |
|    time_elapsed         | 5319        |
|    total_timesteps      | 4702208     |
| train/                  |             |
|    approx_kl            | 0.046804793 |
|    clip_fraction        | 0.147       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0144     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0146     |
|    n_updates            | 3980        |
|    policy_gradient_loss | 0.00832     |
|    std                  | 0.762       |
|    value_loss           | 6.4e-05     |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
----------------------------------------
| time/                   |            |
|    fps                  | 884        |
|    iterations           | 575        |
|    time_elapsed         | 5322       |
|    total_timesteps      | 4710400    |
| train/                  |            |
|    approx_kl            | 0.02826459 |
|    clip_fraction        | 0.128      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0226    |
|    learning_rate        | 5e-05      |
|    loss                 | 0.00265    |
|    n_updates            | 3981       |
|    policy_gradient_loss | 0.0157     |
|    std                  | 0.762      |
|    value_loss           | 2.98e-05   |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 886         |
|    iterations           | 576         |
|    time_elapsed         | 5325        |
|    total_timesteps      | 4718592     |
| train/                  |             |
|    approx_kl            | 0.029705914 |
|    clip_fraction        | 0.117       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0264     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0132     |
|    n_updates            | 3982        |
|    policy_gradient_loss | 0.00895     |
|    std                  | 0.762       |
|    value_loss           | 2.56e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
Eval num_timesteps=4720000, episode_reward=-0.00 +/- 0.09
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.00184    |
| time/                   |             |
|    total_timesteps      | 4720000     |
| train/                  |             |
|    approx_kl            | 0.022241328 |
|    clip_fraction        | 0.118       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.019      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0114     |
|    n_updates            | 3983        |
|    policy_gradient_loss | 0.00856     |
|    std                  | 0.763       |
|    value_loss           | 3.22e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 883     |
|    iterations      | 577     |
|    time_elapsed    | 5350    |
|    total_timesteps | 4726784 |
--------------------------------
Early stopping at step 1 due to reaching max kl: 0.05
-----------------------------------------
| time/                   |             |
|    fps                  | 884         |
|    iterations           | 578         |
|    time_elapsed         | 5353        |
|    total_timesteps      | 4734976     |
| train/                  |             |
|    approx_kl            | 0.032082863 |
|    clip_fraction        | 0.138       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0198     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00963    |
|    n_updates            | 3985        |
|    policy_gradient_loss | 0.00978     |
|    std                  | 0.762       |
|    value_loss           | 3.23e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 885         |
|    iterations           | 579         |
|    time_elapsed         | 5356        |
|    total_timesteps      | 4743168     |
| train/                  |             |
|    approx_kl            | 0.028006395 |
|    clip_fraction        | 0.129       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0227     |
|    learning_rate        | 5e-05       |
|    loss                 | 0.0182      |
|    n_updates            | 3986        |
|    policy_gradient_loss | 0.0203      |
|    std                  | 0.762       |
|    value_loss           | 3.17e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 886         |
|    iterations           | 580         |
|    time_elapsed         | 5359        |
|    total_timesteps      | 4751360     |
| train/                  |             |
|    approx_kl            | 0.026891902 |
|    clip_fraction        | 0.13        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0203     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00594    |
|    n_updates            | 3987        |
|    policy_gradient_loss | 0.00753     |
|    std                  | 0.762       |
|    value_loss           | 4.01e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 887         |
|    iterations           | 581         |
|    time_elapsed         | 5361        |
|    total_timesteps      | 4759552     |
| train/                  |             |
|    approx_kl            | 0.025784275 |
|    clip_fraction        | 0.122       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0333     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0108     |
|    n_updates            | 3988        |
|    policy_gradient_loss | 0.00767     |
|    std                  | 0.762       |
|    value_loss           | 2.94e-05    |
-----------------------------------------
Early stopping at step 2 due to reaching max kl: 0.03
Eval num_timesteps=4760000, episode_reward=0.01 +/- 0.09
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | 0.00525     |
| time/                   |             |
|    total_timesteps      | 4760000     |
| train/                  |             |
|    approx_kl            | 0.024176983 |
|    clip_fraction        | 0.121       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0504     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0104     |
|    n_updates            | 3991        |
|    policy_gradient_loss | 0.0102      |
|    std                  | 0.762       |
|    value_loss           | 1.47e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 885     |
|    iterations      | 582     |
|    time_elapsed    | 5386    |
|    total_timesteps | 4767744 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 886         |
|    iterations           | 583         |
|    time_elapsed         | 5390        |
|    total_timesteps      | 4775936     |
| train/                  |             |
|    approx_kl            | 0.025041323 |
|    clip_fraction        | 0.119       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0515     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0103     |
|    n_updates            | 3992        |
|    policy_gradient_loss | 0.01        |
|    std                  | 0.762       |
|    value_loss           | 1.61e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 886         |
|    iterations           | 584         |
|    time_elapsed         | 5393        |
|    total_timesteps      | 4784128     |
| train/                  |             |
|    approx_kl            | 0.026671443 |
|    clip_fraction        | 0.117       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0374     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0106     |
|    n_updates            | 3993        |
|    policy_gradient_loss | 0.00847     |
|    std                  | 0.762       |
|    value_loss           | 2.15e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 887         |
|    iterations           | 585         |
|    time_elapsed         | 5397        |
|    total_timesteps      | 4792320     |
| train/                  |             |
|    approx_kl            | 0.026292022 |
|    clip_fraction        | 0.123       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0405     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0153     |
|    n_updates            | 3994        |
|    policy_gradient_loss | 0.00639     |
|    std                  | 0.762       |
|    value_loss           | 2.03e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
Eval num_timesteps=4800000, episode_reward=-0.00 +/- 0.09
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.00144    |
| time/                   |             |
|    total_timesteps      | 4800000     |
| train/                  |             |
|    approx_kl            | 0.024371378 |
|    clip_fraction        | 0.135       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0326     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00218    |
|    n_updates            | 3995        |
|    policy_gradient_loss | 0.0116      |
|    std                  | 0.762       |
|    value_loss           | 2.6e-05     |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 885     |
|    iterations      | 586     |
|    time_elapsed    | 5423    |
|    total_timesteps | 4800512 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 886         |
|    iterations           | 587         |
|    time_elapsed         | 5427        |
|    total_timesteps      | 4808704     |
| train/                  |             |
|    approx_kl            | 0.024357764 |
|    clip_fraction        | 0.114       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0104     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0145     |
|    n_updates            | 3996        |
|    policy_gradient_loss | 0.00569     |
|    std                  | 0.762       |
|    value_loss           | 3.96e-05    |
-----------------------------------------
Early stopping at step 1 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 886         |
|    iterations           | 588         |
|    time_elapsed         | 5430        |
|    total_timesteps      | 4816896     |
| train/                  |             |
|    approx_kl            | 0.040636286 |
|    clip_fraction        | 0.127       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0154     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0122     |
|    n_updates            | 3998        |
|    policy_gradient_loss | 0.0107      |
|    std                  | 0.763       |
|    value_loss           | 3.79e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 887         |
|    iterations           | 589         |
|    time_elapsed         | 5434        |
|    total_timesteps      | 4825088     |
| train/                  |             |
|    approx_kl            | 0.022359654 |
|    clip_fraction        | 0.121       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0522     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0163     |
|    n_updates            | 3999        |
|    policy_gradient_loss | 0.00759     |
|    std                  | 0.763       |
|    value_loss           | 1.96e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 888         |
|    iterations           | 590         |
|    time_elapsed         | 5437        |
|    total_timesteps      | 4833280     |
| train/                  |             |
|    approx_kl            | 0.025258482 |
|    clip_fraction        | 0.116       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0236     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0174     |
|    n_updates            | 4000        |
|    policy_gradient_loss | 0.00615     |
|    std                  | 0.763       |
|    value_loss           | 3.2e-05     |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
Eval num_timesteps=4840000, episode_reward=0.00 +/- 0.09
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | 0.00399     |
| time/                   |             |
|    total_timesteps      | 4840000     |
| train/                  |             |
|    approx_kl            | 0.026866037 |
|    clip_fraction        | 0.123       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0327     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.000675   |
|    n_updates            | 4001        |
|    policy_gradient_loss | 0.0121      |
|    std                  | 0.763       |
|    value_loss           | 1.99e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 886     |
|    iterations      | 591     |
|    time_elapsed    | 5464    |
|    total_timesteps | 4841472 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 886         |
|    iterations           | 592         |
|    time_elapsed         | 5467        |
|    total_timesteps      | 4849664     |
| train/                  |             |
|    approx_kl            | 0.026838563 |
|    clip_fraction        | 0.131       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0559     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0183     |
|    n_updates            | 4002        |
|    policy_gradient_loss | 0.00927     |
|    std                  | 0.763       |
|    value_loss           | 1.82e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
----------------------------------------
| time/                   |            |
|    fps                  | 887        |
|    iterations           | 593        |
|    time_elapsed         | 5471       |
|    total_timesteps      | 4857856    |
| train/                  |            |
|    approx_kl            | 0.03737022 |
|    clip_fraction        | 0.14       |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0246    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0135    |
|    n_updates            | 4003       |
|    policy_gradient_loss | 0.0095     |
|    std                  | 0.763      |
|    value_loss           | 2.87e-05   |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
----------------------------------------
| time/                   |            |
|    fps                  | 888        |
|    iterations           | 594        |
|    time_elapsed         | 5474       |
|    total_timesteps      | 4866048    |
| train/                  |            |
|    approx_kl            | 0.02564541 |
|    clip_fraction        | 0.13       |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0354    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0178    |
|    n_updates            | 4004       |
|    policy_gradient_loss | 0.0107     |
|    std                  | 0.763      |
|    value_loss           | 2.55e-05   |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 889         |
|    iterations           | 595         |
|    time_elapsed         | 5478        |
|    total_timesteps      | 4874240     |
| train/                  |             |
|    approx_kl            | 0.025045972 |
|    clip_fraction        | 0.132       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0259     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0149     |
|    n_updates            | 4005        |
|    policy_gradient_loss | 0.00642     |
|    std                  | 0.763       |
|    value_loss           | 4.11e-05    |
-----------------------------------------
Early stopping at step 1 due to reaching max kl: 0.03
Eval num_timesteps=4880000, episode_reward=-0.03 +/- 0.06
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.0258     |
| time/                   |             |
|    total_timesteps      | 4880000     |
| train/                  |             |
|    approx_kl            | 0.027839221 |
|    clip_fraction        | 0.126       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0501     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00114    |
|    n_updates            | 4007        |
|    policy_gradient_loss | 0.0131      |
|    std                  | 0.763       |
|    value_loss           | 1.59e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 886     |
|    iterations      | 596     |
|    time_elapsed    | 5505    |
|    total_timesteps | 4882432 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 887         |
|    iterations           | 597         |
|    time_elapsed         | 5509        |
|    total_timesteps      | 4890624     |
| train/                  |             |
|    approx_kl            | 0.023919884 |
|    clip_fraction        | 0.121       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0435     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0131     |
|    n_updates            | 4008        |
|    policy_gradient_loss | 0.00987     |
|    std                  | 0.763       |
|    value_loss           | 2.04e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 888         |
|    iterations           | 598         |
|    time_elapsed         | 5512        |
|    total_timesteps      | 4898816     |
| train/                  |             |
|    approx_kl            | 0.026906034 |
|    clip_fraction        | 0.134       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0292     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0133     |
|    n_updates            | 4009        |
|    policy_gradient_loss | 0.0105      |
|    std                  | 0.763       |
|    value_loss           | 2.38e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
---------------------------------------
| time/                   |           |
|    fps                  | 889       |
|    iterations           | 599       |
|    time_elapsed         | 5516      |
|    total_timesteps      | 4907008   |
| train/                  |           |
|    approx_kl            | 0.0253272 |
|    clip_fraction        | 0.139     |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.15     |
|    explained_variance   | -0.0374   |
|    learning_rate        | 5e-05     |
|    loss                 | 0.0042    |
|    n_updates            | 4010      |
|    policy_gradient_loss | 0.0141    |
|    std                  | 0.763     |
|    value_loss           | 1.94e-05  |
---------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 890         |
|    iterations           | 600         |
|    time_elapsed         | 5520        |
|    total_timesteps      | 4915200     |
| train/                  |             |
|    approx_kl            | 0.027513277 |
|    clip_fraction        | 0.137       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0242     |
|    learning_rate        | 5e-05       |
|    loss                 | 0.00661     |
|    n_updates            | 4011        |
|    policy_gradient_loss | 0.0126      |
|    std                  | 0.763       |
|    value_loss           | 2.89e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
Eval num_timesteps=4920000, episode_reward=-0.02 +/- 0.07
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.0176     |
| time/                   |             |
|    total_timesteps      | 4920000     |
| train/                  |             |
|    approx_kl            | 0.029786594 |
|    clip_fraction        | 0.133       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0233     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0129     |
|    n_updates            | 4012        |
|    policy_gradient_loss | 0.013       |
|    std                  | 0.763       |
|    value_loss           | 2.48e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 887     |
|    iterations      | 601     |
|    time_elapsed    | 5547    |
|    total_timesteps | 4923392 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 888         |
|    iterations           | 602         |
|    time_elapsed         | 5551        |
|    total_timesteps      | 4931584     |
| train/                  |             |
|    approx_kl            | 0.025321478 |
|    clip_fraction        | 0.14        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0428     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0166     |
|    n_updates            | 4013        |
|    policy_gradient_loss | 0.00841     |
|    std                  | 0.763       |
|    value_loss           | 2.08e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
----------------------------------------
| time/                   |            |
|    fps                  | 889        |
|    iterations           | 603        |
|    time_elapsed         | 5554       |
|    total_timesteps      | 4939776    |
| train/                  |            |
|    approx_kl            | 0.03379833 |
|    clip_fraction        | 0.148      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0252    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.00463   |
|    n_updates            | 4014       |
|    policy_gradient_loss | 0.0177     |
|    std                  | 0.763      |
|    value_loss           | 3e-05      |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
----------------------------------------
| time/                   |            |
|    fps                  | 890        |
|    iterations           | 604        |
|    time_elapsed         | 5558       |
|    total_timesteps      | 4947968    |
| train/                  |            |
|    approx_kl            | 0.02763949 |
|    clip_fraction        | 0.147      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0206    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.00659   |
|    n_updates            | 4015       |
|    policy_gradient_loss | 0.014      |
|    std                  | 0.763      |
|    value_loss           | 3.23e-05   |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.05
-----------------------------------------
| time/                   |             |
|    fps                  | 891         |
|    iterations           | 605         |
|    time_elapsed         | 5561        |
|    total_timesteps      | 4956160     |
| train/                  |             |
|    approx_kl            | 0.032187976 |
|    clip_fraction        | 0.145       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0243     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.000433   |
|    n_updates            | 4016        |
|    policy_gradient_loss | 0.0101      |
|    std                  | 0.763       |
|    value_loss           | 2.64e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
Eval num_timesteps=4960000, episode_reward=-0.01 +/- 0.11
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.00929    |
| time/                   |             |
|    total_timesteps      | 4960000     |
| train/                  |             |
|    approx_kl            | 0.029981518 |
|    clip_fraction        | 0.144       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0288     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00502    |
|    n_updates            | 4017        |
|    policy_gradient_loss | 0.0152      |
|    std                  | 0.763       |
|    value_loss           | 2.51e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 888     |
|    iterations      | 606     |
|    time_elapsed    | 5587    |
|    total_timesteps | 4964352 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 889         |
|    iterations           | 607         |
|    time_elapsed         | 5590        |
|    total_timesteps      | 4972544     |
| train/                  |             |
|    approx_kl            | 0.030145915 |
|    clip_fraction        | 0.141       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0127     |
|    learning_rate        | 5e-05       |
|    loss                 | 0.00276     |
|    n_updates            | 4018        |
|    policy_gradient_loss | 0.0148      |
|    std                  | 0.763       |
|    value_loss           | 6.46e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 890         |
|    iterations           | 608         |
|    time_elapsed         | 5593        |
|    total_timesteps      | 4980736     |
| train/                  |             |
|    approx_kl            | 0.029941728 |
|    clip_fraction        | 0.161       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0108     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0145     |
|    n_updates            | 4019        |
|    policy_gradient_loss | 0.00906     |
|    std                  | 0.763       |
|    value_loss           | 7.37e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
----------------------------------------
| time/                   |            |
|    fps                  | 891        |
|    iterations           | 609        |
|    time_elapsed         | 5596       |
|    total_timesteps      | 4988928    |
| train/                  |            |
|    approx_kl            | 0.04248315 |
|    clip_fraction        | 0.146      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0119    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0202    |
|    n_updates            | 4020       |
|    policy_gradient_loss | 0.00273    |
|    std                  | 0.763      |
|    value_loss           | 5.43e-05   |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 892         |
|    iterations           | 610         |
|    time_elapsed         | 5600        |
|    total_timesteps      | 4997120     |
| train/                  |             |
|    approx_kl            | 0.034992494 |
|    clip_fraction        | 0.146       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0309     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.012      |
|    n_updates            | 4021        |
|    policy_gradient_loss | 0.0109      |
|    std                  | 0.763       |
|    value_loss           | 2.21e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
Eval num_timesteps=5000000, episode_reward=0.05 +/- 0.08
Episode length: 2340.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 2.34e+03   |
|    mean_reward          | 0.0549     |
| time/                   |            |
|    total_timesteps      | 5000000    |
| train/                  |            |
|    approx_kl            | 0.02788165 |
|    clip_fraction        | 0.138      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0388    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.00258   |
|    n_updates            | 4022       |
|    policy_gradient_loss | 0.0169     |
|    std                  | 0.763      |
|    value_loss           | 2.23e-05   |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 889     |
|    iterations      | 611     |
|    time_elapsed    | 5628    |
|    total_timesteps | 5005312 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 890         |
|    iterations           | 612         |
|    time_elapsed         | 5632        |
|    total_timesteps      | 5013504     |
| train/                  |             |
|    approx_kl            | 0.030520763 |
|    clip_fraction        | 0.119       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0493     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0115     |
|    n_updates            | 4023        |
|    policy_gradient_loss | 0.0115      |
|    std                  | 0.763       |
|    value_loss           | 1.6e-05     |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 891         |
|    iterations           | 613         |
|    time_elapsed         | 5635        |
|    total_timesteps      | 5021696     |
| train/                  |             |
|    approx_kl            | 0.027816575 |
|    clip_fraction        | 0.144       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0411     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0107     |
|    n_updates            | 4024        |
|    policy_gradient_loss | 0.00947     |
|    std                  | 0.763       |
|    value_loss           | 2.13e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 891         |
|    iterations           | 614         |
|    time_elapsed         | 5639        |
|    total_timesteps      | 5029888     |
| train/                  |             |
|    approx_kl            | 0.034363516 |
|    clip_fraction        | 0.127       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0278     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0102     |
|    n_updates            | 4025        |
|    policy_gradient_loss | 0.0128      |
|    std                  | 0.763       |
|    value_loss           | 2.34e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 892         |
|    iterations           | 615         |
|    time_elapsed         | 5643        |
|    total_timesteps      | 5038080     |
| train/                  |             |
|    approx_kl            | 0.026837915 |
|    clip_fraction        | 0.134       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0291     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0118     |
|    n_updates            | 4026        |
|    policy_gradient_loss | 0.0131      |
|    std                  | 0.763       |
|    value_loss           | 2.56e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
Eval num_timesteps=5040000, episode_reward=-0.02 +/- 0.09
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.0169     |
| time/                   |             |
|    total_timesteps      | 5040000     |
| train/                  |             |
|    approx_kl            | 0.025682645 |
|    clip_fraction        | 0.136       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0273     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0128     |
|    n_updates            | 4027        |
|    policy_gradient_loss | 0.0121      |
|    std                  | 0.763       |
|    value_loss           | 3.85e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 889     |
|    iterations      | 616     |
|    time_elapsed    | 5671    |
|    total_timesteps | 5046272 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 890         |
|    iterations           | 617         |
|    time_elapsed         | 5675        |
|    total_timesteps      | 5054464     |
| train/                  |             |
|    approx_kl            | 0.023925751 |
|    clip_fraction        | 0.123       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0269     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0161     |
|    n_updates            | 4028        |
|    policy_gradient_loss | 0.00772     |
|    std                  | 0.763       |
|    value_loss           | 2.84e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
----------------------------------------
| time/                   |            |
|    fps                  | 891        |
|    iterations           | 618        |
|    time_elapsed         | 5679       |
|    total_timesteps      | 5062656    |
| train/                  |            |
|    approx_kl            | 0.02710844 |
|    clip_fraction        | 0.136      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0391    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.011     |
|    n_updates            | 4029       |
|    policy_gradient_loss | 0.0111     |
|    std                  | 0.763      |
|    value_loss           | 2.34e-05   |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 892         |
|    iterations           | 619         |
|    time_elapsed         | 5683        |
|    total_timesteps      | 5070848     |
| train/                  |             |
|    approx_kl            | 0.032379646 |
|    clip_fraction        | 0.147       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0262     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00407    |
|    n_updates            | 4030        |
|    policy_gradient_loss | 0.0176      |
|    std                  | 0.763       |
|    value_loss           | 3.02e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 893         |
|    iterations           | 620         |
|    time_elapsed         | 5686        |
|    total_timesteps      | 5079040     |
| train/                  |             |
|    approx_kl            | 0.043515768 |
|    clip_fraction        | 0.16        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0339     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0143     |
|    n_updates            | 4031        |
|    policy_gradient_loss | 0.00864     |
|    std                  | 0.763       |
|    value_loss           | 1.91e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
Eval num_timesteps=5080000, episode_reward=-0.01 +/- 0.06
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.00749    |
| time/                   |             |
|    total_timesteps      | 5080000     |
| train/                  |             |
|    approx_kl            | 0.028311789 |
|    clip_fraction        | 0.132       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0119     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00982    |
|    n_updates            | 4032        |
|    policy_gradient_loss | 0.0103      |
|    std                  | 0.764       |
|    value_loss           | 4.2e-05     |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 890     |
|    iterations      | 621     |
|    time_elapsed    | 5714    |
|    total_timesteps | 5087232 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 891         |
|    iterations           | 622         |
|    time_elapsed         | 5717        |
|    total_timesteps      | 5095424     |
| train/                  |             |
|    approx_kl            | 0.025447475 |
|    clip_fraction        | 0.12        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.00202    |
|    learning_rate        | 5e-05       |
|    loss                 | -0.014      |
|    n_updates            | 4033        |
|    policy_gradient_loss | 0.00982     |
|    std                  | 0.764       |
|    value_loss           | 9.05e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 892         |
|    iterations           | 623         |
|    time_elapsed         | 5720        |
|    total_timesteps      | 5103616     |
| train/                  |             |
|    approx_kl            | 0.029656047 |
|    clip_fraction        | 0.148       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0181     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0193     |
|    n_updates            | 4034        |
|    policy_gradient_loss | 0.00971     |
|    std                  | 0.764       |
|    value_loss           | 3.65e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.07
----------------------------------------
| time/                   |            |
|    fps                  | 893        |
|    iterations           | 624        |
|    time_elapsed         | 5724       |
|    total_timesteps      | 5111808    |
| train/                  |            |
|    approx_kl            | 0.06764096 |
|    clip_fraction        | 0.134      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0212    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.00893   |
|    n_updates            | 4035       |
|    policy_gradient_loss | 0.014      |
|    std                  | 0.764      |
|    value_loss           | 3.87e-05   |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.06
Eval num_timesteps=5120000, episode_reward=-0.01 +/- 0.05
Episode length: 2340.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 2.34e+03   |
|    mean_reward          | -0.0129    |
| time/                   |            |
|    total_timesteps      | 5120000    |
| train/                  |            |
|    approx_kl            | 0.04279204 |
|    clip_fraction        | 0.138      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0266    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0114    |
|    n_updates            | 4036       |
|    policy_gradient_loss | 0.0102     |
|    std                  | 0.764      |
|    value_loss           | 2.51e-05   |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 890     |
|    iterations      | 625     |
|    time_elapsed    | 5750    |
|    total_timesteps | 5120000 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 891         |
|    iterations           | 626         |
|    time_elapsed         | 5753        |
|    total_timesteps      | 5128192     |
| train/                  |             |
|    approx_kl            | 0.029813897 |
|    clip_fraction        | 0.138       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0271     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00135    |
|    n_updates            | 4037        |
|    policy_gradient_loss | 0.0148      |
|    std                  | 0.764       |
|    value_loss           | 3.28e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 892         |
|    iterations           | 627         |
|    time_elapsed         | 5756        |
|    total_timesteps      | 5136384     |
| train/                  |             |
|    approx_kl            | 0.028414194 |
|    clip_fraction        | 0.14        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.022      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0154     |
|    n_updates            | 4038        |
|    policy_gradient_loss | 0.00801     |
|    std                  | 0.764       |
|    value_loss           | 2.53e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 893         |
|    iterations           | 628         |
|    time_elapsed         | 5759        |
|    total_timesteps      | 5144576     |
| train/                  |             |
|    approx_kl            | 0.027030976 |
|    clip_fraction        | 0.132       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0321     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0135     |
|    n_updates            | 4039        |
|    policy_gradient_loss | 0.00899     |
|    std                  | 0.764       |
|    value_loss           | 2.9e-05     |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 894         |
|    iterations           | 629         |
|    time_elapsed         | 5763        |
|    total_timesteps      | 5152768     |
| train/                  |             |
|    approx_kl            | 0.031751674 |
|    clip_fraction        | 0.145       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0178     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00412    |
|    n_updates            | 4040        |
|    policy_gradient_loss | 0.0186      |
|    std                  | 0.764       |
|    value_loss           | 5.22e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
Eval num_timesteps=5160000, episode_reward=-0.03 +/- 0.07
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.0277     |
| time/                   |             |
|    total_timesteps      | 5160000     |
| train/                  |             |
|    approx_kl            | 0.029564157 |
|    clip_fraction        | 0.131       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0118     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00942    |
|    n_updates            | 4041        |
|    policy_gradient_loss | 0.0105      |
|    std                  | 0.764       |
|    value_loss           | 6.4e-05     |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 891     |
|    iterations      | 630     |
|    time_elapsed    | 5789    |
|    total_timesteps | 5160960 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 892         |
|    iterations           | 631         |
|    time_elapsed         | 5792        |
|    total_timesteps      | 5169152     |
| train/                  |             |
|    approx_kl            | 0.031827435 |
|    clip_fraction        | 0.131       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0316     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00918    |
|    n_updates            | 4042        |
|    policy_gradient_loss | 0.0177      |
|    std                  | 0.764       |
|    value_loss           | 2.09e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 893         |
|    iterations           | 632         |
|    time_elapsed         | 5795        |
|    total_timesteps      | 5177344     |
| train/                  |             |
|    approx_kl            | 0.039198738 |
|    clip_fraction        | 0.15        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.03       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00643    |
|    n_updates            | 4043        |
|    policy_gradient_loss | 0.0166      |
|    std                  | 0.764       |
|    value_loss           | 2.21e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
----------------------------------------
| time/                   |            |
|    fps                  | 894        |
|    iterations           | 633        |
|    time_elapsed         | 5799       |
|    total_timesteps      | 5185536    |
| train/                  |            |
|    approx_kl            | 0.03464508 |
|    clip_fraction        | 0.153      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0139    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0168    |
|    n_updates            | 4044       |
|    policy_gradient_loss | 0.00617    |
|    std                  | 0.764      |
|    value_loss           | 3.56e-05   |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 895         |
|    iterations           | 634         |
|    time_elapsed         | 5802        |
|    total_timesteps      | 5193728     |
| train/                  |             |
|    approx_kl            | 0.029267065 |
|    clip_fraction        | 0.141       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0612     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00707    |
|    n_updates            | 4045        |
|    policy_gradient_loss | 0.0104      |
|    std                  | 0.764       |
|    value_loss           | 1.79e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
Eval num_timesteps=5200000, episode_reward=0.01 +/- 0.07
Episode length: 2340.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 2.34e+03   |
|    mean_reward          | 0.00528    |
| time/                   |            |
|    total_timesteps      | 5200000    |
| train/                  |            |
|    approx_kl            | 0.03190268 |
|    clip_fraction        | 0.135      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0119    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0165    |
|    n_updates            | 4046       |
|    policy_gradient_loss | 0.00651    |
|    std                  | 0.764      |
|    value_loss           | 5.5e-05    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 892     |
|    iterations      | 635     |
|    time_elapsed    | 5827    |
|    total_timesteps | 5201920 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 893         |
|    iterations           | 636         |
|    time_elapsed         | 5830        |
|    total_timesteps      | 5210112     |
| train/                  |             |
|    approx_kl            | 0.039698467 |
|    clip_fraction        | 0.155       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0215     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00523    |
|    n_updates            | 4047        |
|    policy_gradient_loss | 0.0178      |
|    std                  | 0.764       |
|    value_loss           | 2.88e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
----------------------------------------
| time/                   |            |
|    fps                  | 894        |
|    iterations           | 637        |
|    time_elapsed         | 5833       |
|    total_timesteps      | 5218304    |
| train/                  |            |
|    approx_kl            | 0.03827502 |
|    clip_fraction        | 0.135      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0123    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0195    |
|    n_updates            | 4048       |
|    policy_gradient_loss | 0.00345    |
|    std                  | 0.764      |
|    value_loss           | 3.61e-05   |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
----------------------------------------
| time/                   |            |
|    fps                  | 895        |
|    iterations           | 638        |
|    time_elapsed         | 5836       |
|    total_timesteps      | 5226496    |
| train/                  |            |
|    approx_kl            | 0.02538679 |
|    clip_fraction        | 0.126      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0276    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0182    |
|    n_updates            | 4049       |
|    policy_gradient_loss | 0.00872    |
|    std                  | 0.764      |
|    value_loss           | 3.54e-05   |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 896         |
|    iterations           | 639         |
|    time_elapsed         | 5839        |
|    total_timesteps      | 5234688     |
| train/                  |             |
|    approx_kl            | 0.040200945 |
|    clip_fraction        | 0.15        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0469     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00971    |
|    n_updates            | 4050        |
|    policy_gradient_loss | 0.0133      |
|    std                  | 0.764       |
|    value_loss           | 2.17e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
Eval num_timesteps=5240000, episode_reward=0.05 +/- 0.10
Episode length: 2340.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 2.34e+03   |
|    mean_reward          | 0.0453     |
| time/                   |            |
|    total_timesteps      | 5240000    |
| train/                  |            |
|    approx_kl            | 0.03370349 |
|    clip_fraction        | 0.151      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0159    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.00948   |
|    n_updates            | 4051       |
|    policy_gradient_loss | 0.0135     |
|    std                  | 0.764      |
|    value_loss           | 3.78e-05   |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 894     |
|    iterations      | 640     |
|    time_elapsed    | 5863    |
|    total_timesteps | 5242880 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
---------------------------------------
| time/                   |           |
|    fps                  | 895       |
|    iterations           | 641       |
|    time_elapsed         | 5866      |
|    total_timesteps      | 5251072   |
| train/                  |           |
|    approx_kl            | 0.0313487 |
|    clip_fraction        | 0.144     |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.15     |
|    explained_variance   | -0.0349   |
|    learning_rate        | 5e-05     |
|    loss                 | -0.0092   |
|    n_updates            | 4052      |
|    policy_gradient_loss | 0.0103    |
|    std                  | 0.764     |
|    value_loss           | 1.81e-05  |
---------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 896         |
|    iterations           | 642         |
|    time_elapsed         | 5868        |
|    total_timesteps      | 5259264     |
| train/                  |             |
|    approx_kl            | 0.027446464 |
|    clip_fraction        | 0.139       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0289     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0108     |
|    n_updates            | 4053        |
|    policy_gradient_loss | 0.0111      |
|    std                  | 0.764       |
|    value_loss           | 2.19e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.06
----------------------------------------
| time/                   |            |
|    fps                  | 897        |
|    iterations           | 643        |
|    time_elapsed         | 5871       |
|    total_timesteps      | 5267456    |
| train/                  |            |
|    approx_kl            | 0.04268777 |
|    clip_fraction        | 0.154      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0345    |
|    learning_rate        | 5e-05      |
|    loss                 | 0.0053     |
|    n_updates            | 4054       |
|    policy_gradient_loss | 0.0222     |
|    std                  | 0.764      |
|    value_loss           | 2.46e-05   |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.05
-----------------------------------------
| time/                   |             |
|    fps                  | 898         |
|    iterations           | 644         |
|    time_elapsed         | 5874        |
|    total_timesteps      | 5275648     |
| train/                  |             |
|    approx_kl            | 0.045138836 |
|    clip_fraction        | 0.163       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0163     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0127     |
|    n_updates            | 4055        |
|    policy_gradient_loss | 0.0103      |
|    std                  | 0.764       |
|    value_loss           | 2.73e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
Eval num_timesteps=5280000, episode_reward=0.01 +/- 0.07
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | 0.0114      |
| time/                   |             |
|    total_timesteps      | 5280000     |
| train/                  |             |
|    approx_kl            | 0.035358656 |
|    clip_fraction        | 0.164       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.031      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0089     |
|    n_updates            | 4056        |
|    policy_gradient_loss | 0.0141      |
|    std                  | 0.764       |
|    value_loss           | 2.05e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 895     |
|    iterations      | 645     |
|    time_elapsed    | 5900    |
|    total_timesteps | 5283840 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 896         |
|    iterations           | 646         |
|    time_elapsed         | 5903        |
|    total_timesteps      | 5292032     |
| train/                  |             |
|    approx_kl            | 0.027770115 |
|    clip_fraction        | 0.145       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0332     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0078     |
|    n_updates            | 4057        |
|    policy_gradient_loss | 0.00828     |
|    std                  | 0.764       |
|    value_loss           | 2e-05       |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 897         |
|    iterations           | 647         |
|    time_elapsed         | 5906        |
|    total_timesteps      | 5300224     |
| train/                  |             |
|    approx_kl            | 0.030056996 |
|    clip_fraction        | 0.15        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0346     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0146     |
|    n_updates            | 4058        |
|    policy_gradient_loss | 0.00842     |
|    std                  | 0.764       |
|    value_loss           | 1.98e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 898         |
|    iterations           | 648         |
|    time_elapsed         | 5909        |
|    total_timesteps      | 5308416     |
| train/                  |             |
|    approx_kl            | 0.030128874 |
|    clip_fraction        | 0.142       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.046      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.013      |
|    n_updates            | 4059        |
|    policy_gradient_loss | 0.0127      |
|    std                  | 0.764       |
|    value_loss           | 1.4e-05     |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 899         |
|    iterations           | 649         |
|    time_elapsed         | 5912        |
|    total_timesteps      | 5316608     |
| train/                  |             |
|    approx_kl            | 0.027429406 |
|    clip_fraction        | 0.152       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0463     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0168     |
|    n_updates            | 4060        |
|    policy_gradient_loss | 0.0108      |
|    std                  | 0.764       |
|    value_loss           | 1.44e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
Eval num_timesteps=5320000, episode_reward=0.02 +/- 0.11
Episode length: 2340.00 +/- 0.00
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 2.34e+03 |
|    mean_reward          | 0.0184   |
| time/                   |          |
|    total_timesteps      | 5320000  |
| train/                  |          |
|    approx_kl            | 0.028828 |
|    clip_fraction        | 0.148    |
|    clip_range           | 0.2      |
|    entropy_loss         | -1.15    |
|    explained_variance   | -0.0208  |
|    learning_rate        | 5e-05    |
|    loss                 | -0.0136  |
|    n_updates            | 4061     |
|    policy_gradient_loss | 0.0105   |
|    std                  | 0.764    |
|    value_loss           | 3.84e-05 |
--------------------------------------
--------------------------------
| time/              |         |
|    fps             | 896     |
|    iterations      | 650     |
|    time_elapsed    | 5937    |
|    total_timesteps | 5324800 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 897         |
|    iterations           | 651         |
|    time_elapsed         | 5940        |
|    total_timesteps      | 5332992     |
| train/                  |             |
|    approx_kl            | 0.032224346 |
|    clip_fraction        | 0.144       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0278     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00997    |
|    n_updates            | 4062        |
|    policy_gradient_loss | 0.0121      |
|    std                  | 0.764       |
|    value_loss           | 3.32e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 898         |
|    iterations           | 652         |
|    time_elapsed         | 5943        |
|    total_timesteps      | 5341184     |
| train/                  |             |
|    approx_kl            | 0.035211816 |
|    clip_fraction        | 0.167       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0341     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0116     |
|    n_updates            | 4063        |
|    policy_gradient_loss | 0.0114      |
|    std                  | 0.764       |
|    value_loss           | 1.79e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 899         |
|    iterations           | 653         |
|    time_elapsed         | 5946        |
|    total_timesteps      | 5349376     |
| train/                  |             |
|    approx_kl            | 0.036369264 |
|    clip_fraction        | 0.139       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0153     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0123     |
|    n_updates            | 4064        |
|    policy_gradient_loss | 0.0107      |
|    std                  | 0.764       |
|    value_loss           | 4.73e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
----------------------------------------
| time/                   |            |
|    fps                  | 900        |
|    iterations           | 654        |
|    time_elapsed         | 5949       |
|    total_timesteps      | 5357568    |
| train/                  |            |
|    approx_kl            | 0.03868957 |
|    clip_fraction        | 0.141      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0109    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.012     |
|    n_updates            | 4065       |
|    policy_gradient_loss | 0.011      |
|    std                  | 0.764      |
|    value_loss           | 4.75e-05   |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
Eval num_timesteps=5360000, episode_reward=-0.01 +/- 0.06
Episode length: 2340.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 2.34e+03   |
|    mean_reward          | -0.00687   |
| time/                   |            |
|    total_timesteps      | 5360000    |
| train/                  |            |
|    approx_kl            | 0.03541401 |
|    clip_fraction        | 0.152      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0357    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0121    |
|    n_updates            | 4066       |
|    policy_gradient_loss | 0.0108     |
|    std                  | 0.764      |
|    value_loss           | 2.58e-05   |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 898     |
|    iterations      | 655     |
|    time_elapsed    | 5974    |
|    total_timesteps | 5365760 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 899         |
|    iterations           | 656         |
|    time_elapsed         | 5976        |
|    total_timesteps      | 5373952     |
| train/                  |             |
|    approx_kl            | 0.031111935 |
|    clip_fraction        | 0.157       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0371     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0124     |
|    n_updates            | 4067        |
|    policy_gradient_loss | 0.0105      |
|    std                  | 0.764       |
|    value_loss           | 1.8e-05     |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 900         |
|    iterations           | 657         |
|    time_elapsed         | 5979        |
|    total_timesteps      | 5382144     |
| train/                  |             |
|    approx_kl            | 0.038335368 |
|    clip_fraction        | 0.158       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0162     |
|    learning_rate        | 5e-05       |
|    loss                 | 0.00139     |
|    n_updates            | 4068        |
|    policy_gradient_loss | 0.0244      |
|    std                  | 0.764       |
|    value_loss           | 3.2e-05     |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 901         |
|    iterations           | 658         |
|    time_elapsed         | 5981        |
|    total_timesteps      | 5390336     |
| train/                  |             |
|    approx_kl            | 0.030046444 |
|    clip_fraction        | 0.151       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0312     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0104     |
|    n_updates            | 4069        |
|    policy_gradient_loss | 0.0135      |
|    std                  | 0.764       |
|    value_loss           | 2.51e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 902         |
|    iterations           | 659         |
|    time_elapsed         | 5984        |
|    total_timesteps      | 5398528     |
| train/                  |             |
|    approx_kl            | 0.037294716 |
|    clip_fraction        | 0.139       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0238     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0051     |
|    n_updates            | 4070        |
|    policy_gradient_loss | 0.0179      |
|    std                  | 0.764       |
|    value_loss           | 3.42e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
Eval num_timesteps=5400000, episode_reward=0.01 +/- 0.05
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | 0.00858     |
| time/                   |             |
|    total_timesteps      | 5400000     |
| train/                  |             |
|    approx_kl            | 0.040309303 |
|    clip_fraction        | 0.159       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0293     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.012      |
|    n_updates            | 4071        |
|    policy_gradient_loss | 0.011       |
|    std                  | 0.764       |
|    value_loss           | 2.26e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 899     |
|    iterations      | 660     |
|    time_elapsed    | 6008    |
|    total_timesteps | 5406720 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
----------------------------------------
| time/                   |            |
|    fps                  | 900        |
|    iterations           | 661        |
|    time_elapsed         | 6010       |
|    total_timesteps      | 5414912    |
| train/                  |            |
|    approx_kl            | 0.02766823 |
|    clip_fraction        | 0.14       |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0343    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.00248   |
|    n_updates            | 4072       |
|    policy_gradient_loss | 0.0148     |
|    std                  | 0.764      |
|    value_loss           | 2.2e-05    |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.05
----------------------------------------
| time/                   |            |
|    fps                  | 901        |
|    iterations           | 662        |
|    time_elapsed         | 6013       |
|    total_timesteps      | 5423104    |
| train/                  |            |
|    approx_kl            | 0.04582558 |
|    clip_fraction        | 0.132      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0238    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0111    |
|    n_updates            | 4073       |
|    policy_gradient_loss | 0.0119     |
|    std                  | 0.764      |
|    value_loss           | 1.98e-05   |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 902         |
|    iterations           | 663         |
|    time_elapsed         | 6015        |
|    total_timesteps      | 5431296     |
| train/                  |             |
|    approx_kl            | 0.025197253 |
|    clip_fraction        | 0.141       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0414     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00799    |
|    n_updates            | 4074        |
|    policy_gradient_loss | 0.0104      |
|    std                  | 0.764       |
|    value_loss           | 2.19e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 903         |
|    iterations           | 664         |
|    time_elapsed         | 6018        |
|    total_timesteps      | 5439488     |
| train/                  |             |
|    approx_kl            | 0.032950334 |
|    clip_fraction        | 0.148       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0458     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0137     |
|    n_updates            | 4075        |
|    policy_gradient_loss | 0.00628     |
|    std                  | 0.764       |
|    value_loss           | 2e-05       |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
Eval num_timesteps=5440000, episode_reward=-0.00 +/- 0.06
Episode length: 2340.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 2.34e+03   |
|    mean_reward          | -0.00389   |
| time/                   |            |
|    total_timesteps      | 5440000    |
| train/                  |            |
|    approx_kl            | 0.03047487 |
|    clip_fraction        | 0.143      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0415    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.00791   |
|    n_updates            | 4076       |
|    policy_gradient_loss | 0.0151     |
|    std                  | 0.764      |
|    value_loss           | 1.97e-05   |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 901     |
|    iterations      | 665     |
|    time_elapsed    | 6042    |
|    total_timesteps | 5447680 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
----------------------------------------
| time/                   |            |
|    fps                  | 902        |
|    iterations           | 666        |
|    time_elapsed         | 6044       |
|    total_timesteps      | 5455872    |
| train/                  |            |
|    approx_kl            | 0.02908732 |
|    clip_fraction        | 0.135      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0278    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.00865   |
|    n_updates            | 4077       |
|    policy_gradient_loss | 0.0104     |
|    std                  | 0.764      |
|    value_loss           | 3.72e-05   |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
---------------------------------------
| time/                   |           |
|    fps                  | 903       |
|    iterations           | 667       |
|    time_elapsed         | 6047      |
|    total_timesteps      | 5464064   |
| train/                  |           |
|    approx_kl            | 0.0288333 |
|    clip_fraction        | 0.144     |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.15     |
|    explained_variance   | -0.0241   |
|    learning_rate        | 5e-05     |
|    loss                 | -0.0126   |
|    n_updates            | 4078      |
|    policy_gradient_loss | 0.0101    |
|    std                  | 0.765     |
|    value_loss           | 3.31e-05  |
---------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 904         |
|    iterations           | 668         |
|    time_elapsed         | 6050        |
|    total_timesteps      | 5472256     |
| train/                  |             |
|    approx_kl            | 0.034381866 |
|    clip_fraction        | 0.146       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0242     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0112     |
|    n_updates            | 4079        |
|    policy_gradient_loss | 0.0118      |
|    std                  | 0.765       |
|    value_loss           | 2.81e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
Eval num_timesteps=5480000, episode_reward=-0.04 +/- 0.10
Episode length: 2340.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 2.34e+03   |
|    mean_reward          | -0.035     |
| time/                   |            |
|    total_timesteps      | 5480000    |
| train/                  |            |
|    approx_kl            | 0.02552582 |
|    clip_fraction        | 0.136      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0209    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0115    |
|    n_updates            | 4080       |
|    policy_gradient_loss | 0.0143     |
|    std                  | 0.765      |
|    value_loss           | 4.21e-05   |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 902     |
|    iterations      | 669     |
|    time_elapsed    | 6073    |
|    total_timesteps | 5480448 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 903         |
|    iterations           | 670         |
|    time_elapsed         | 6076        |
|    total_timesteps      | 5488640     |
| train/                  |             |
|    approx_kl            | 0.030734183 |
|    clip_fraction        | 0.151       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0138     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.014      |
|    n_updates            | 4081        |
|    policy_gradient_loss | 0.0116      |
|    std                  | 0.765       |
|    value_loss           | 5.52e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 904         |
|    iterations           | 671         |
|    time_elapsed         | 6079        |
|    total_timesteps      | 5496832     |
| train/                  |             |
|    approx_kl            | 0.029174205 |
|    clip_fraction        | 0.132       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0135     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0121     |
|    n_updates            | 4082        |
|    policy_gradient_loss | 0.012       |
|    std                  | 0.765       |
|    value_loss           | 4.47e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 905         |
|    iterations           | 672         |
|    time_elapsed         | 6081        |
|    total_timesteps      | 5505024     |
| train/                  |             |
|    approx_kl            | 0.031382926 |
|    clip_fraction        | 0.152       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0222     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0098     |
|    n_updates            | 4083        |
|    policy_gradient_loss | 0.0132      |
|    std                  | 0.765       |
|    value_loss           | 3.8e-05     |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
----------------------------------------
| time/                   |            |
|    fps                  | 906        |
|    iterations           | 673        |
|    time_elapsed         | 6084       |
|    total_timesteps      | 5513216    |
| train/                  |            |
|    approx_kl            | 0.02746658 |
|    clip_fraction        | 0.141      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0455    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.00567   |
|    n_updates            | 4084       |
|    policy_gradient_loss | 0.0137     |
|    std                  | 0.765      |
|    value_loss           | 2.2e-05    |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
Eval num_timesteps=5520000, episode_reward=0.06 +/- 0.07
Episode length: 2340.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 2.34e+03   |
|    mean_reward          | 0.0564     |
| time/                   |            |
|    total_timesteps      | 5520000    |
| train/                  |            |
|    approx_kl            | 0.02862444 |
|    clip_fraction        | 0.135      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0211    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0123    |
|    n_updates            | 4085       |
|    policy_gradient_loss | 0.0105     |
|    std                  | 0.765      |
|    value_loss           | 2.85e-05   |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 903     |
|    iterations      | 674     |
|    time_elapsed    | 6108    |
|    total_timesteps | 5521408 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
----------------------------------------
| time/                   |            |
|    fps                  | 904        |
|    iterations           | 675        |
|    time_elapsed         | 6111       |
|    total_timesteps      | 5529600    |
| train/                  |            |
|    approx_kl            | 0.02654174 |
|    clip_fraction        | 0.138      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0148    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0175    |
|    n_updates            | 4086       |
|    policy_gradient_loss | 0.0064     |
|    std                  | 0.765      |
|    value_loss           | 4.98e-05   |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 905         |
|    iterations           | 676         |
|    time_elapsed         | 6114        |
|    total_timesteps      | 5537792     |
| train/                  |             |
|    approx_kl            | 0.027335849 |
|    clip_fraction        | 0.135       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0171     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0166     |
|    n_updates            | 4087        |
|    policy_gradient_loss | 0.00656     |
|    std                  | 0.765       |
|    value_loss           | 3.69e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 906         |
|    iterations           | 677         |
|    time_elapsed         | 6117        |
|    total_timesteps      | 5545984     |
| train/                  |             |
|    approx_kl            | 0.036652952 |
|    clip_fraction        | 0.146       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0336     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00151    |
|    n_updates            | 4088        |
|    policy_gradient_loss | 0.0215      |
|    std                  | 0.765       |
|    value_loss           | 1.97e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 907         |
|    iterations           | 678         |
|    time_elapsed         | 6120        |
|    total_timesteps      | 5554176     |
| train/                  |             |
|    approx_kl            | 0.028221274 |
|    clip_fraction        | 0.144       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0295     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00287    |
|    n_updates            | 4089        |
|    policy_gradient_loss | 0.0126      |
|    std                  | 0.765       |
|    value_loss           | 2.73e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
Eval num_timesteps=5560000, episode_reward=0.01 +/- 0.09
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | 0.012       |
| time/                   |             |
|    total_timesteps      | 5560000     |
| train/                  |             |
|    approx_kl            | 0.026587745 |
|    clip_fraction        | 0.151       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0144     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0073     |
|    n_updates            | 4090        |
|    policy_gradient_loss | 0.0125      |
|    std                  | 0.765       |
|    value_loss           | 5.74e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 905     |
|    iterations      | 679     |
|    time_elapsed    | 6144    |
|    total_timesteps | 5562368 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 906         |
|    iterations           | 680         |
|    time_elapsed         | 6147        |
|    total_timesteps      | 5570560     |
| train/                  |             |
|    approx_kl            | 0.029621512 |
|    clip_fraction        | 0.14        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0125     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00208    |
|    n_updates            | 4091        |
|    policy_gradient_loss | 0.0125      |
|    std                  | 0.765       |
|    value_loss           | 4.34e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 907         |
|    iterations           | 681         |
|    time_elapsed         | 6150        |
|    total_timesteps      | 5578752     |
| train/                  |             |
|    approx_kl            | 0.034959905 |
|    clip_fraction        | 0.142       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0186     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0175     |
|    n_updates            | 4092        |
|    policy_gradient_loss | 0.00548     |
|    std                  | 0.765       |
|    value_loss           | 2.73e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 907         |
|    iterations           | 682         |
|    time_elapsed         | 6153        |
|    total_timesteps      | 5586944     |
| train/                  |             |
|    approx_kl            | 0.025618488 |
|    clip_fraction        | 0.143       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0226     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00871    |
|    n_updates            | 4093        |
|    policy_gradient_loss | 0.0121      |
|    std                  | 0.765       |
|    value_loss           | 3.7e-05     |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 908         |
|    iterations           | 683         |
|    time_elapsed         | 6156        |
|    total_timesteps      | 5595136     |
| train/                  |             |
|    approx_kl            | 0.028585892 |
|    clip_fraction        | 0.152       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0488     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00922    |
|    n_updates            | 4094        |
|    policy_gradient_loss | 0.0104      |
|    std                  | 0.765       |
|    value_loss           | 2.01e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
Eval num_timesteps=5600000, episode_reward=0.03 +/- 0.07
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | 0.0312      |
| time/                   |             |
|    total_timesteps      | 5600000     |
| train/                  |             |
|    approx_kl            | 0.042355783 |
|    clip_fraction        | 0.151       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0349     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.016      |
|    n_updates            | 4095        |
|    policy_gradient_loss | 0.00699     |
|    std                  | 0.765       |
|    value_loss           | 2.23e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 906     |
|    iterations      | 684     |
|    time_elapsed    | 6181    |
|    total_timesteps | 5603328 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 907         |
|    iterations           | 685         |
|    time_elapsed         | 6184        |
|    total_timesteps      | 5611520     |
| train/                  |             |
|    approx_kl            | 0.028224219 |
|    clip_fraction        | 0.147       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.00611    |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0116     |
|    n_updates            | 4096        |
|    policy_gradient_loss | 0.00991     |
|    std                  | 0.765       |
|    value_loss           | 7.16e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 908         |
|    iterations           | 686         |
|    time_elapsed         | 6187        |
|    total_timesteps      | 5619712     |
| train/                  |             |
|    approx_kl            | 0.032394513 |
|    clip_fraction        | 0.164       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0372     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0134     |
|    n_updates            | 4097        |
|    policy_gradient_loss | 0.0096      |
|    std                  | 0.765       |
|    value_loss           | 2.52e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 909         |
|    iterations           | 687         |
|    time_elapsed         | 6190        |
|    total_timesteps      | 5627904     |
| train/                  |             |
|    approx_kl            | 0.029645678 |
|    clip_fraction        | 0.146       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0249     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0168     |
|    n_updates            | 4098        |
|    policy_gradient_loss | 0.00692     |
|    std                  | 0.765       |
|    value_loss           | 3.95e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 910         |
|    iterations           | 688         |
|    time_elapsed         | 6192        |
|    total_timesteps      | 5636096     |
| train/                  |             |
|    approx_kl            | 0.033679117 |
|    clip_fraction        | 0.145       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0254     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0109     |
|    n_updates            | 4099        |
|    policy_gradient_loss | 0.0121      |
|    std                  | 0.765       |
|    value_loss           | 2.65e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
Eval num_timesteps=5640000, episode_reward=0.01 +/- 0.07
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | 0.011       |
| time/                   |             |
|    total_timesteps      | 5640000     |
| train/                  |             |
|    approx_kl            | 0.030655487 |
|    clip_fraction        | 0.156       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0298     |
|    learning_rate        | 5e-05       |
|    loss                 | 0.00205     |
|    n_updates            | 4100        |
|    policy_gradient_loss | 0.0251      |
|    std                  | 0.765       |
|    value_loss           | 2.41e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 907     |
|    iterations      | 689     |
|    time_elapsed    | 6217    |
|    total_timesteps | 5644288 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 908         |
|    iterations           | 690         |
|    time_elapsed         | 6220        |
|    total_timesteps      | 5652480     |
| train/                  |             |
|    approx_kl            | 0.028862527 |
|    clip_fraction        | 0.136       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0559     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.011      |
|    n_updates            | 4101        |
|    policy_gradient_loss | 0.0145      |
|    std                  | 0.765       |
|    value_loss           | 1.62e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 909         |
|    iterations           | 691         |
|    time_elapsed         | 6223        |
|    total_timesteps      | 5660672     |
| train/                  |             |
|    approx_kl            | 0.031907544 |
|    clip_fraction        | 0.163       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0168     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00517    |
|    n_updates            | 4102        |
|    policy_gradient_loss | 0.0178      |
|    std                  | 0.765       |
|    value_loss           | 3.25e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 910         |
|    iterations           | 692         |
|    time_elapsed         | 6227        |
|    total_timesteps      | 5668864     |
| train/                  |             |
|    approx_kl            | 0.030189583 |
|    clip_fraction        | 0.146       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0149     |
|    learning_rate        | 5e-05       |
|    loss                 | 0.00144     |
|    n_updates            | 4103        |
|    policy_gradient_loss | 0.0244      |
|    std                  | 0.765       |
|    value_loss           | 4.26e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 911         |
|    iterations           | 693         |
|    time_elapsed         | 6229        |
|    total_timesteps      | 5677056     |
| train/                  |             |
|    approx_kl            | 0.027664173 |
|    clip_fraction        | 0.139       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0139     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00377    |
|    n_updates            | 4104        |
|    policy_gradient_loss | 0.0118      |
|    std                  | 0.765       |
|    value_loss           | 2.87e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
Eval num_timesteps=5680000, episode_reward=0.01 +/- 0.06
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | 0.00922     |
| time/                   |             |
|    total_timesteps      | 5680000     |
| train/                  |             |
|    approx_kl            | 0.026863197 |
|    clip_fraction        | 0.141       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0241     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00924    |
|    n_updates            | 4105        |
|    policy_gradient_loss | 0.00919     |
|    std                  | 0.765       |
|    value_loss           | 3e-05       |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 908     |
|    iterations      | 694     |
|    time_elapsed    | 6257    |
|    total_timesteps | 5685248 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
----------------------------------------
| time/                   |            |
|    fps                  | 909        |
|    iterations           | 695        |
|    time_elapsed         | 6261       |
|    total_timesteps      | 5693440    |
| train/                  |            |
|    approx_kl            | 0.03301109 |
|    clip_fraction        | 0.162      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0304    |
|    learning_rate        | 5e-05      |
|    loss                 | 0.00261    |
|    n_updates            | 4106       |
|    policy_gradient_loss | 0.0256     |
|    std                  | 0.765      |
|    value_loss           | 2.12e-05   |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
----------------------------------------
| time/                   |            |
|    fps                  | 909        |
|    iterations           | 696        |
|    time_elapsed         | 6265       |
|    total_timesteps      | 5701632    |
| train/                  |            |
|    approx_kl            | 0.02868225 |
|    clip_fraction        | 0.134      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0347    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0184    |
|    n_updates            | 4107       |
|    policy_gradient_loss | 0.0103     |
|    std                  | 0.765      |
|    value_loss           | 2.07e-05   |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 910         |
|    iterations           | 697         |
|    time_elapsed         | 6270        |
|    total_timesteps      | 5709824     |
| train/                  |             |
|    approx_kl            | 0.030104108 |
|    clip_fraction        | 0.146       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.04       |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00862    |
|    n_updates            | 4108        |
|    policy_gradient_loss | 0.0144      |
|    std                  | 0.765       |
|    value_loss           | 1.93e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 911         |
|    iterations           | 698         |
|    time_elapsed         | 6273        |
|    total_timesteps      | 5718016     |
| train/                  |             |
|    approx_kl            | 0.032470293 |
|    clip_fraction        | 0.135       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0244     |
|    learning_rate        | 5e-05       |
|    loss                 | 0.00163     |
|    n_updates            | 4109        |
|    policy_gradient_loss | 0.0246      |
|    std                  | 0.765       |
|    value_loss           | 3.32e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
Eval num_timesteps=5720000, episode_reward=-0.02 +/- 0.09
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | -0.0205     |
| time/                   |             |
|    total_timesteps      | 5720000     |
| train/                  |             |
|    approx_kl            | 0.035509776 |
|    clip_fraction        | 0.156       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0451     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00287    |
|    n_updates            | 4110        |
|    policy_gradient_loss | 0.0201      |
|    std                  | 0.765       |
|    value_loss           | 2.31e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 909     |
|    iterations      | 699     |
|    time_elapsed    | 6299    |
|    total_timesteps | 5726208 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
----------------------------------------
| time/                   |            |
|    fps                  | 909        |
|    iterations           | 700        |
|    time_elapsed         | 6302       |
|    total_timesteps      | 5734400    |
| train/                  |            |
|    approx_kl            | 0.03328359 |
|    clip_fraction        | 0.146      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0526    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0137    |
|    n_updates            | 4111       |
|    policy_gradient_loss | 0.00935    |
|    std                  | 0.765      |
|    value_loss           | 1.54e-05   |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 910         |
|    iterations           | 701         |
|    time_elapsed         | 6304        |
|    total_timesteps      | 5742592     |
| train/                  |             |
|    approx_kl            | 0.031592023 |
|    clip_fraction        | 0.161       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0345     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0108     |
|    n_updates            | 4112        |
|    policy_gradient_loss | 0.0121      |
|    std                  | 0.765       |
|    value_loss           | 2.11e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
----------------------------------------
| time/                   |            |
|    fps                  | 911        |
|    iterations           | 702        |
|    time_elapsed         | 6307       |
|    total_timesteps      | 5750784    |
| train/                  |            |
|    approx_kl            | 0.03234672 |
|    clip_fraction        | 0.173      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0279    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0108    |
|    n_updates            | 4113       |
|    policy_gradient_loss | 0.0122     |
|    std                  | 0.765      |
|    value_loss           | 2.11e-05   |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 912         |
|    iterations           | 703         |
|    time_elapsed         | 6310        |
|    total_timesteps      | 5758976     |
| train/                  |             |
|    approx_kl            | 0.031662174 |
|    clip_fraction        | 0.169       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0341     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00649    |
|    n_updates            | 4114        |
|    policy_gradient_loss | 0.0165      |
|    std                  | 0.765       |
|    value_loss           | 2.15e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
Eval num_timesteps=5760000, episode_reward=0.01 +/- 0.09
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | 0.0096      |
| time/                   |             |
|    total_timesteps      | 5760000     |
| train/                  |             |
|    approx_kl            | 0.029722637 |
|    clip_fraction        | 0.151       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0262     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0157     |
|    n_updates            | 4115        |
|    policy_gradient_loss | 0.0106      |
|    std                  | 0.766       |
|    value_loss           | 2.89e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 909     |
|    iterations      | 704     |
|    time_elapsed    | 6339    |
|    total_timesteps | 5767168 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 910         |
|    iterations           | 705         |
|    time_elapsed         | 6342        |
|    total_timesteps      | 5775360     |
| train/                  |             |
|    approx_kl            | 0.030968407 |
|    clip_fraction        | 0.148       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.00884    |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0148     |
|    n_updates            | 4116        |
|    policy_gradient_loss | 0.0104      |
|    std                  | 0.766       |
|    value_loss           | 7.39e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 911         |
|    iterations           | 706         |
|    time_elapsed         | 6346        |
|    total_timesteps      | 5783552     |
| train/                  |             |
|    approx_kl            | 0.030097917 |
|    clip_fraction        | 0.156       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0146     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0136     |
|    n_updates            | 4117        |
|    policy_gradient_loss | 0.0094      |
|    std                  | 0.766       |
|    value_loss           | 4.35e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
----------------------------------------
| time/                   |            |
|    fps                  | 912        |
|    iterations           | 707        |
|    time_elapsed         | 6349       |
|    total_timesteps      | 5791744    |
| train/                  |            |
|    approx_kl            | 0.03002486 |
|    clip_fraction        | 0.134      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0225    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0172    |
|    n_updates            | 4118       |
|    policy_gradient_loss | 0.00578    |
|    std                  | 0.766      |
|    value_loss           | 3.43e-05   |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 912         |
|    iterations           | 708         |
|    time_elapsed         | 6353        |
|    total_timesteps      | 5799936     |
| train/                  |             |
|    approx_kl            | 0.028878435 |
|    clip_fraction        | 0.143       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.057      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0122     |
|    n_updates            | 4119        |
|    policy_gradient_loss | 0.00855     |
|    std                  | 0.766       |
|    value_loss           | 1.78e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
Eval num_timesteps=5800000, episode_reward=0.02 +/- 0.08
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | 0.0215      |
| time/                   |             |
|    total_timesteps      | 5800000     |
| train/                  |             |
|    approx_kl            | 0.041177996 |
|    clip_fraction        | 0.154       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0506     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.000859   |
|    n_updates            | 4120        |
|    policy_gradient_loss | 0.0222      |
|    std                  | 0.766       |
|    value_loss           | 1.37e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 910     |
|    iterations      | 709     |
|    time_elapsed    | 6381    |
|    total_timesteps | 5808128 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 910         |
|    iterations           | 710         |
|    time_elapsed         | 6384        |
|    total_timesteps      | 5816320     |
| train/                  |             |
|    approx_kl            | 0.035450302 |
|    clip_fraction        | 0.155       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0418     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00867    |
|    n_updates            | 4121        |
|    policy_gradient_loss | 0.0144      |
|    std                  | 0.766       |
|    value_loss           | 2.28e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 911         |
|    iterations           | 711         |
|    time_elapsed         | 6388        |
|    total_timesteps      | 5824512     |
| train/                  |             |
|    approx_kl            | 0.030087585 |
|    clip_fraction        | 0.143       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0221     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0101     |
|    n_updates            | 4122        |
|    policy_gradient_loss | 0.0129      |
|    std                  | 0.766       |
|    value_loss           | 2.07e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
----------------------------------------
| time/                   |            |
|    fps                  | 912        |
|    iterations           | 712        |
|    time_elapsed         | 6392       |
|    total_timesteps      | 5832704    |
| train/                  |            |
|    approx_kl            | 0.04124364 |
|    clip_fraction        | 0.163      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0041    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.00926   |
|    n_updates            | 4123       |
|    policy_gradient_loss | 0.0137     |
|    std                  | 0.766      |
|    value_loss           | 0.000133   |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
Eval num_timesteps=5840000, episode_reward=-0.00 +/- 0.07
Episode length: 2340.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 2.34e+03   |
|    mean_reward          | -0.0032    |
| time/                   |            |
|    total_timesteps      | 5840000    |
| train/                  |            |
|    approx_kl            | 0.03983383 |
|    clip_fraction        | 0.157      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0139    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0098    |
|    n_updates            | 4124       |
|    policy_gradient_loss | 0.0132     |
|    std                  | 0.766      |
|    value_loss           | 3.95e-05   |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 909     |
|    iterations      | 713     |
|    time_elapsed    | 6419    |
|    total_timesteps | 5840896 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
----------------------------------------
| time/                   |            |
|    fps                  | 910        |
|    iterations           | 714        |
|    time_elapsed         | 6423       |
|    total_timesteps      | 5849088    |
| train/                  |            |
|    approx_kl            | 0.03612146 |
|    clip_fraction        | 0.166      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0269    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0152    |
|    n_updates            | 4125       |
|    policy_gradient_loss | 0.00785    |
|    std                  | 0.766      |
|    value_loss           | 4.12e-05   |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 911         |
|    iterations           | 715         |
|    time_elapsed         | 6426        |
|    total_timesteps      | 5857280     |
| train/                  |             |
|    approx_kl            | 0.031905275 |
|    clip_fraction        | 0.166       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.027      |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0156     |
|    n_updates            | 4126        |
|    policy_gradient_loss | 0.00739     |
|    std                  | 0.766       |
|    value_loss           | 2.38e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
----------------------------------------
| time/                   |            |
|    fps                  | 912        |
|    iterations           | 716        |
|    time_elapsed         | 6429       |
|    total_timesteps      | 5865472    |
| train/                  |            |
|    approx_kl            | 0.03449715 |
|    clip_fraction        | 0.143      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0238    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.00622   |
|    n_updates            | 4127       |
|    policy_gradient_loss | 0.0168     |
|    std                  | 0.766      |
|    value_loss           | 2.79e-05   |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 913         |
|    iterations           | 717         |
|    time_elapsed         | 6432        |
|    total_timesteps      | 5873664     |
| train/                  |             |
|    approx_kl            | 0.036351986 |
|    clip_fraction        | 0.165       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0207     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00752    |
|    n_updates            | 4128        |
|    policy_gradient_loss | 0.0155      |
|    std                  | 0.766       |
|    value_loss           | 2.9e-05     |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
Eval num_timesteps=5880000, episode_reward=-0.06 +/- 0.10
Episode length: 2340.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 2.34e+03   |
|    mean_reward          | -0.0606    |
| time/                   |            |
|    total_timesteps      | 5880000    |
| train/                  |            |
|    approx_kl            | 0.03180804 |
|    clip_fraction        | 0.153      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0496    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0123    |
|    n_updates            | 4129       |
|    policy_gradient_loss | 0.0107     |
|    std                  | 0.766      |
|    value_loss           | 1.69e-05   |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 910     |
|    iterations      | 718     |
|    time_elapsed    | 6459    |
|    total_timesteps | 5881856 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
----------------------------------------
| time/                   |            |
|    fps                  | 911        |
|    iterations           | 719        |
|    time_elapsed         | 6462       |
|    total_timesteps      | 5890048    |
| train/                  |            |
|    approx_kl            | 0.02906442 |
|    clip_fraction        | 0.147      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0442    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0142    |
|    n_updates            | 4130       |
|    policy_gradient_loss | 0.0129     |
|    std                  | 0.766      |
|    value_loss           | 1.92e-05   |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 912         |
|    iterations           | 720         |
|    time_elapsed         | 6465        |
|    total_timesteps      | 5898240     |
| train/                  |             |
|    approx_kl            | 0.030014604 |
|    clip_fraction        | 0.149       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0222     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0156     |
|    n_updates            | 4131        |
|    policy_gradient_loss | 0.00747     |
|    std                  | 0.766       |
|    value_loss           | 3.4e-05     |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.05
-----------------------------------------
| time/                   |             |
|    fps                  | 913         |
|    iterations           | 721         |
|    time_elapsed         | 6468        |
|    total_timesteps      | 5906432     |
| train/                  |             |
|    approx_kl            | 0.046452507 |
|    clip_fraction        | 0.191       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0138     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0145     |
|    n_updates            | 4132        |
|    policy_gradient_loss | 0.00855     |
|    std                  | 0.766       |
|    value_loss           | 7.17e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 913         |
|    iterations           | 722         |
|    time_elapsed         | 6471        |
|    total_timesteps      | 5914624     |
| train/                  |             |
|    approx_kl            | 0.032809447 |
|    clip_fraction        | 0.155       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0329     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0151     |
|    n_updates            | 4133        |
|    policy_gradient_loss | 0.0079      |
|    std                  | 0.766       |
|    value_loss           | 2.89e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
Eval num_timesteps=5920000, episode_reward=0.02 +/- 0.08
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | 0.0239      |
| time/                   |             |
|    total_timesteps      | 5920000     |
| train/                  |             |
|    approx_kl            | 0.041792624 |
|    clip_fraction        | 0.176       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0187     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0123     |
|    n_updates            | 4134        |
|    policy_gradient_loss | 0.0107      |
|    std                  | 0.766       |
|    value_loss           | 3.36e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 911     |
|    iterations      | 723     |
|    time_elapsed    | 6495    |
|    total_timesteps | 5922816 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
----------------------------------------
| time/                   |            |
|    fps                  | 912        |
|    iterations           | 724        |
|    time_elapsed         | 6499       |
|    total_timesteps      | 5931008    |
| train/                  |            |
|    approx_kl            | 0.03909476 |
|    clip_fraction        | 0.174      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0238    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0074    |
|    n_updates            | 4135       |
|    policy_gradient_loss | 0.0156     |
|    std                  | 0.766      |
|    value_loss           | 3.04e-05   |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
-----------------------------------------
| time/                   |             |
|    fps                  | 913         |
|    iterations           | 725         |
|    time_elapsed         | 6503        |
|    total_timesteps      | 5939200     |
| train/                  |             |
|    approx_kl            | 0.033567704 |
|    clip_fraction        | 0.168       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0361     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00167    |
|    n_updates            | 4136        |
|    policy_gradient_loss | 0.0214      |
|    std                  | 0.766       |
|    value_loss           | 2.49e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
----------------------------------------
| time/                   |            |
|    fps                  | 913        |
|    iterations           | 726        |
|    time_elapsed         | 6507       |
|    total_timesteps      | 5947392    |
| train/                  |            |
|    approx_kl            | 0.03304908 |
|    clip_fraction        | 0.137      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0299    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0063    |
|    n_updates            | 4137       |
|    policy_gradient_loss | 0.0146     |
|    std                  | 0.766      |
|    value_loss           | 2.03e-05   |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 914         |
|    iterations           | 727         |
|    time_elapsed         | 6510        |
|    total_timesteps      | 5955584     |
| train/                  |             |
|    approx_kl            | 0.031519316 |
|    clip_fraction        | 0.16        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0311     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.0134     |
|    n_updates            | 4138        |
|    policy_gradient_loss | 0.00903     |
|    std                  | 0.766       |
|    value_loss           | 2.35e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
Eval num_timesteps=5960000, episode_reward=0.06 +/- 0.04
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | 0.0593      |
| time/                   |             |
|    total_timesteps      | 5960000     |
| train/                  |             |
|    approx_kl            | 0.034390725 |
|    clip_fraction        | 0.152       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0384     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00992    |
|    n_updates            | 4139        |
|    policy_gradient_loss | 0.0111      |
|    std                  | 0.766       |
|    value_loss           | 2.11e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 912     |
|    iterations      | 728     |
|    time_elapsed    | 6536    |
|    total_timesteps | 5963776 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
----------------------------------------
| time/                   |            |
|    fps                  | 913        |
|    iterations           | 729        |
|    time_elapsed         | 6539       |
|    total_timesteps      | 5971968    |
| train/                  |            |
|    approx_kl            | 0.03740013 |
|    clip_fraction        | 0.157      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.0151    |
|    learning_rate        | 5e-05      |
|    loss                 | -0.00723   |
|    n_updates            | 4140       |
|    policy_gradient_loss | 0.0158     |
|    std                  | 0.766      |
|    value_loss           | 5.27e-05   |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.04
-----------------------------------------
| time/                   |             |
|    fps                  | 913         |
|    iterations           | 730         |
|    time_elapsed         | 6543        |
|    total_timesteps      | 5980160     |
| train/                  |             |
|    approx_kl            | 0.038679205 |
|    clip_fraction        | 0.141       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0417     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00814    |
|    n_updates            | 4141        |
|    policy_gradient_loss | 0.0149      |
|    std                  | 0.766       |
|    value_loss           | 1.43e-05    |
-----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
----------------------------------------
| time/                   |            |
|    fps                  | 914        |
|    iterations           | 731        |
|    time_elapsed         | 6546       |
|    total_timesteps      | 5988352    |
| train/                  |            |
|    approx_kl            | 0.03297757 |
|    clip_fraction        | 0.15       |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | -0.023     |
|    learning_rate        | 5e-05      |
|    loss                 | -0.0124    |
|    n_updates            | 4142       |
|    policy_gradient_loss | 0.0107     |
|    std                  | 0.766      |
|    value_loss           | 3.33e-05   |
----------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
---------------------------------------
| time/                   |           |
|    fps                  | 915       |
|    iterations           | 732       |
|    time_elapsed         | 6549      |
|    total_timesteps      | 5996544   |
| train/                  |           |
|    approx_kl            | 0.0302749 |
|    clip_fraction        | 0.158     |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.15     |
|    explained_variance   | -0.0148   |
|    learning_rate        | 5e-05     |
|    loss                 | -0.00227  |
|    n_updates            | 4143      |
|    policy_gradient_loss | 0.0208    |
|    std                  | 0.766     |
|    value_loss           | 3.91e-05  |
---------------------------------------
Early stopping at step 0 due to reaching max kl: 0.03
Eval num_timesteps=6000000, episode_reward=0.04 +/- 0.08
Episode length: 2340.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | 0.042       |
| time/                   |             |
|    total_timesteps      | 6000000     |
| train/                  |             |
|    approx_kl            | 0.030249588 |
|    clip_fraction        | 0.148       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | -0.0213     |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00665    |
|    n_updates            | 4144        |
|    policy_gradient_loss | 0.0164      |
|    std                  | 0.766       |
|    value_loss           | 2.89e-05    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 913     |
|    iterations      | 733     |
|    time_elapsed    | 6573    |
|    total_timesteps | 6004736 |
--------------------------------
Early stopping at step 0 due to reaching max kl: 0.05
